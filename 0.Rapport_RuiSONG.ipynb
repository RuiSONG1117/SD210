{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rapport du challenge du cours SD210\n",
    "\n",
    "Autheur: Rui SONG\n",
    "\n",
    "<p>Ce notebook contients le rapport du challenge du cours SD210.</p>\n",
    "<p>La méthode retenue à la fin est un Bagging Classifieur combinant 200 Multi-layer Perceptron (MLP) classifieurs. \n",
    "Le code pour le classifeur retenue finale est dans le fichier: <b>Final.ipynb</b>. \n",
    "Et le meilleur score obtenu est 0.125235404896 (18 ème position). </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Investigation des données\n",
    "\n",
    "Avant de passer les données aux classifiers, on va d'abord explorer les variables explicatives des données d'apprentisage (training data) pour déterminer si elles ont besoin de preprocessing et si oui quel type de preprocessing. On a utilisé l'ACP et le pourcentage d'inertie (l'attribut 'pca.explained_varianceratio') qui représente le pourcentage de variance expliqué par chacun des composants sélectionnés pour détérminer le nombre de varaibles explicatives à garder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11327df90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEWCAYAAABMoxE0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3XuYXXV97/H3Z/bcL7kPSUgCBAlipBp0BKrWiggFvCSe\n9mA4XlA5J6Ki0lNbo/ac0tP2lFov1UckRUtBRSleOKY+KCDaR6simSgCASMBEpKQy5B7MveZ7/lj\nrZmsTOayJyubmU0+r+fZz17rd1n7uzYk36zfb63fVkRgZmZ2rComOgAzMytvTiRmZpaLE4mZmeXi\nRGJmZrk4kZiZWS5OJGZmlosTidnzjKSQdMYw5W+TdM9zGMcfSFr/XH2eTRwnEptwkjZK6pB0UNIO\nSbdIapzouIol6V2S/nOi4xhO+l2+CyAibouIi0v4WUcksIj4aUS8sFSfZ5OHE4lNFm+KiEbgZUAL\n8JfH8+CSKo/n8ewwf7fmRGKTSkRsBb4PnA0g6WRJqyXtlrRB0v8YaJv+a/tvM/uvlbQls79R0kcl\nPQQcklQpaYGk70hqk7RL0hcy7d8j6TFJeyTdLenUTF1IulrS45L2SrpBiRcBq4DfT6+o9qbt3yDp\n15L2S9os6brseUp6p6RNaQz/K4319WldhaSVkp5I6++QNGOk70zSn0vaJukZSe8Zpd0RV04jndM4\nvo8PSHoceFzST9Kq36Tfw1uH+e9xsqRvp9/9U5I+NFKsVl6cSGxSkbQAuAz4dVp0O7AFOBn4E+D/\nSnrdOA55BfAGYBoQwPeATcBpwLz0+EhaCnwc+C9AM/BT4BtDjvVG4BXAS4DLgT+KiMeAq4FfRERj\nRExL2x4C3pl+7huA90laln7WYuCLwNuAucDUNJYBHwSWAX+Ynvce4IbhTk7SJcBHgIuARcDrs/UR\n8a6IuGWU7+eocxrH97EMOA9YHBGvSctemn4P/zYkzgrg34HfpOd6IXCtpD8aJTYrFxHhl18T+gI2\nAgeBvSR/yX8RqAMWAH1AU6bt3wO3pNu3AH+bqXstsGXIcd+T2f99oA2oHCaG7wNXZfYrgHbg1HQ/\ngFdn6u8AVqbb7wL+c4xz/Cfgs+n2/wa+kamrB7qB16f7jwEXZurnAj0jxH0zcH1m/8w01jOGaXtE\nnGOcUzHfx+uGHP+Iz83+9yBJOE8Paf8x4F8n+v8/v/K/PLZpk8WyiPhhtkDSycDuiDiQKd5EModS\nrM2Z7QXApojoHabdqcDnJH06GwLJv543pfvbM3XtwIg3BEg6D7ieZIiuGqgBvplWn5yNKyLaJe0a\nEsudkvozZX3AbGDrkI86GVib2d/E+Ix0TsV8H9nvdiynAicPDP2lCiRXOlbmnEhsMnsGmCGpKZNM\nTuHwX6aHSP41P2DOMMfILm+9GThFUuUwyWQz8HcRcdsxxDncEtpfB74AXBoRnZL+CZiV1m0DBu9m\nklQHzBwSy3si4mdFfPY2kgQ54JTxBD6KYr6P8Swdvhl4KiIW5QvLJiPPkdikFRGbgZ8Dfy+pVtJL\ngKuAr6VNHgQukzRD0hzg2jEO+QDJX7zXS2pIj/mqtG4V8DFJLwaQNFXSfy0y1B3AfEnVmbImkqup\nTknnAv8tU/ct4E2SXpn2uY7kX/sDVgF/NzC5Lak5nbMYzh3AuyQtllQP/FWRMY/lWL6PHcDpI9Q9\nABxIb36ok1SQdLakVxyneG0COZHYZHcFycT4M8CdwF9lhsC+SjJ5uxG4B/i3YfoPiog+4E3AGcDT\nJJP4b03r7gT+Abhd0n7gEeDSImP8EbAO2C7p2bTs/cD/kXSAZE7kjkwc60gm1G8nSWwHgZ1AV9rk\nc8Bq4J60//0kcwzDndP3SeZffgRsSN9zO8bv4zrg1vQOsMuHHK+PZGJ/CfAU8CzwZZIbDazMKcI/\nbGU2kZQ8fLkXWBQRT010PGbj5SsSswkg6U2S6iU1AJ8CHia5sjIrOyVNJJIukbReyYNkK4epf5uk\nhyQ9LOnnkl46Vt90PPze9CGqeyVNL+U5mJXIUpLhumdInv9YHh4esDJVsqEtSQXgdyQPSm0B1gBX\nRMSjmTavBB6LiD2SLgWui4jzRusr6ZMkk5jXpwlmekR8tCQnYWZmYyrlFcm5wIaIeDIiukkmFo+4\n8yQifh4Re9Ld+4H5RfRdCtyabt9K8nStmZlNkFI+RzKPIx9Y2sIId56kriJ5mnasvrMjYlu6vZ3k\nIa2jSFoBrABoaGh4+VlnnTWu4M3MTnRr1659NiKax2o3KR5IlHQBSSJ59Xj6RURIGnZsLiJuAm4C\naGlpidbW1txxmpmdSCQVtVJCKYe2tnLkE7fzOXp5B9KHzL4MLI2IXUX03SFpbtp3Lsn992ZmNkFK\nmUjWAIskLUyf3l1O8pDVIEmnAN8B3hERvyuy72rgynT7SuC7JTwHMzMbQ8mGtiKiV9I1wN0ki7Pd\nHBHrJF2d1q8ieeJ3JvDF9GcQeiOiZaS+6aGvB+6QdBXJ4nFHPEFrZmbPrRPiyXbPkZiZjZ+ktREx\n5mrbfrLdzMxycSIxM7NcnEjMzCwXJxIzM8vFicTMzHJxIjEzs1ycSMzMLBcnEjMzy8WJxMzMcnEi\nMTOzXJxIzMwsFycSMzPLxYnEzMxycSIxM7NcnEjMzCwXJxIzM8vFicTMzHJxIjEzs1xKmkgkXSJp\nvaQNklYOU3+WpF9I6pL0kUz5CyU9mHntl3RtWnedpK2ZustKeQ5mZja6ylIdWFIBuAG4CNgCrJG0\nOiIezTTbDXwIWJbtGxHrgSWZ42wF7sw0+WxEfKpUsZuZWfFKeUVyLrAhIp6MiG7gdmBptkFE7IyI\nNUDPKMe5EHgiIjaVLlQzMztWpUwk84DNmf0tadl4LQe+MaTsg5IeknSzpOnHGqCZmeU3qSfbJVUD\nbwa+mSm+ETidZOhrG/DpEfqukNQqqbWtra3ksZqZnahKmUi2Agsy+/PTsvG4FPhVROwYKIiIHRHR\nFxH9wJdIhtCOEhE3RURLRLQ0NzeP82PNzKxYpUwka4BFkhamVxbLgdXjPMYVDBnWkjQ3s/sW4JFc\nUZqZWS4lu2srInolXQPcDRSAmyNinaSr0/pVkuYArcAUoD+9xXdxROyX1EByx9d7hxz6k5KWAAFs\nHKbezMyeQ4qIiY6h5FpaWqK1tXWiwzAzKyuS1kZEy1jtJvVku5mZTX5OJGZmlosTiZmZ5eJEYmZm\nuTiRmJlZLk4kZmaWixOJmZnl4kRiZma5OJGYmVkuTiRmZpaLE4mZmeXiRGJmZrk4kZiZWS5OJGZm\nlosTiZmZ5eJEYmZmuTiRmJlZLk4kZmaWixOJmZnlUtJEIukSSeslbZC0cpj6syT9QlKXpI8Mqdso\n6WFJD0pqzZTPkHSvpMfT9+mlPAczMxtdyRKJpAJwA3ApsBi4QtLiIc12Ax8CPjXCYS6IiCVDfnx+\nJXBfRCwC7kv3zcxsgpTyiuRcYENEPBkR3cDtwNJsg4jYGRFrgJ5xHHcpcGu6fSuw7HgEa2Zmx6aU\niWQesDmzvyUtK1YAP5S0VtKKTPnsiNiWbm8HZg/XWdIKSa2SWtva2sYTt5mZjcNknmx/dUQsIRka\n+4Ck1wxtEBFBknCOEhE3RURLRLQ0NzeXOFQzsxNXKRPJVmBBZn9+WlaUiNiavu8E7iQZKgPYIWku\nQPq+87hEa2Zmx6SUiWQNsEjSQknVwHJgdTEdJTVIahrYBi4GHkmrVwNXpttXAt89rlGbmdm4VJbq\nwBHRK+ka4G6gANwcEeskXZ3Wr5I0B2gFpgD9kq4lucNrFnCnpIEYvx4RP0gPfT1wh6SrgE3A5aU6\nBzMzG5uSaYbnt5aWlmhtbR27oZmZDZK0dsjjF8OazJPtZmZWBpxIzMwsFycSMzPLxYnEzMxycSIx\nM7NcnEjMzCwXJxIzM8vFicTMzHJxIjEzs1ycSMzMLBcnEjMzy8WJxMzMcnEiMTOzXJxIzMwsFycS\nMzPLxYnEzMxycSIxM7NcnEjMzCyXkiYSSZdIWi9pg6SVw9SfJekXkrokfSRTvkDSjyU9KmmdpA9n\n6q6TtFXSg+nrslKeg5mZja6yVAeWVABuAC4CtgBrJK2OiEczzXYDHwKWDeneC/xZRPxKUhOwVtK9\nmb6fjYhPlSp2MzMrXimvSM4FNkTEkxHRDdwOLM02iIidEbEG6BlSvi0ifpVuHwAeA+aVMFYzMztG\npUwk84DNmf0tHEMykHQacA7wy0zxByU9JOlmSdNH6LdCUquk1ra2tvF+rJmZFWlST7ZLagS+DVwb\nEfvT4huB04ElwDbg08P1jYibIqIlIlqam5ufk3jNzE5EpUwkW4EFmf35aVlRJFWRJJHbIuI7A+UR\nsSMi+iKiH/gSyRCamZlNkFImkjXAIkkLJVUDy4HVxXSUJOBfgMci4jND6uZmdt8CPHKc4jUzs2NQ\nsru2IqJX0jXA3UABuDki1km6Oq1fJWkO0ApMAfolXQssBl4CvAN4WNKD6SE/HhF3AZ+UtAQIYCPw\n3lKdg5mZjU0RMdExlFxLS0u0trZOdBhmZmVF0tqIaBmr3aSebDczs8nPicTMzHJxIjEzs1ycSMzM\nLBcnEjMzy8WJxMzMcnEiMTOzXJxIzMwsFycSMzPLxYnEzMxycSIxM7Ncil60MV3B98x0d31E9IzW\n3szMTgxFJRJJrwVuJVltV8ACSVdGxE9KF5qZmZWDYq9IPg1cHBHrASSdCXwDeHmpAjMzs/JQ7BxJ\n1UASAYiI3wFVpQnJzMzKSbFXJK2Svgx8Ld1/G8kPUpmZ2Qmu2ETyPuADwIfS/Z8CXyxJRGZmVlaK\nSiQR0QV8Jn2ZmZkNGnWORNId6fvDkh4a+hrr4JIukbRe0gZJK4epP0vSLyR1SfpIMX0lzZB0r6TH\n0/fpxZ+umZkdb2NdkXw4fX/jeA8sqQDcAFwEbAHWSFodEY9mmu0mGS5bNo6+K4H7IuL6NMGsBD46\n3vjMzOz4GPWKJCK2pZvvj4hN2Rfw/jGOfS6wISKejIhu4HZg6ZDj74yINcDQhxtH67uU5JkW0vdl\nmJnZhCn29t+Lhim7dIw+84DNmf0taVkxRus7O5PgtgOzhzuApBWSWiW1trW1FfmxZmY2XmPNkbxP\n0sPAC4fMjzwFjDlHUmoREUCMUHdTRLREREtzc/NzHJmZ2YljrDmSrwPfB/6eZC5iwIGI2D1G363A\ngsz+/LSsGKP13SFpbkRskzQX2FnkMc3MrATGmiPZFxEbI+KKdF6kg+QKoFHSKWMcew2wSNLCdMHH\n5cDqIuMare9q4Mp0+0rgu0Ue08zMSqDYRRvfRPIMyckkVwCnAo8BLx6pT0T0SroGuBsoADdHxDpJ\nV6f1qyTNIXlCfgrQL+laYHFE7B+ub3ro64E7JF0FbAIuH+9Jm5nZ8aNkmmGMRtJvgNcBP4yIcyRd\nALw9Iq4qdYDHQ0tLS7S2ekUXM7PxkLQ2IlrGalfsXVs9EbELqJBUERE/BsY8uJmZPf8Vu9bWXkmN\nwE+A2yTtBA6VLiwzMysXxV6RLAXagT8FfgA8AbypVEGZmVn5KHbRxoGrj37gVkkVwBXAbaUKzMzM\nysNYDyROkfQxSV+QdLES1wBP4rulzMyMsa9IvgrsAX4B/Hfg4yS/2b4sIh4scWxmZlYGxkokp0fE\n7wGkv5C4DTglIjpLHpmZmZWFsSbbB1fljYg+YIuTiJmZZY11RfJSSfvTbQF16b5I1kycUtLozMxs\n0hs1kURE4bkKxMzMylOxz5GYmZkNy4nEzMxycSIxM7NcnEjMzCwXJxIzM8vFicTMzHJxIjEzs1yc\nSMzMLJeSJhJJl0haL2mDpJXD1EvS59P6hyS9LC1/oaQHM6/96e+5I+k6SVszdZeV8hzMzGx0xf5C\n4rhJKgA3ABcBW4A1klZHxKOZZpcCi9LXecCNwHkRsR5YkjnOVuDOTL/PRsSnShW7mZkVr5RXJOcC\nGyLiyYjoBm4n+aXFrKXAVyJxPzBN0twhbS4EnoiITSWM1czMjlEpE8k8YHNmf0taNt42y4FvDCn7\nYDoUdrOk6cN9uKQVkloltba1tY0/ejMzK8qknmyXVA28GfhmpvhG4HSSoa9twKeH6xsRN0VES0S0\nNDc3lzxWM7MTVSkTyVZgQWZ/flo2njaXAr+KiB0DBRGxIyL6IqIf+BLJEJqZmU2QUiaSNcAiSQvT\nK4vlwOohbVYD70zv3jof2BcR2zL1VzBkWGvIHMpbgEeOf+hmZlaskt21FRG9kq4B7gYKwM0RsU7S\n1Wn9KuAu4DJgA9AOvHugv6QGkju+3jvk0J+UtAQIYOMw9WZm9hxSREx0DCXX0tISra2tEx2GmVlZ\nkbQ2IlrGajepJ9vNzGzycyIxM7NcnEjMzCwXJxIzM8vFicTMzHJxIjEzs1ycSMzMLBcnEjMzy8WJ\nxMzMcnEiMTOzXJxIzMwsFycSMzPLxYnEzMxycSIxM7NcnEjMzCwXJxIzM8vFicTMzHJxIjEzs1xK\nmkgkXSJpvaQNklYOUy9Jn0/rH5L0skzdRkkPS3pQUmumfIakeyU9nr5PL+U5mJnZ6EqWSCQVgBuA\nS4HFwBWSFg9pdimwKH2tAG4cUn9BRCwZ8pvBK4H7ImIRcF+6b2ZmE6SUVyTnAhsi4smI6AZuB5YO\nabMU+Eok7gemSZo7xnGXArem27cCy45n0GZmNj6lTCTzgM2Z/S1pWbFtAvihpLWSVmTazI6Iben2\ndmD2cB8uaYWkVkmtbW1tx3oOZmY2hsk82f7qiFhCMvz1AUmvGdogIoIk4RwlIm6KiJaIaGlubi5x\nqGZmJ65SJpKtwILM/vy0rKg2ETHwvhO4k2SoDGDHwPBX+r7zuEduZmZFK2UiWQMskrRQUjWwHFg9\npM1q4J3p3VvnA/siYpukBklNAJIagIuBRzJ9rky3rwS+W8JzMDOzMVSW6sAR0SvpGuBuoADcHBHr\nJF2d1q8C7gIuAzYA7cC70+6zgTslDcT49Yj4QVp3PXCHpKuATcDlpToHMzMbm5Jphue3lpaWaG1t\nHbuhmZkNkrR2yOMXw5rMk+1mZlYGnEjMzCwXJxIzM8vFicTMzHJxIjEzs1ycSMzMLBcnEjMzy8WJ\nxMzMcnEiMTOzXJxIzMwsFycSMzPLxYnEzMxycSIxM7NcnEjMzCwXJ5IxnAjL7JuZ5eFEMoov/Ohx\n3vrP9090GGZmk5oTyShqqwo8sHE3T+9qn+hQzMwmLSeSUVy0eDYA9zy6fYIjMTObvEqaSCRdImm9\npA2SVg5TL0mfT+sfkvSytHyBpB9LelTSOkkfzvS5TtJWSQ+mr8tKFf+pMxs4a04T9zy6o1QfYWZW\n9kqWSCQVgBuAS4HFwBWSFg9pdimwKH2tAG5My3uBP4uIxcD5wAeG9P1sRCxJX3eV6hwALl48m9aN\nu9l1sKuUH2NmVrZKeUVyLrAhIp6MiG7gdmDpkDZLga9E4n5gmqS5EbEtIn4FEBEHgMeAeSWMdUQX\nv3gO/QH3/XbnRHy8mdmkV8pEMg/YnNnfwtHJYMw2kk4DzgF+mSn+YDoUdrOk6ccr4OG8+OQpzJtW\nxz3rPLxlZjacST3ZLqkR+DZwbUTsT4tvBE4HlgDbgE+P0HeFpFZJrW1tbXli4KLFs/np4220d/ce\n83HMzJ6vSplItgILMvvz07Ki2kiqIkkit0XEdwYaRMSOiOiLiH7gSyRDaEeJiJsioiUiWpqbm3Od\nyCVnz6Grt5+rbmnlt9v3j93BzOwEUspEsgZYJGmhpGpgObB6SJvVwDvTu7fOB/ZFxDZJAv4FeCwi\nPpPtIGluZvctwCOlO4XEeQtn8DfLzuax7fu57HM/5b1fbeWr929iw86D9Pf7yXczO7FVlurAEdEr\n6RrgbqAA3BwR6yRdndavAu4CLgM2AO3Au9PurwLeATws6cG07OPpHVqflLQECGAj8N5SncMASbzj\n/FN500vm8oUfbeCuh7dxdzpn0lBd4EVzp/D6xbO5vGUBMxqqSx2OmdmkohNhLamWlpZobW09bseL\nCDbuaueBp3bx6DP7eXDzXn6zZR/VlRW8+oxZzJ5SS3NTDWec1MhZc5o4fVYDlYVJPR1lZnYUSWsj\nomWsdiW7Ink+k8TCWQ0snNUwWLZ++wG+dv8mHnhqNw9t2cvuQ90MjHo11VbyqhfM4g/OnMVrFjWz\nYEb9BEVuZnb8OZEcJy+c08TfLDt7cL+7t58n2g7y2Lb9PPDUbn7yuzZ+sC5ZamXhrAbOnjeVFzQ3\ncHpzY/I+q5G66sJEhW9mdsw8tPUciQieaDvETx9v42cbnmX9jgNs2dPBwNcvweK5Uzj/9JmcObuR\nqXXVzJlay+/Nm0qhQhMau5mdmDy0NclI4oyTGjnjpEbe/aqFAHT29PHUs4d4su0Q63ccYM1Tu/na\n/Zvo6u0f7DersZqLFs/mzNlNzGqsYVZjDc1N1Zw0pZYptVUTdTpmZoOcSCZQbVVyx9eL5k7hDSR3\nNXf39vPswS72tvewoe0g96zbzr//ZhsHuzYf1f+sOU38waJZvHTBNOZNq2P+9HpmNVaT3D1tZvbc\n8NBWGejvD/a0d/PswW6ePdjFswe72LKng59teJbWjXvo7jt8BVNbVcG8aXWcMqOeU2c2cOrMek6d\nWc8pMxpYMKOOmkrPw5hZcTy09TxSUSFmNtYws7GGF9I0WP6BC86go7uPTbsPsWV3B1v2tLNlTwdb\n9nTw9O52HnhqN4e6+wbbS3Dy1CTJnDarnhc0N3LBWSfxgubGiTgtM3ue8BXJ81hEsOtQN5t2tbNp\n1yE27Wrn6d2Ht3cd6gbg9FkNnDm7ieamGk5qquGkKTWc1JQ8C9PcVMPMhmo/B2N2AvIViSFpcIL+\n5acevUjy1r0d3PfYDv5jfRtPtB3kF0/uYl9HzzDHgZkN1elEf/JadFITLz55CqfNbKCuukBDTYHa\nygIVvsPM7ITjKxI7QmdPH88e7GLngS7aMq/B/YNd7NjXyfb9ncP2r68uMLOxmnnT6pg3rZ550+uY\nN62WxpoqaqsqqKksUFtVQX11JQtnNfjZGbNJzFckdkxqqwrMn17P/OmjP32/t72bR5/ZzzP7Ouno\n7uVQdx/t3X20d/Wy80AXz+zt4OdPPMv2/Z2M9G8VCU6ZUc/cqcmtzDMaqpk/vY4FM+qZ2VDDtPoq\nptZVMa2+isaaSt+NZjZJOZHYMZlWX80rz5g1Zruevn527O/kUFcfXb19dPb009Xbx/6OXjbsPMjv\ndhyg7UAXT+9u51dP7+HZg93DHqdQIabVVTG1voqmmkoaaiqpr66ksaZAQ00lU+uSRNTcVMOCGfXM\nm1ZHQ00ldVUFP9BpVmJOJFZSVYWKMa9usjq6+9i6t53dh3rY297N3o4e9rX3sLejm73tPext7+FA\nVy/tXb3sae+gvbuXg5297O3ooW+EJf2rKyuoqypQX12grqpAXeZ9Wn01J0+t5aQptTRUH1lXU1mg\nsiCqCxU01lQypS65QnJiMjuSE4lNKnXVBc44qWnshkNEBPs7e9mxv5PNu9vZtq+T9u5eOrr7ae/p\npbO7j46eZPitM30/0NnL07vbuXtdJ92Z1QRGU1kh5kytZc6UWmqqKqgqVDCzoYaTp9VyUlMNU+qq\naKqtpKk2eZ+SvjdUV/pGBHveciKx5wVJTE2vGM6cPb5EFBHs6+ihPU02Hel7Z08fff1BT19woLOH\nfR09tKXzPzsPdNHV08/+jl7Wbz/Ajv2djPYbZxI01SQJprqyggolV2v11QXqqyvT9wL1NZXUVyXv\nA8N2jTVJImqoqaQhW5a2dYKyieZEYic8SUyrr2ZajtX9e/v62d3ezYHOXg509rK/oyfd7mF/Z8/h\n8s4eevqC/gi6e/vp6O6jvbuXZw92JTcrdPem731jfyhJgqqvOjK5NNQUMtvZRHS4PNu2siJ5Rqi6\nsoIptYeTnVmxnEjMjoPKQgUnNdVyDKNyw+rvDw6lSeVgVy+HunrT977M9kB5WtZ9uGzr3s5Mfe8R\nC4EWo66qQFNtknDq0qul2sw8U+0RrwpqqwbKK46sq6w4ul11gSbfhfe84kRiNglVVCidZ6li9nE4\nXm9fP4e6+gaTzeFE1Ed/en92V2/f4NXU/s5e9rX3cKi7N71qSup27u8aHPbr7Omjs7e/6PmlrNqq\nCmZPqaWhupJChShUiMr0fTBhDQz3VVcO3iwxOPQ3WF85uF1XVaCmsoKaNIF5NYbnjhOJ2QmgslDB\n1PoKptYf/58e6OuPwVu7j0gyPf1Hb/f20d7VR9vBLrbv66QjnYfq7Q/6+vvp6UsWKN26t29w2K+9\nu2/cV1SQ3DJeU1mRvpI78KoKFVQVRGVFBTVVFdRWJklo4GrpqDmrwe3kvaGmQF1VMiRYX13J9Poq\nJyxKnEgkXQJ8DigAX46I64fUK62/DGgH3hURvxqtr6QZwL8BpwEbgcsjYk8pz8PMRlaoUPoXbek+\no68/0rvuegdvhmjv7hu8Wmrv7qWzJ0k4XWnS6uo9/N7V20dvX9DTH/T09tPT1093X1K/80BPkgTT\n4x4ax1BghUjXo6s54sqorjpZMqgmTVDZhFZTldmuPJzQatKVHxprKpkztZbaqvJZ9aFkiURSAbgB\nuAjYAqyRtDoiHs00uxRYlL7OA24Ezhuj70rgvoi4XtLKdP+jpToPM5t4hQrRmN4k8FwYTFxdyRXR\nwBDfoe6+ZCWHriR5tR3sZvu+DnYd7KajJ5nPajuQDP91pQ/fDiS00e7qG05zUw1NtZVUF5LhuppC\nBdWVyasmfa8uDOwXjqjL1r/mzGZOnlZXmi8qVcr/KucCGyLiSQBJtwNLgWwiWQp8JZIFv+6XNE3S\nXJKrjZH6LgVem/a/FfgPnEjM7DgqReLq6etPr5gGrpKOvHIaGAI82NXLM3s72Lqng0PdydVRd/pq\n7+5lb8fh/WxdV9/w81W3vPsVZZ1I5gHZn/XbQnLVMVabeWP0nR0R29Lt7TD8XKSkFcCKdPegpPXj\njH8W8Ow4+0wmjn9ilXP85Rw7OP4jXPAPubqfWkyjsp5sj4iQNOwFY0TcBNx0rMeW1FrMqpeTleOf\nWOUcfzkKdKA0AAAGkElEQVTHDo5/IpTydoOtwILM/vy0rJg2o/XdkQ5/kb7vPI4xm5nZOJUykawB\nFklaKKkaWA6sHtJmNfBOJc4H9qXDVqP1XQ1cmW5fCXy3hOdgZmZjKNnQVkT0SroGuJvkFt6bI2Kd\npKvT+lXAXSS3/m4guf333aP1TQ99PXCHpKuATcDlJTqFYx4WmyQc/8Qq5/jLOXZw/M+5E+IXEs3M\nrHT8SKaZmeXiRGJmZrk4kQwh6RJJ6yVtSJ+cn9QkLZD0Y0mPSlon6cNp+QxJ90p6PH2fPtGxjkZS\nQdKvJX0v3S+b+NMHab8l6beSHpP0+2UW/5+m/+88Iukbkmonc/ySbpa0U9IjmbIR45X0sfTP83pJ\nfzQxUR82Qvz/mP7/85CkOyVNy9RNqviH40SSkVma5VJgMXCFpMUTG9WYeoE/i4jFwPnAB9KYB5aS\nWQTcl+5PZh8GHsvsl1P8nwN+EBFnAS8lOY+yiF/SPOBDQEtEnE1yc8tyJnf8twCXDCkbNt70z8Jy\n4MVpny+mf84n0i0cHf+9wNkR8RLgd8DHYNLGfxQnkiMNLusSEd3AwNIsk1ZEbBtY6DIiDpD8JTaP\nJO5b02a3AssmJsKxSZoPvAH4cqa4LOKXNBV4DfAvABHRHRF7KZP4U5VAnaRKoB54hkkcf0T8BNg9\npHikeJcCt0dEV0Q8RXKH6LnPSaAjGC7+iLgnInrT3ftJnp2DSRj/cJxIjjTSki1lQdJpwDnALyly\nKZlJ4p+AvwCyCwWVS/wLgTbgX9OhuS9LaqBM4o+IrcCngKeBbSTPct1DmcSfMVK85fhn+j3A99Pt\nsojfieR5QlIj8G3g2ojYn61LF8WclPd5S3ojsDMi1o7UZjLHT/Kv+ZcBN0bEOcAhhgwDTeb407mE\npSQJ8WSgQdLbs20mc/zDKbd4syR9gmS4+raJjmU8nEiOVMyyLpOOpCqSJHJbRHwnLS6XpWReBbxZ\n0kaSocTXSfoa5RP/FmBLRPwy3f8WSWIpl/hfDzwVEW0R0QN8B3gl5RP/gJHiLZs/05LeBbwReFsc\nfsCvLOJ3IjlSMcu6TCqSRDI+/1hEfCZTVRZLyUTExyJifkScRvJ9/ygi3k75xL8d2CzphWnRhSQ/\nd1AW8ZMMaZ0vqT79f+lCknm2col/wEjxrgaWS6qRtJDkt48emID4RqXkh/z+AnhzRLRnqsoifiLC\nr8yLZMmW3wFPAJ+Y6HiKiPfVJJfxDwEPpq/LgJkkd688DvwQmDHRsRZxLq8Fvpdul038wBKgNf1v\n8P+A6WUW/18DvwUeAb4K1Ezm+IFvkMzn9JBcEV41WrzAJ9I/z+uBSydp/BtI5kIG/gyvmqzxD/fy\nEilmZpaLh7bMzCwXJxIzM8vFicTMzHJxIjEzs1ycSMzMLBcnErNxSFf6fX9m/7UDKxaP0e8sSQ+m\ny6i84Bg+91pJ9ePtZ/ZccCIxG59pwPvHbHW0ZcC3IuKciHjiGPpfS7KgYtHSRRjNSs6JxIxkwcv0\nt0S+lP42xz2S6oZpej3wgvTq4h/TssbM75Hclj4hnj32ZSSJ4H2SfpyWvV3SA+lx/nlgaXBJN0pq\nTWP467TsQyTrYP040/9g5vh/IumWdPsWSask/RL4pKSG9PcvHkivhib1atZWnpxIzA5bBNwQES8G\n9gJ/PEyblcATEbEkIv48LTuHJFEsBk4nWT9sUETcBawCPhsRF0h6EfBW4FURsQToA96WNv9ERLQA\nLwH+UNJLIuLzJEu7XxARFxRxHvOBV0bE/yR5KvpHEXEucAHwj+nqxGbHjS99zQ57KiIeTLfXAqcV\n2e+BiNgCIOnBtN9/jtL+QuDlwJr04qWOw4sMXi5pBcmfzbkkyemh4k8BgG9GRF+6fTHJopgfSfdr\ngVM48kfEzHJxIjE7rCuz3UfyY08LgH9Py1YBPyii31h/rgTcGhEfO6IwWZTvI8ArImJPOlxVO8Ix\nsmsbDW1zaMhn/XFErB8jJrNj5qEts1FExOZ0GGtJRKwCDgBNOQ97H/Ankk6Cwd8bPxWYQpIE9kma\nTfKTzwOGfu4OSS+SVAG8ZZTPuhv44MC8jaRzcsZudhQnErNxiIhdwM8kPZKZbB/vMR4F/hK4R9JD\nJL/XPTcifgP8mmQl3q8DP8t0uwn4wcBkO8lczfeAn5OsJDuSvwGqgIckrUv3zY4rr/5rZma5+IrE\nzMxycSIxM7NcnEjMzCwXJxIzM8vFicTMzHJxIjEzs1ycSMzMLJf/D0kg6nwtA3GFAAAAAElFTkSu\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x113c612d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "X_train_fname = 'training_templates.csv'\n",
    "y_train_fname = 'training_labels.txt'\n",
    "X_test_fname  = 'testing_templates.csv'\n",
    "X_train = pd.read_csv(X_train_fname, sep=',', header=None).values\n",
    "X_test  = pd.read_csv(X_test_fname,  sep=',', header=None).values\n",
    "y_train = np.loadtxt(y_train_fname, dtype=np.int)\n",
    "\n",
    "X_train = preprocessing.scale(X_train)\n",
    "pca = PCA()  \n",
    "PCA_X = pca.fit_transform(X_train)\n",
    "ratio = pca.explained_variance_ratio_\n",
    "\n",
    "plt.figure(1)\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_title('Pourcentage d\\'inertie')\n",
    "ax.plot(np.linspace(1, ratio.shape[0], num=ratio.shape[0]), ratio)\n",
    "ax.set_xlabel(\"n-th feature\")\n",
    "ax.set_ylabel(\"Ratio\")\n",
    "plt.ylim(0, 0.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme l'on peut voir dans le graphe ci-dessus, le pourcentage d'inertie diminue prèsque linéairement. Donc il faut mieux garder tous les variables explicatives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Selection de classifieurs et de hyperparamètres\n",
    "\n",
    "Dans ce secteur, on va parler de tous les classifiers que l'on a essayé d'utiliser ainsi que les hyperparamètres que l'on a joué pendant GridSearch pour atteindre une meilleure performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Logistic Regression\n",
    "\n",
    "La régression logistique est un modèle linéaire de classifier au lieu de régression. \n",
    "La liste de hyperparamètres que l'on a joués pendant le processus de GridSearch est indiquée comme ci-dessus:\n",
    "\n",
    "<b>(a) solver: </b> \n",
    "Les solvers implementés dans la classe de LogisticRegression sont: “liblinear”, “newton-cg”, “lbfgs” and “sag“. Le solver \"liblinear\" utilise un algorithme de descente de coordonnées (CD). Les solvers “lbfgs”, “sag” and “newton-cg” ne supportent que la pénalité L2 et convergent plus rapidement pour certaines données de dimensions élevées. Mais pour notre cas, \"liblinear\" obtient une meilleure performance selon le résultat de GridSearch et validation croisée.\n",
    "\n",
    "<b>(b) C: </b>\n",
    "L'inverse de la force de régularisation. Comme pour SVM, les valeurs de C plus petites spécifient une régularisation plus forte.\n",
    "\n",
    "<p>Le résultat d'un LogisticRegression n'est pas satisfaisant puisque evidement la prédiction du genre d'une personne à partir de sa photo n'est pas un modèle linéaire.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Naive Bayes\n",
    "\n",
    "<p>Les méthodes Naive Bayes sont un ensemble d'algorithmes d'apprentissage supervisés basés sur l'application du théorème de Bayes avec l'hypothèse «naïve» d'indépendance entre chaque paire de fonctionnalités. </p>\n",
    "<p>Ce type de classifier n'est évidement pas adapté à notre cas. Parmi les trois types de Naive Bayes classifiers implémentés par sklearn, on n'a choisi le Gaussian Naive Bayes (GaussianNB), et le résultat obtenu n'est pas très satisfaisant.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 AdaBoost Classifier\n",
    "\n",
    "<p>Le principe de base d'AdaBoost est de s'adapter à une séquence de classifieurs faibles (c'est-à-dire des modèles qui ne sont que légèrement mieux que les hypothèses aléatoires, comme les arbres de décision) sur des versions modifiées à plusieurs reprises des données. Les prédictions de tous les classifieurs faibles sont ensuite combinées par un vote majoritaire pondéré (ou somme) pour produire la prédiction finale. </p>\n",
    "<p>Pour ce classifier, on a utilisé l'estimateur de base par défault.</p>\n",
    "\n",
    "<p>Le résultat obtenu par AdaBoost Classifier n'est pas très satisfaisant, les probablités prédictées sont toutes environ 0,5. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 GradientBoosting Classifier\n",
    "\n",
    "<p>GradientBoosting construit un modèle additif de manière étape par étape; Il permet l'optimisation de fonctions de perte différentiables arbitraires.</p>\n",
    "\n",
    "<p>Pour ce classifier, on a utilisé l'estimateur de base par défault, et la liste de hyperparamètres que l'on a joué pendant le processus de GridSearch est indiquée comme ci-dessous:</p>\n",
    "\n",
    "<b>(a) n_estimators:</b>\n",
    "\n",
    "Le nombre d'étapes de boosting à effectuer. L'augmentation progressive du gradient est assez robuste pour sur-apprentisage, de sorte qu'un grand nombre d'estimateurs entraîne généralement de meilleures performances. Le résultat de GridSearch a aussi prouvé que la perfomance de validation croisée d'un grand nombre d'estimateurs surpasse celle d'un petit nombre (n_estimators = 1000 au lieu de 100 ou 10).\n",
    "\n",
    "<b>(b) max_features:</b>\n",
    "\n",
    "Le nombre de features à considérer lors de la recherche de la meilleure split pour un arbre de regression.\n",
    "\n",
    "<b>(c) learning_rate:</b>\n",
    "\n",
    "Le taux d'apprentissage (learning rate) réduit la contribution de chaque classificateur par learning_rate. Il existe un compromis entre les niveaux d'apprentissage et les n_estimateurs\n",
    "\n",
    "En utilisant le meilleur classifieur trouvé par GridSearch, le score est très bien pour les données d'apprentissage (training data) mais pas satisfaisant pour le test, c'est à dire, ce classifieur a un problème de sur-apprentisage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 SVM\n",
    "\n",
    "<p>SVM est un classifieur que l'on a vu dans le cours. Comme le temps pour entraîner un classifieur SVM est très longue, on ne peut que mettre de côté $\\frac{2}{3}$ de données d'apprentisage (training data) pendant le processus de GridSearch pour trouver les paramètres. </p>\n",
    "<p>Le résultat obtenu par SVM est assez satisfaisant (environs 0.15), mais le temps requis pour entraîner un classifieur SVM peut restreindre l'utilisation de SVM. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 Random Forests\n",
    "\n",
    "Les forêts aléatoires (random forests) sont aussi un classifieur que l'on a vu dans ce cours. Bien que les forêts aléatoires soient souvent le champoin de chanllenges, on n'a pas réussi à trouver un classifieur de forêts aléatoires avec une performance assez satisfaisante."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.7 Neural Network (sklearn)\n",
    "\n",
    "<p>Un classifier de réseau neuronal supporté par sklearn le classifier Perceptron multicouche (Multi-layer Perceptron classifier). </p>\n",
    "\n",
    "<p>Un perceptron multicouches (MLP) est un modèle de réseau neuronal artificiel qui mappe les ensembles de données d'entrée sur un ensemble de sorties appropriées. Un MLP consiste en plusieurs couches de nœuds dans un graphe dirigé, chaque couche étant entièrement connectée à la suivante. Sauf pour les nœuds d'entrée, chaque nœud est un neurone avec une fonction d'activation non linéaire.</p>\n",
    "\n",
    "<p>Comme le classifier MLP ont une performance très satisfaisante pour notre challenge, on a fait de nombreuses explorations d’approfondissement sur ce classifier. La liste de hyperparamètres que l'on a joué pendant le processus de GridSearch est indiquée comme ci-dessous:</p>\n",
    "\n",
    "#### (a) hidden_layer_sizes\n",
    "\n",
    "<p>Pour un classifier MLP, le nombre de neurones d'entrées est le nombre de variables explicatives de données, et le nombre de neurones de sortie est 1, donc on peut seulement faire changer le nombre de couches cachées (hidden layer) et le nombre de neurones pour chaque couche cashée. Le ième élément de hidden_layer_sizes représente le nombre de neurones dans la ième couche cachée.</p>\n",
    "\n",
    "<p>On a essaiyé de nombreux hidden_layer_sizes différents: (128,),(256,),(512,),(1024,), etc, pour le cas d'une couche cachée; (128,64),(128,256), etc, pour le cas de deux couches cachées; (128,128,128),(256,256,256), etc, pour le cas de trois couches cachées. Le résultat s'avère que la performance de différents hidden_layer_sizes ne diffère pas beaucoup en combinant un alpha approprié tant que le structure de couches cachées est similaire</p>\n",
    "\n",
    "#### (b) activation\n",
    "\n",
    "<p>La fonction d'activation pour les couches cachées. \n",
    "La fonction d'activation contrôle la non-linéarité des neurones individuels et le moment pour terminer. </p>\n",
    "<p>Pour un MLP de sklearn, on ne peut seulement choisir qu'une même fonction d'activation pour tous les couches cachées. Au vue de résultats de GridSearch et validation croisée, la performance de fonction 'relu' surpasse celles d'autres pour notre challenge.</p>\n",
    "\n",
    "#### (c) solver\n",
    "\n",
    "<p>Le solveur pour l'optimisation du poids.</p>\n",
    "\n",
    "<p>Le solveur SGD (Stochastic gradient descent) est le plus étudié solveur parmi les autres solveurs supportés par sklearn. L'algorithme de sgd est intuitif. La vitesse de convergence de sgd depend beaucoup du taux d'apprentisage (learning rate). Et on peut facilement trouver un minimum local en utilisant sgd.</p>\n",
    "\n",
    "<p>Le solveur Adam (Adaptive Moment Estimation) est une méthode qui calcule les taux d'apprentissage adaptatifs pour chaque paramètre. En plus de stocker une moyenne exponentiellement en décomposition des gradients carrés précédents, Adam conserve également une moyenne exponentiellement en décomposition des gradients précédents, similaire à le momentum.</p> \n",
    "\n",
    "<p>Adam est plus rapide que SGD et le résultat de GridSearch et validation croisée s'avère que Adam obtient aussi une preformance meilleure que SGD.</p>\n",
    "\n",
    "#### (d) alpha\n",
    "\n",
    "<p>Paramètre de pénalisation pour la pénalité L2. Différents valeurs d'alpha peut avoir une grande influence sur la performance. Au vue de résultats de GridSearch et validation croisée, la valeur d'alpha augemente quand le nombre de couchés cachées augemente.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.8 Neural Network (Keras)\n",
    "\n",
    "<p>Du fait qu'il y a des contraintes de MLP supporté par sklearn, on a fait des premières tentatives d'utiliser un autre module de Python: Keras. Keras est une bibliothèque d'apprentissage en profondeur (deep learning) Python qui offre un accès facile et pratique aux puissantes bibliothèques numériques Theano et TensorFlow. Pour profiter la fonction de GridSearch de sklearn et régler les hyperparamètres des modèles de Keras, la bibliothèque Keras fournit une enveloppe pratique à utiliser comme estimateurs de classifiers dans sklearn. </p>\n",
    "\n",
    "<p>La liste de hyperparamètres que l'on a joué est indiquée comme ci-dessous:</p>\n",
    "\n",
    "#### (a) Epochs\n",
    "\n",
    "Une des différences entre sklearn et Keras est que, l'apprentissage de classifier de sklearn termine quand la perte de deux epochs consécutif n'améliore pas mais celui de Keras termine quand un nombre maximum d'epochs est atteint.\n",
    "\n",
    "#### (b) Fonction d'activation\n",
    "\n",
    "En utilisant Keras, on peut choisir des différentes fonctions d'activation pour différente couche.\n",
    "\n",
    "#### (c) Dropout\n",
    "\n",
    "Dropout est une technique de régularisation simple et puissante pour les réseaux de neurones et les modèles d'apprentissage en profondeur (deep learning). C'est une technique où des neurones sélectionnés au hasard sont ignorés pendant l'entraînement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.9 Bagging\n",
    "\n",
    "<p>Bagging est un classifier que l'on a vu en cours, qui s'adapte aux classifiers de base chacun sur des sous-ensembles aléatoires de données d'origine, puis agrège leurs prédictions individuelles pour former une prédiction finale</p>\n",
    "\n",
    "<p>En combinant des MLPClassifiers par Bagging, on a obtenu les meilleures performances par rapport aux autres classifiers que l'on a essayé de jouer. Mais un seule MLPClassifier dont performance surpasse les autres ne guarantie pas une performance aussi satifaisante quand il est combiné dans un classifier Baggings. Généralement, la valeur d'alpha de MLPClassifier devient beaucoup plus petite si l'on veut obtenir un meilleur résultat dans Bagging. Ainsi si le nombre d'estimateurs combinés dans Baggings est assez grand, on peut diminuer le hyperparamètre 'max_features' du classifier Bagging pour obtenir un meilleur résultat.</p>\n",
    "\n",
    "<p>Au vu que le temps pour entraîner un classifier Baggings est relativement longue, c'est pas très pratique d'utiliser GridSearch.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Prédiction de 0\n",
    "\n",
    "Génaralement, un classifier ne prédit pas une nouvelle classe qui a jamais appraître dans les données d'apprentisage (training data.). Mais prèsque tous les classifieurs de sklearn ont proposé une méthode 'predict_proba()' (sauf pour SVM, on doit d'abord mettre le hyperparamètre 'probability' à True avant l'entraînement) qui nous donne les probabilités qu'une donées soit prédit correctement. On met à zéro les prédictions qui ont une probabilité faible d'être correcte."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Conclusion\n",
    "\n",
    "<p>Le classifier retenu à la fin un Bagging combinant 200 MLPClassifiers. Les hyperparamètres pour MLPClassifier sont:\n",
    "alpha=0.000001, hidden_layer_sizes=(128,128,128), tol=0.00001, random_state=42; Les hyperparamètres pour BaggingClassifier sont: n_estimators=200,max_samples=0.4,max_features=0.7. Et le meilleur résultat obtenu est 0.125235404896 (18 ème position).</p>\n",
    "\n",
    "<p> Ce challenge nous offre une opportunité de trouver le meilleur classifier pour un problème réel. Le processus de trouver des meilleurs hyperparamètres requiert beaucoup de travail et de patience. Mais on peut accéder aux GPU pour accélérer la formation des modèles de machine learning (surtout deep learning) en utilisant l'infrastructure Amazon Web Service (AWS).</p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
