{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prédiction du genre d'une personne à partir de sa photo\n",
    "## MLPClassifier\n",
    "\n",
    "auteur : Rui SONG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Imports and initializations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Critere de performance\n",
    "def compute_pred_score(y_true, y_pred):\n",
    "    y_pred_unq =  np.unique(y_pred)\n",
    "    for i in y_pred_unq:\n",
    "        if((i != -1) & (i!= 1) & (i!= 0) ):\n",
    "            raise ValueError('The predictions can contain only -1, 1, or 0!')\n",
    "    y_comp = y_true * y_pred\n",
    "    score = float(10*np.sum(y_comp == -1) + np.sum(y_comp == 0))\n",
    "    score /= y_comp.shape[0]\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "X_train_fname = 'training_templates.csv'\n",
    "y_train_fname = 'training_labels.txt'\n",
    "X_test_fname  = 'testing_templates.csv'\n",
    "X_train = pd.read_csv(X_train_fname, sep=',', header=None).values\n",
    "X_test  = pd.read_csv(X_test_fname,  sep=',', header=None).values\n",
    "y_train = np.loadtxt(y_train_fname, dtype=np.int)\n",
    "\n",
    "X_scaler = StandardScaler()\n",
    "X_train = X_scaler.fit_transform(X_train)\n",
    "X_test = X_scaler.transform(X_test)\n",
    "\n",
    "pca=PCA()\n",
    "X_train = pca.fit_transform(X_train)\n",
    "X_test = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done   2 out of   8 | elapsed: 57.6min remaining: 172.9min\n",
      "[Parallel(n_jobs=8)]: Done   8 out of   8 | elapsed: 58.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.24466965\n",
      "Iteration 1, loss = 0.22263408\n",
      "Iteration 1, loss = 0.20872654\n",
      "Iteration 1, loss = 0.19861797\n",
      "Iteration 1, loss = 0.24739606\n",
      "Iteration 1, loss = 0.23217069\n",
      "Iteration 1, loss = 0.20820480\n",
      "Iteration 1, loss = 0.21519995\n",
      "Iteration 2, loss = 0.11650499Iteration 2, loss = 0.10664965Iteration 2, loss = 0.09249039Iteration 2, loss = 0.08929391Iteration 2, loss = 0.11511323Iteration 2, loss = 0.11000715Iteration 2, loss = 0.10022390Iteration 2, loss = 0.09782420\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 3, loss = 0.09114932Iteration 3, loss = 0.08412937Iteration 3, loss = 0.07062699Iteration 3, loss = 0.06805765Iteration 3, loss = 0.08919192Iteration 3, loss = 0.08555718Iteration 3, loss = 0.07881571Iteration 3, loss = 0.07575546\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 4, loss = 0.07604077Iteration 4, loss = 0.07040131Iteration 4, loss = 0.05787565Iteration 4, loss = 0.05525515Iteration 4, loss = 0.07451969Iteration 4, loss = 0.07145912Iteration 4, loss = 0.06553002Iteration 4, loss = 0.06327949\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 5, loss = 0.06449565Iteration 5, loss = 0.05973783Iteration 5, loss = 0.04852082Iteration 5, loss = 0.04609703Iteration 5, loss = 0.06263238Iteration 5, loss = 0.06085164Iteration 5, loss = 0.05535100Iteration 5, loss = 0.05306557\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 6, loss = 0.05548472Iteration 6, loss = 0.05103689Iteration 6, loss = 0.04083177Iteration 6, loss = 0.03906583Iteration 6, loss = 0.05371374Iteration 6, loss = 0.05151663Iteration 6, loss = 0.04683687Iteration 6, loss = 0.04530535\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 7, loss = 0.04843319Iteration 7, loss = 0.04430092Iteration 7, loss = 0.03389127Iteration 7, loss = 0.03299535Iteration 7, loss = 0.04652630Iteration 7, loss = 0.04417240Iteration 7, loss = 0.04052687Iteration 7, loss = 0.03870915\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 8, loss = 0.04125794Iteration 8, loss = 0.03724746Iteration 8, loss = 0.02884688Iteration 8, loss = 0.02729779Iteration 8, loss = 0.04003611Iteration 8, loss = 0.03782774Iteration 8, loss = 0.03500652Iteration 8, loss = 0.03294883\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 9, loss = 0.03585544Iteration 9, loss = 0.03258390Iteration 9, loss = 0.02425066Iteration 9, loss = 0.02294936Iteration 9, loss = 0.03389511Iteration 9, loss = 0.03326011Iteration 9, loss = 0.02991187Iteration 9, loss = 0.02791792\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 10, loss = 0.03125057Iteration 10, loss = 0.02768876Iteration 10, loss = 0.02017798Iteration 10, loss = 0.01899014Iteration 10, loss = 0.02954781Iteration 10, loss = 0.02758280Iteration 10, loss = 0.02588102Iteration 10, loss = 0.02399577\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 11, loss = 0.02648599Iteration 11, loss = 0.02410422Iteration 11, loss = 0.01745676Iteration 11, loss = 0.01536990Iteration 11, loss = 0.02478814Iteration 11, loss = 0.02403503Iteration 11, loss = 0.02146599Iteration 11, loss = 0.01982277\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 12, loss = 0.02313825Iteration 12, loss = 0.02025746Iteration 12, loss = 0.01441642Iteration 12, loss = 0.01333552Iteration 12, loss = 0.02124191Iteration 12, loss = 0.01995414Iteration 12, loss = 0.01854711Iteration 12, loss = 0.01680198\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 13, loss = 0.01955541Iteration 13, loss = 0.01708915Iteration 13, loss = 0.01184295Iteration 13, loss = 0.01088260Iteration 13, loss = 0.01791934Iteration 13, loss = 0.01723783Iteration 13, loss = 0.01533752Iteration 13, loss = 0.01378627\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 14, loss = 0.01695032Iteration 14, loss = 0.01426132Iteration 14, loss = 0.00919124Iteration 14, loss = 0.00823290Iteration 14, loss = 0.01506469Iteration 14, loss = 0.01457883Iteration 14, loss = 0.01261647Iteration 14, loss = 0.01148004\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 15, loss = 0.01391782Iteration 15, loss = 0.01216677Iteration 15, loss = 0.00755984Iteration 15, loss = 0.00667306Iteration 15, loss = 0.01271776Iteration 15, loss = 0.01202408Iteration 15, loss = 0.01107063Iteration 15, loss = 0.00964180\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 16, loss = 0.01186877Iteration 16, loss = 0.00961153Iteration 16, loss = 0.00602976Iteration 16, loss = 0.00534658Iteration 16, loss = 0.01068714Iteration 16, loss = 0.01019219Iteration 16, loss = 0.00902022Iteration 16, loss = 0.00789543\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 17, loss = 0.01019030Iteration 17, loss = 0.00801565Iteration 17, loss = 0.00532319Iteration 17, loss = 0.00477635Iteration 17, loss = 0.00909890Iteration 17, loss = 0.00847039Iteration 17, loss = 0.00765972Iteration 17, loss = 0.00620209"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(512,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=42, shuffle=True,\n",
       "       solver='adam', tol=1e-05, validation_fraction=0.1, verbose=True,\n",
       "       warm_start=False),\n",
       "         bootstrap=True, bootstrap_features=False, max_features=0.7,\n",
       "         max_samples=0.5, n_estimators=200, n_jobs=-1, oob_score=False,\n",
       "         random_state=None, verbose=True, warm_start=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 18, loss = 0.00844444Iteration 18, loss = 0.00701174Iteration 18, loss = 0.00474030Iteration 18, loss = 0.00412760Iteration 18, loss = 0.00781096Iteration 18, loss = 0.00713000Iteration 18, loss = 0.00590620Iteration 18, loss = 0.00497438\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 19, loss = 0.00696232Iteration 19, loss = 0.00532093Iteration 19, loss = 0.00400489Iteration 19, loss = 0.00340345Iteration 19, loss = 0.00680863Iteration 19, loss = 0.00593129Iteration 19, loss = 0.00474508Iteration 19, loss = 0.00429195\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 20, loss = 0.00604174Iteration 20, loss = 0.00440165Iteration 20, loss = 0.00327240Iteration 20, loss = 0.00261706Iteration 20, loss = 0.00603619Iteration 20, loss = 0.00508348Iteration 20, loss = 0.00453022Iteration 20, loss = 0.00334041\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 21, loss = 0.00601741Iteration 21, loss = 0.00377401Iteration 21, loss = 0.00335984Iteration 21, loss = 0.00257778Iteration 21, loss = 0.00549639Iteration 21, loss = 0.00437137Iteration 21, loss = 0.00325708Iteration 21, loss = 0.00298155\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 22, loss = 0.00432208Iteration 22, loss = 0.00330455Iteration 22, loss = 0.00303740Iteration 22, loss = 0.00206093Iteration 22, loss = 0.00480233Iteration 22, loss = 0.00391134Iteration 22, loss = 0.00257181Iteration 22, loss = 0.00249475\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 23, loss = 0.00330859Iteration 23, loss = 0.00287263Iteration 23, loss = 0.00263646Iteration 23, loss = 0.00210375Iteration 23, loss = 0.00352827Iteration 23, loss = 0.00270128Iteration 23, loss = 0.00226955Iteration 23, loss = 0.00199731\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 24, loss = 0.00305841Iteration 24, loss = 0.00243898Iteration 24, loss = 0.00324322Iteration 24, loss = 0.00185642Iteration 24, loss = 0.00350327Iteration 24, loss = 0.00215072Iteration 24, loss = 0.00184447Iteration 24, loss = 0.00165888\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 25, loss = 0.00255843Iteration 25, loss = 0.00189493Iteration 25, loss = 0.00742934Iteration 25, loss = 0.00143730Iteration 25, loss = 0.00255003Iteration 25, loss = 0.00188769Iteration 25, loss = 0.00158510Iteration 25, loss = 0.00133820\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 26, loss = 0.00212871Iteration 26, loss = 0.00158413Iteration 26, loss = 0.01142515Iteration 26, loss = 0.00111053Iteration 26, loss = 0.00252932Iteration 26, loss = 0.00176362Iteration 26, loss = 0.00129396Iteration 26, loss = 0.00117172\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 27, loss = 0.00178256Iteration 27, loss = 0.00123389Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "Iteration 27, loss = 0.00136084Iteration 27, loss = 0.00383387Iteration 27, loss = 0.00147925Iteration 27, loss = 0.00117139Iteration 27, loss = 0.00097688\n",
      "\n",
      "Iteration 1, loss = 0.19690475\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 28, loss = 0.00146626Iteration 28, loss = 0.00102959\n",
      "Iteration 28, loss = 0.00489685Iteration 28, loss = 0.01994560Iteration 28, loss = 0.00138131Iteration 28, loss = 0.00096847Iteration 28, loss = 0.00084483\n",
      "\n",
      "Iteration 2, loss = 0.09267901\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 29, loss = 0.00122900Iteration 29, loss = 0.00088501\n",
      "Iteration 29, loss = 0.01945249Iteration 29, loss = 0.00840186Iteration 29, loss = 0.00118451Iteration 29, loss = 0.00082976Iteration 29, loss = 0.00072103\n",
      "\n",
      "Iteration 3, loss = 0.07236366\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 30, loss = 0.00108054Iteration 30, loss = 0.00076637\n",
      "Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "Iteration 30, loss = 0.02987639Iteration 30, loss = 0.00076969Iteration 30, loss = 0.00066387\n",
      "\n",
      "Iteration 4, loss = 0.05933496Iteration 1, loss = 0.19978512Iteration 1, loss = 0.25622732\n",
      "\n",
      "\n",
      "Iteration 31, loss = 0.00087670Iteration 31, loss = 0.00070310\n",
      "\n",
      "\n",
      "Iteration 31, loss = 0.00936333Iteration 31, loss = 0.00204807Iteration 31, loss = 0.00065464\n",
      "\n",
      "Iteration 5, loss = 0.05051450Iteration 2, loss = 0.09279713Iteration 2, loss = 0.12149209\n",
      "\n",
      "\n",
      "Iteration 32, loss = 0.00080749Iteration 32, loss = 0.00067922\n",
      "\n",
      "\n",
      "Iteration 32, loss = 0.00265646Iteration 32, loss = 0.03393441Iteration 32, loss = 0.02562127\n",
      "\n",
      "Iteration 6, loss = 0.04239371Iteration 3, loss = 0.07215599Iteration 3, loss = 0.09426954\n",
      "\n",
      "\n",
      "Iteration 33, loss = 0.00076163Iteration 33, loss = 0.00086094\n",
      "\n",
      "\n",
      "Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "Iteration 33, loss = 0.00564261Iteration 33, loss = 0.01207579\n",
      "\n",
      "Iteration 7, loss = 0.03669658Iteration 4, loss = 0.05865802Iteration 4, loss = 0.07863422Iteration 1, loss = 0.18685833\n",
      "\n",
      "Iteration 34, loss = 0.00070280Iteration 34, loss = 0.03964581\n",
      "\n",
      "\n",
      "\n",
      "Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "\n",
      "\n",
      "Iteration 8, loss = 0.03110445Iteration 5, loss = 0.04952720Iteration 5, loss = 0.06759940Iteration 2, loss = 0.08400799Iteration 1, loss = 0.20445741Iteration 1, loss = 0.21565377Iteration 35, loss = 0.04042245Iteration 35, loss = 0.00687342\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 9, loss = 0.02644304Iteration 6, loss = 0.04096256Iteration 6, loss = 0.05860878Iteration 3, loss = 0.06364616Iteration 2, loss = 0.09611145Iteration 2, loss = 0.10559884Iteration 36, loss = 0.00868626Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 1, loss = 0.26314658Iteration 10, loss = 0.02275048Iteration 7, loss = 0.03504865Iteration 7, loss = 0.05125136Iteration 4, loss = 0.05222035Iteration 3, loss = 0.07393768Iteration 3, loss = 0.08280993Iteration 37, loss = 0.00216249\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 2, loss = 0.12130816Iteration 11, loss = 0.01925536Iteration 8, loss = 0.02898539Iteration 8, loss = 0.04414595Iteration 5, loss = 0.04285469Iteration 4, loss = 0.06010949Iteration 4, loss = 0.06838588Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 1, loss = 0.21636471Iteration 3, loss = 0.09591442Iteration 12, loss = 0.01546259Iteration 9, loss = 0.02471233Iteration 9, loss = 0.03849711Iteration 6, loss = 0.03636116Iteration 5, loss = 0.05089954Iteration 5, loss = 0.05808174\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 2, loss = 0.09805982Iteration 4, loss = 0.07983565Iteration 13, loss = 0.01297946Iteration 10, loss = 0.02058518Iteration 10, loss = 0.03431598Iteration 7, loss = 0.03047082Iteration 6, loss = 0.04283030Iteration 6, loss = 0.04981997\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 3, loss = 0.07532815Iteration 5, loss = 0.06910695Iteration 14, loss = 0.01091616Iteration 11, loss = 0.01747050Iteration 11, loss = 0.02902159Iteration 8, loss = 0.02467788Iteration 7, loss = 0.03617901Iteration 7, loss = 0.04286679\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 4, loss = 0.06188403Iteration 6, loss = 0.05981891Iteration 15, loss = 0.00886428Iteration 12, loss = 0.01402717Iteration 12, loss = 0.02538078Iteration 9, loss = 0.02118242Iteration 8, loss = 0.03008721Iteration 8, loss = 0.03725361\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 5, loss = 0.05258750Iteration 7, loss = 0.05205288Iteration 16, loss = 0.00718774Iteration 13, loss = 0.01136889Iteration 13, loss = 0.02171663Iteration 10, loss = 0.01748050Iteration 9, loss = 0.02561957Iteration 9, loss = 0.03178500\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 6, loss = 0.04375617Iteration 8, loss = 0.04572931Iteration 17, loss = 0.00572942Iteration 14, loss = 0.00960776Iteration 14, loss = 0.01888387Iteration 11, loss = 0.01434895Iteration 10, loss = 0.02149659Iteration 10, loss = 0.02651084\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 7, loss = 0.03781318Iteration 9, loss = 0.03993819Iteration 18, loss = 0.00457772Iteration 15, loss = 0.00751682Iteration 15, loss = 0.01565136Iteration 12, loss = 0.01206802Iteration 11, loss = 0.01743325Iteration 11, loss = 0.02290834\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 8, loss = 0.03206974Iteration 10, loss = 0.03522158Iteration 19, loss = 0.00379820Iteration 16, loss = 0.00643278Iteration 16, loss = 0.01368529Iteration 13, loss = 0.00925210Iteration 12, loss = 0.01477251Iteration 12, loss = 0.01978950\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 9, loss = 0.02691163Iteration 11, loss = 0.02947865Iteration 20, loss = 0.00333371Iteration 17, loss = 0.00530621Iteration 17, loss = 0.01177276Iteration 14, loss = 0.00765785Iteration 13, loss = 0.01209678Iteration 13, loss = 0.01595445\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 10, loss = 0.02265012Iteration 12, loss = 0.02633518Iteration 21, loss = 0.00281419Iteration 18, loss = 0.00388980Iteration 18, loss = 0.00981726Iteration 15, loss = 0.00601383Iteration 14, loss = 0.01003909Iteration 14, loss = 0.01301363\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 11, loss = 0.01935227Iteration 13, loss = 0.02293732Iteration 22, loss = 0.00288521Iteration 19, loss = 0.00312868Iteration 19, loss = 0.00884489Iteration 16, loss = 0.00506364Iteration 15, loss = 0.00818399Iteration 15, loss = 0.01089133\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "#np.random.seed(45)\n",
    "clf = MLPClassifier(alpha=0.00001, hidden_layer_sizes=(512,), verbose=True, tol=0.00001, random_state=42)\n",
    "bagging = BaggingClassifier(base_estimator=clf,n_estimators=200,max_samples=0.5,max_features=0.7,verbose=True, n_jobs=-1)\n",
    "\n",
    "bagging.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 12, loss = 0.01604877Iteration 14, loss = 0.01951965Iteration 23, loss = 0.00217606Iteration 20, loss = 0.00260625Iteration 20, loss = 0.00766180Iteration 17, loss = 0.00391409Iteration 16, loss = 0.00663619Iteration 16, loss = 0.00934955\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 13, loss = 0.01325540Iteration 15, loss = 0.01688500Iteration 24, loss = 0.00159694Iteration 21, loss = 0.00215029Iteration 21, loss = 0.00637521Iteration 18, loss = 0.00319785Iteration 17, loss = 0.00542405Iteration 17, loss = 0.00806085\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 14, loss = 0.01124157Iteration 16, loss = 0.01411915Iteration 25, loss = 0.00139429Iteration 22, loss = 0.00170039Iteration 22, loss = 0.00555298Iteration 19, loss = 0.00261513Iteration 18, loss = 0.00468519Iteration 18, loss = 0.00671425\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 15, loss = 0.00911780Iteration 17, loss = 0.01200772Iteration 26, loss = 0.00108962Iteration 23, loss = 0.00147229Iteration 23, loss = 0.00422982Iteration 20, loss = 0.00204917Iteration 19, loss = 0.00438394Iteration 19, loss = 0.00545715\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 16, loss = 0.00765817Iteration 18, loss = 0.00993678Iteration 27, loss = 0.00084584Iteration 24, loss = 0.00122735Iteration 24, loss = 0.00443065Iteration 21, loss = 0.00163450Iteration 20, loss = 0.00372879Iteration 20, loss = 0.00445652\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 17, loss = 0.00607222Iteration 19, loss = 0.00859231Iteration 28, loss = 0.00071022Iteration 25, loss = 0.00116273Iteration 25, loss = 0.00493463Iteration 22, loss = 0.00132243Iteration 21, loss = 0.00305967Iteration 21, loss = 0.00424208\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 18, loss = 0.00514104Iteration 20, loss = 0.00756893Iteration 29, loss = 0.00063638Iteration 26, loss = 0.00114644Iteration 26, loss = 0.00605318Iteration 23, loss = 0.00111195Iteration 22, loss = 0.00325484Iteration 22, loss = 0.00328370\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 19, loss = 0.00430235Iteration 21, loss = 0.00672912Iteration 30, loss = 0.00057425Iteration 27, loss = 0.00217653Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "Iteration 24, loss = 0.00094162Iteration 23, loss = 0.00258329Iteration 23, loss = 0.00289808\n",
      "\n",
      "\n",
      "\n",
      "Iteration 1, loss = 0.20058243\n",
      "\n",
      "\n",
      "Iteration 20, loss = 0.00332818Iteration 22, loss = 0.00627205Iteration 31, loss = 0.00052842Iteration 28, loss = 0.02525736\n",
      "Iteration 25, loss = 0.00079246Iteration 24, loss = 0.00286743Iteration 24, loss = 0.00248263\n",
      "\n",
      "\n",
      "\n",
      "Iteration 2, loss = 0.09414660\n",
      "\n",
      "\n",
      "Iteration 21, loss = 0.00270548Iteration 23, loss = 0.00477690Iteration 32, loss = 0.00045690Iteration 29, loss = 0.00557303\n",
      "Iteration 26, loss = 0.00070364Iteration 25, loss = 0.01227731Iteration 25, loss = 0.00298073\n",
      "\n",
      "\n",
      "\n",
      "Iteration 3, loss = 0.07262402\n",
      "\n",
      "\n",
      "Iteration 22, loss = 0.00218454Iteration 24, loss = 0.00420563Iteration 33, loss = 0.00037827Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "\n",
      "Iteration 27, loss = 0.00063512Iteration 26, loss = 0.01103367Iteration 26, loss = 0.01433882\n",
      "\n",
      "\n",
      "Iteration 1, loss = 0.26731561Iteration 4, loss = 0.05945223\n",
      "\n",
      "\n",
      "Iteration 23, loss = 0.00184160Iteration 25, loss = 0.00439557Iteration 34, loss = 0.00034361\n",
      "\n",
      "Iteration 28, loss = 0.00060787Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "Iteration 27, loss = 0.01050179\n",
      "\n",
      "\n",
      "Iteration 2, loss = 0.12663004Iteration 5, loss = 0.04948092\n",
      "Iteration 1, loss = 0.21555104\n",
      "Iteration 24, loss = 0.00159415Iteration 26, loss = 0.00374724Iteration 35, loss = 0.00032966\n",
      "\n",
      "Iteration 29, loss = 0.00056642\n",
      "Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "\n",
      "\n",
      "\n",
      "Iteration 3, loss = 0.10023313Iteration 6, loss = 0.04180558\n",
      "Iteration 2, loss = 0.09754015Iteration 1, loss = 0.23115663Iteration 25, loss = 0.00150786Iteration 27, loss = 0.00300297Iteration 36, loss = 0.00029263\n",
      "\n",
      "Iteration 30, loss = 0.02082272\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 4, loss = 0.08400895Iteration 7, loss = 0.03611704\n",
      "Iteration 3, loss = 0.07457332Iteration 2, loss = 0.11356179Iteration 26, loss = 0.00147357Iteration 28, loss = 0.00463688Iteration 37, loss = 0.00025027\n",
      "\n",
      "Iteration 31, loss = 0.01350555\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 5, loss = 0.07262367Iteration 8, loss = 0.02960649\n",
      "Iteration 4, loss = 0.06094022Iteration 3, loss = 0.08745503Iteration 27, loss = 0.00945381Iteration 29, loss = 0.01243140Iteration 38, loss = 0.00021724\n",
      "\n",
      "Iteration 32, loss = 0.00270968\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 6, loss = 0.06248462Iteration 9, loss = 0.02440826\n",
      "Iteration 5, loss = 0.05140971Iteration 4, loss = 0.07177820Iteration 28, loss = 0.02059080Iteration 30, loss = 0.01040588Iteration 39, loss = 0.00170631\n",
      "\n",
      "Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 7, loss = 0.05433907Iteration 10, loss = 0.02078180Iteration 1, loss = 0.23633678Iteration 6, loss = 0.04277748Iteration 5, loss = 0.06052584Iteration 29, loss = 0.00538327Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "Iteration 40, loss = 0.03856608\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 1, loss = 0.28041366\n",
      "Iteration 8, loss = 0.04763551Iteration 11, loss = 0.01694199Iteration 2, loss = 0.10680861Iteration 7, loss = 0.03705072Iteration 6, loss = 0.05138483Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "\n",
      "Iteration 41, loss = 0.00495771\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 1, loss = 0.20575897Iteration 2, loss = 0.14014624\n",
      "Iteration 9, loss = 0.04188903Iteration 12, loss = 0.01390110Iteration 3, loss = 0.08177184Iteration 8, loss = 0.03112847Iteration 7, loss = 0.04424116\n",
      "\n",
      "Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 2, loss = 0.08996856Iteration 3, loss = 0.11229753Iteration 1, loss = 0.19793533Iteration 10, loss = 0.03662794Iteration 13, loss = 0.01223611Iteration 4, loss = 0.06793296Iteration 9, loss = 0.02636472Iteration 8, loss = 0.03777874\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 3, loss = 0.06796601Iteration 4, loss = 0.09569950Iteration 2, loss = 0.08854242Iteration 11, loss = 0.03164630Iteration 14, loss = 0.00981796Iteration 5, loss = 0.05701240Iteration 10, loss = 0.02229814Iteration 9, loss = 0.03269198\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 4, loss = 0.05455998Iteration 5, loss = 0.08322428Iteration 3, loss = 0.06733318Iteration 12, loss = 0.02797860Iteration 15, loss = 0.00769323Iteration 6, loss = 0.04884765Iteration 11, loss = 0.01887637Iteration 10, loss = 0.02747950\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 5, loss = 0.04530100Iteration 6, loss = 0.07453874Iteration 4, loss = 0.05499229Iteration 13, loss = 0.02409835Iteration 16, loss = 0.00651967Iteration 7, loss = 0.04185248Iteration 12, loss = 0.01576536Iteration 11, loss = 0.02386514\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 6, loss = 0.03775467Iteration 7, loss = 0.06493837Iteration 5, loss = 0.04513561Iteration 14, loss = 0.02084956Iteration 17, loss = 0.00553280Iteration 8, loss = 0.03561014Iteration 13, loss = 0.01352121Iteration 12, loss = 0.02024618\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 7, loss = 0.03162607Iteration 8, loss = 0.05839802Iteration 6, loss = 0.03784114Iteration 15, loss = 0.01744163Iteration 18, loss = 0.00458741Iteration 9, loss = 0.03126719Iteration 14, loss = 0.01123849Iteration 13, loss = 0.01690202\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 8, loss = 0.02634659Iteration 9, loss = 0.05228325Iteration 7, loss = 0.03124933Iteration 16, loss = 0.01522883Iteration 19, loss = 0.00388243Iteration 10, loss = 0.02672677Iteration 15, loss = 0.00970280Iteration 14, loss = 0.01460061\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 9, loss = 0.02172704Iteration 10, loss = 0.04632575Iteration 8, loss = 0.02616504Iteration 17, loss = 0.01280297Iteration 20, loss = 0.00350861Iteration 11, loss = 0.02265685Iteration 16, loss = 0.00795872Iteration 15, loss = 0.01205962\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 10, loss = 0.01813759Iteration 11, loss = 0.04168122Iteration 9, loss = 0.02226496Iteration 18, loss = 0.01196814Iteration 21, loss = 0.00280631Iteration 12, loss = 0.01951434Iteration 17, loss = 0.00631268Iteration 16, loss = 0.01014866\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 11, loss = 0.01484272Iteration 12, loss = 0.03722549Iteration 10, loss = 0.01798683Iteration 19, loss = 0.01007922Iteration 22, loss = 0.00246058Iteration 13, loss = 0.01544052Iteration 18, loss = 0.00525086Iteration 17, loss = 0.00839017\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 12, loss = 0.01162569Iteration 13, loss = 0.03200588Iteration 11, loss = 0.01456350Iteration 20, loss = 0.00827289Iteration 23, loss = 0.00247571Iteration 14, loss = 0.01335051Iteration 19, loss = 0.00477728Iteration 18, loss = 0.00707193\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 13, loss = 0.00940062Iteration 14, loss = 0.02913877Iteration 12, loss = 0.01254671Iteration 21, loss = 0.00713281Iteration 24, loss = 0.00163465Iteration 15, loss = 0.01142215Iteration 20, loss = 0.00465645Iteration 19, loss = 0.00606934\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 14, loss = 0.00828839Iteration 15, loss = 0.02526509Iteration 13, loss = 0.00994428Iteration 22, loss = 0.00650703Iteration 25, loss = 0.00816912Iteration 16, loss = 0.00942805Iteration 21, loss = 0.00387327Iteration 20, loss = 0.00546317\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 15, loss = 0.00680483Iteration 16, loss = 0.02173376Iteration 14, loss = 0.00768728Iteration 23, loss = 0.00564716Iteration 26, loss = 0.01297288Iteration 17, loss = 0.00830951Iteration 22, loss = 0.00361837Iteration 21, loss = 0.00494916\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 16, loss = 0.00556241Iteration 17, loss = 0.01946536Iteration 15, loss = 0.00668842Iteration 24, loss = 0.00467852Iteration 27, loss = 0.00398279Iteration 18, loss = 0.00695613Iteration 23, loss = 0.00333264Iteration 22, loss = 0.00461661\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 17, loss = 0.00434834Iteration 18, loss = 0.01680123Iteration 16, loss = 0.00524152Iteration 25, loss = 0.00360076Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "Iteration 19, loss = 0.00571887Iteration 24, loss = 0.00261704Iteration 23, loss = 0.00344668\n",
      "\n",
      "\n",
      "\n",
      "Iteration 1, loss = 0.22101743\n",
      "\n",
      "\n",
      "Iteration 18, loss = 0.00350990Iteration 19, loss = 0.01474725Iteration 17, loss = 0.00457226Iteration 26, loss = 0.00280444\n",
      "Iteration 20, loss = 0.00452330Iteration 25, loss = 0.00307779Iteration 24, loss = 0.00366266\n",
      "\n",
      "\n",
      "\n",
      "Iteration 2, loss = 0.10381479\n",
      "\n",
      "\n",
      "Iteration 19, loss = 0.00305065Iteration 20, loss = 0.01298180Iteration 18, loss = 0.00348732Iteration 27, loss = 0.00245630\n",
      "Iteration 21, loss = 0.00367658Iteration 26, loss = 0.00382202Iteration 25, loss = 0.00270108\n",
      "\n",
      "\n",
      "\n",
      "Iteration 3, loss = 0.08052035\n",
      "\n",
      "\n",
      "Iteration 20, loss = 0.00282464Iteration 21, loss = 0.01060902Iteration 19, loss = 0.00341857Iteration 28, loss = 0.00317589\n",
      "Iteration 22, loss = 0.00306033Iteration 27, loss = 0.00315276Iteration 26, loss = 0.00276881\n",
      "\n",
      "\n",
      "\n",
      "Iteration 4, loss = 0.06658703\n",
      "\n",
      "\n",
      "Iteration 21, loss = 0.00196964Iteration 22, loss = 0.00950293Iteration 20, loss = 0.00319751Iteration 29, loss = 0.02144693\n",
      "Iteration 23, loss = 0.00249782Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "Iteration 27, loss = 0.01134378\n",
      "\n",
      "\n",
      "\n",
      "Iteration 5, loss = 0.05585745\n",
      "Iteration 1, loss = 0.19514430\n",
      "Iteration 22, loss = 0.00150435Iteration 23, loss = 0.00871266Iteration 21, loss = 0.00277551Iteration 30, loss = 0.01097750\n",
      "Iteration 24, loss = 0.00205011\n",
      "Iteration 28, loss = 0.01382601\n",
      "\n",
      "\n",
      "\n",
      "Iteration 6, loss = 0.04804696\n",
      "Iteration 2, loss = 0.09073969\n",
      "Iteration 23, loss = 0.00130671Iteration 24, loss = 0.00688168Iteration 22, loss = 0.00230656Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "\n",
      "Iteration 25, loss = 0.00168380\n",
      "Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "\n",
      "\n",
      "\n",
      "Iteration 1, loss = 0.24658853Iteration 7, loss = 0.04132459\n",
      "Iteration 3, loss = 0.06965687Iteration 1, loss = 0.20800603Iteration 24, loss = 0.00103015Iteration 25, loss = 0.00597054Iteration 23, loss = 0.00255079\n",
      "\n",
      "Iteration 26, loss = 0.00138230\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 2, loss = 0.12090207Iteration 8, loss = 0.03499935\n",
      "Iteration 4, loss = 0.05685875Iteration 2, loss = 0.09816870Iteration 25, loss = 0.00087143Iteration 26, loss = 0.00592194Iteration 24, loss = 0.00321651\n",
      "\n",
      "Iteration 27, loss = 0.00128626\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 3, loss = 0.09267192Iteration 9, loss = 0.03127501\n",
      "Iteration 5, loss = 0.04700984Iteration 3, loss = 0.07535410Iteration 26, loss = 0.00077071Iteration 27, loss = 0.00578125Iteration 25, loss = 0.00706929\n",
      "\n",
      "Iteration 28, loss = 0.00126723\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 4, loss = 0.07701615Iteration 10, loss = 0.02588489\n",
      "Iteration 6, loss = 0.04022771Iteration 4, loss = 0.06175681Iteration 27, loss = 0.00067629Iteration 28, loss = 0.00549269Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "\n",
      "\n",
      "Iteration 29, loss = 0.00119285\n",
      "\n",
      "\n",
      "\n",
      "Iteration 1, loss = 0.22323117Iteration 5, loss = 0.06563111Iteration 11, loss = 0.02223037\n",
      "Iteration 7, loss = 0.03385974Iteration 5, loss = 0.05214827Iteration 28, loss = 0.00059048Iteration 29, loss = 0.00481284\n",
      "\n",
      "\n",
      "Iteration 30, loss = 0.03032637\n",
      "\n",
      "\n",
      "\n",
      "Iteration 2, loss = 0.09600948Iteration 6, loss = 0.05602719Iteration 12, loss = 0.01881851\n",
      "Iteration 8, loss = 0.02887595Iteration 6, loss = 0.04377014Iteration 29, loss = 0.00050704Iteration 30, loss = 0.00573858\n",
      "\n",
      "\n",
      "Iteration 31, loss = 0.01109248\n",
      "\n",
      "\n",
      "\n",
      "Iteration 3, loss = 0.07290210Iteration 7, loss = 0.04911279Iteration 13, loss = 0.01611877\n",
      "Iteration 9, loss = 0.02385772Iteration 7, loss = 0.03732760Iteration 30, loss = 0.00047115Iteration 31, loss = 0.00740716\n",
      "\n",
      "\n",
      "Iteration 32, loss = 0.00224821\n",
      "\n",
      "\n",
      "\n",
      "Iteration 4, loss = 0.05891984Iteration 8, loss = 0.04240454Iteration 14, loss = 0.01391119\n",
      "Iteration 10, loss = 0.01983993Iteration 8, loss = 0.03143383Iteration 31, loss = 0.00045827Iteration 32, loss = 0.00507228\n",
      "\n",
      "\n",
      "Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 5, loss = 0.04933905Iteration 9, loss = 0.03643260Iteration 15, loss = 0.01134936Iteration 1, loss = 0.28123385Iteration 11, loss = 0.01639411Iteration 9, loss = 0.02683106Iteration 32, loss = 0.00042525Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 1, loss = 0.21947939Iteration 6, loss = 0.04225545Iteration 10, loss = 0.03120352Iteration 16, loss = 0.00953320Iteration 2, loss = 0.13450528Iteration 12, loss = 0.01396668Iteration 10, loss = 0.02216590Iteration 33, loss = 0.02839857\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 2, loss = 0.10454208Iteration 7, loss = 0.03626187Iteration 11, loss = 0.02731294Iteration 17, loss = 0.00835935Iteration 3, loss = 0.10630864Iteration 13, loss = 0.01095096Iteration 11, loss = 0.01891819Iteration 34, loss = 0.01168368\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 3, loss = 0.08209168Iteration 8, loss = 0.03083624Iteration 12, loss = 0.02342202Iteration 18, loss = 0.00706422Iteration 4, loss = 0.08950283Iteration 14, loss = 0.00933298Iteration 12, loss = 0.01594325Iteration 35, loss = 0.00265624\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 4, loss = 0.06810034Iteration 9, loss = 0.02546307Iteration 13, loss = 0.02026314Iteration 19, loss = 0.00600262Iteration 5, loss = 0.07750056Iteration 15, loss = 0.00772324Iteration 13, loss = 0.01267230Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 1, loss = 0.22438197Iteration 5, loss = 0.05760659Iteration 10, loss = 0.02218748Iteration 14, loss = 0.01774239Iteration 20, loss = 0.00490908Iteration 6, loss = 0.06803233Iteration 16, loss = 0.00639773Iteration 14, loss = 0.01028442\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 2, loss = 0.11296018Iteration 6, loss = 0.04953912Iteration 11, loss = 0.01841880Iteration 15, loss = 0.01440123Iteration 21, loss = 0.00395769Iteration 7, loss = 0.06058031Iteration 17, loss = 0.00536099Iteration 15, loss = 0.00879177\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 3, loss = 0.08828777Iteration 7, loss = 0.04212121Iteration 12, loss = 0.01543275Iteration 16, loss = 0.01246344Iteration 22, loss = 0.00361377Iteration 8, loss = 0.05285218Iteration 18, loss = 0.00418770Iteration 16, loss = 0.00700349\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 4, loss = 0.07397398Iteration 8, loss = 0.03689807Iteration 13, loss = 0.01299049Iteration 17, loss = 0.01042722Iteration 23, loss = 0.00349142Iteration 9, loss = 0.04747105Iteration 19, loss = 0.00366848Iteration 17, loss = 0.00575356\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 5, loss = 0.06320893Iteration 9, loss = 0.03134633Iteration 14, loss = 0.01046639Iteration 18, loss = 0.00887964Iteration 24, loss = 0.00386655Iteration 10, loss = 0.04175511Iteration 20, loss = 0.00334903Iteration 18, loss = 0.00485203\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 6, loss = 0.05461364Iteration 10, loss = 0.02655608Iteration 15, loss = 0.00912882Iteration 19, loss = 0.00817478Iteration 25, loss = 0.00372747Iteration 11, loss = 0.03694366Iteration 21, loss = 0.00286402Iteration 19, loss = 0.00431477\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 7, loss = 0.04759755Iteration 11, loss = 0.02281153Iteration 16, loss = 0.00725105Iteration 20, loss = 0.00658136Iteration 26, loss = 0.00558483Iteration 12, loss = 0.03232433Iteration 22, loss = 0.00252539Iteration 20, loss = 0.00358488\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 8, loss = 0.04106269Iteration 12, loss = 0.01952203Iteration 17, loss = 0.00575048Iteration 21, loss = 0.00561138Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "Iteration 13, loss = 0.02815158Iteration 23, loss = 0.00184916Iteration 21, loss = 0.00274166\n",
      "\n",
      "\n",
      "\n",
      "Iteration 1, loss = 0.23262359\n",
      "\n",
      "\n",
      "Iteration 9, loss = 0.03604910Iteration 13, loss = 0.01643560Iteration 18, loss = 0.00466738Iteration 22, loss = 0.00502147\n",
      "Iteration 14, loss = 0.02498646Iteration 24, loss = 0.00266073Iteration 22, loss = 0.00242597\n",
      "\n",
      "\n",
      "\n",
      "Iteration 2, loss = 0.11178238\n",
      "\n",
      "\n",
      "Iteration 10, loss = 0.03132620Iteration 14, loss = 0.01407205Iteration 19, loss = 0.00373983Iteration 23, loss = 0.00409705\n",
      "Iteration 15, loss = 0.02177611Iteration 25, loss = 0.00853233Iteration 23, loss = 0.00214512\n",
      "\n",
      "\n",
      "\n",
      "Iteration 3, loss = 0.08771335\n",
      "\n",
      "\n",
      "Iteration 11, loss = 0.02620806Iteration 15, loss = 0.01160351Iteration 20, loss = 0.00298008Iteration 24, loss = 0.00396205\n",
      "Iteration 16, loss = 0.01899175Iteration 26, loss = 0.01234824Iteration 24, loss = 0.00165086\n",
      "\n",
      "\n",
      "\n",
      "Iteration 4, loss = 0.07315068\n",
      "\n",
      "\n",
      "Iteration 12, loss = 0.02244960Iteration 16, loss = 0.00936474Iteration 21, loss = 0.00289540Iteration 25, loss = 0.00342610\n",
      "Iteration 17, loss = 0.01693028Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "Iteration 25, loss = 0.00139552\n",
      "\n",
      "\n",
      "\n",
      "Iteration 5, loss = 0.06241417\n",
      "Iteration 1, loss = 0.20499601\n",
      "Iteration 13, loss = 0.01899450Iteration 17, loss = 0.00784938Iteration 22, loss = 0.00242785Iteration 26, loss = 0.00295163\n",
      "Iteration 18, loss = 0.01442850\n",
      "Iteration 26, loss = 0.00103899\n",
      "\n",
      "\n",
      "\n",
      "Iteration 6, loss = 0.05378517\n",
      "Iteration 2, loss = 0.10128260\n",
      "Iteration 14, loss = 0.01627915Iteration 18, loss = 0.00695250Iteration 23, loss = 0.00174078Iteration 27, loss = 0.00370521\n",
      "Iteration 19, loss = 0.01259381\n",
      "Iteration 27, loss = 0.00084766\n",
      "\n",
      "\n",
      "\n",
      "Iteration 7, loss = 0.04677249\n",
      "Iteration 3, loss = 0.07754687\n",
      "Iteration 15, loss = 0.01365310Iteration 19, loss = 0.00591109Iteration 24, loss = 0.00153243Iteration 28, loss = 0.01453223\n",
      "Iteration 20, loss = 0.01101186\n",
      "Iteration 28, loss = 0.00070607\n",
      "\n",
      "\n",
      "\n",
      "Iteration 8, loss = 0.03991848\n",
      "Iteration 4, loss = 0.06439916\n",
      "Iteration 16, loss = 0.01177051Iteration 20, loss = 0.00462426Iteration 25, loss = 0.00129652Iteration 29, loss = 0.01155897\n",
      "Iteration 21, loss = 0.00943689\n",
      "Iteration 29, loss = 0.00063205\n",
      "\n",
      "\n",
      "\n",
      "Iteration 9, loss = 0.03493903\n",
      "Iteration 5, loss = 0.05460567\n",
      "Iteration 17, loss = 0.01054380Iteration 21, loss = 0.00384510Iteration 26, loss = 0.00099834Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "\n",
      "Iteration 22, loss = 0.00795630\n",
      "Iteration 30, loss = 0.00056069\n",
      "\n",
      "\n",
      "Iteration 1, loss = 0.23608687Iteration 10, loss = 0.02929413\n",
      "Iteration 6, loss = 0.04546174\n",
      "Iteration 18, loss = 0.00857312Iteration 22, loss = 0.00332369Iteration 27, loss = 0.00087121\n",
      "\n",
      "Iteration 23, loss = 0.00663370\n",
      "Iteration 31, loss = 0.00050544\n",
      "\n",
      "\n",
      "Iteration 2, loss = 0.11206450Iteration 11, loss = 0.02548706\n",
      "Iteration 7, loss = 0.03882173\n",
      "Iteration 19, loss = 0.00684286Iteration 23, loss = 0.00270547Iteration 28, loss = 0.00072781\n",
      "\n",
      "Iteration 24, loss = 0.00620816\n",
      "Iteration 32, loss = 0.00046492\n",
      "\n",
      "\n",
      "Iteration 3, loss = 0.08768859Iteration 12, loss = 0.02181947\n",
      "Iteration 8, loss = 0.03366541\n",
      "Iteration 20, loss = 0.00560466Iteration 24, loss = 0.00212882Iteration 29, loss = 0.00065367\n",
      "\n",
      "Iteration 25, loss = 0.00573493\n",
      "Iteration 33, loss = 0.00041273\n",
      "\n",
      "\n",
      "Iteration 4, loss = 0.07281969Iteration 13, loss = 0.01811997\n",
      "Iteration 9, loss = 0.02869408\n",
      "Iteration 21, loss = 0.00495872Iteration 25, loss = 0.00194835Iteration 30, loss = 0.01437378\n",
      "\n",
      "Iteration 26, loss = 0.00437168\n",
      "Iteration 34, loss = 0.00033924\n",
      "\n",
      "\n",
      "Iteration 5, loss = 0.06187608Iteration 14, loss = 0.01557880\n",
      "Iteration 10, loss = 0.02466541\n",
      "Iteration 22, loss = 0.00410138Iteration 26, loss = 0.00279592Iteration 31, loss = 0.03029631\n",
      "\n",
      "Iteration 27, loss = 0.00400998\n",
      "Iteration 35, loss = 0.00030516\n",
      "\n",
      "\n",
      "Iteration 6, loss = 0.05329298Iteration 15, loss = 0.01276589\n",
      "Iteration 11, loss = 0.02118679\n",
      "Iteration 23, loss = 0.00398232Iteration 27, loss = 0.02108530Iteration 32, loss = 0.00471590\n",
      "\n",
      "Iteration 28, loss = 0.00339949\n",
      "Iteration 36, loss = 0.00032510\n",
      "\n",
      "\n",
      "Iteration 7, loss = 0.04641212Iteration 16, loss = 0.01086583\n",
      "Iteration 12, loss = 0.01775204\n",
      "Iteration 24, loss = 0.00344476Iteration 28, loss = 0.00871412Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "\n",
      "\n",
      "Iteration 29, loss = 0.00305769\n",
      "Iteration 37, loss = 0.03015543\n",
      "\n",
      "Iteration 1, loss = 0.21008770Iteration 8, loss = 0.04006445Iteration 17, loss = 0.00897478\n",
      "Iteration 13, loss = 0.01473996\n",
      "Iteration 25, loss = 0.00395589Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "\n",
      "\n",
      "\n",
      "Iteration 30, loss = 0.00317691\n",
      "Iteration 38, loss = 0.01500506\n",
      "Iteration 1, loss = 0.22664169Iteration 2, loss = 0.10645666Iteration 9, loss = 0.03373856Iteration 18, loss = 0.00765141\n",
      "Iteration 14, loss = 0.01257641\n",
      "Iteration 26, loss = 0.00400468\n",
      "\n",
      "\n",
      "\n",
      "Iteration 31, loss = 0.00720640\n",
      "Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "\n",
      "Iteration 2, loss = 0.10781123Iteration 3, loss = 0.08195858Iteration 10, loss = 0.02864488Iteration 19, loss = 0.00625471\n",
      "Iteration 15, loss = 0.01035926Iteration 1, loss = 0.22963582Iteration 27, loss = 0.00886557\n",
      "\n",
      "\n",
      "\n",
      "Iteration 32, loss = 0.02471193\n",
      "\n",
      "\n",
      "Iteration 3, loss = 0.08287416Iteration 4, loss = 0.06751441Iteration 11, loss = 0.02466750Iteration 20, loss = 0.00541894\n",
      "Iteration 16, loss = 0.00821345Iteration 2, loss = 0.11679669Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "\n",
      "\n",
      "Iteration 1, loss = 0.19780417Iteration 4, loss = 0.06782163Iteration 5, loss = 0.05783253Iteration 12, loss = 0.02196628Iteration 21, loss = 0.00447806Iteration 1, loss = 0.24613464Iteration 17, loss = 0.00703051Iteration 3, loss = 0.09194812\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 2, loss = 0.08714843Iteration 5, loss = 0.05701589Iteration 6, loss = 0.04962227Iteration 13, loss = 0.01783015Iteration 22, loss = 0.00342791Iteration 2, loss = 0.11124735Iteration 18, loss = 0.00599220Iteration 4, loss = 0.07677457\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 3, loss = 0.06663548Iteration 6, loss = 0.04841809Iteration 7, loss = 0.04242376Iteration 14, loss = 0.01501910Iteration 23, loss = 0.00308135Iteration 3, loss = 0.08587433Iteration 19, loss = 0.00482468Iteration 5, loss = 0.06629078\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 4, loss = 0.05417468Iteration 7, loss = 0.04149695Iteration 8, loss = 0.03654390Iteration 15, loss = 0.01269291Iteration 24, loss = 0.00272332Iteration 4, loss = 0.07106510Iteration 20, loss = 0.00394115Iteration 6, loss = 0.05767008\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 5, loss = 0.04512399Iteration 8, loss = 0.03539283Iteration 9, loss = 0.03111082Iteration 16, loss = 0.01072624Iteration 25, loss = 0.00225985Iteration 5, loss = 0.06071867Iteration 21, loss = 0.00310878Iteration 7, loss = 0.04964745\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 6, loss = 0.03848446Iteration 9, loss = 0.03051019Iteration 10, loss = 0.02642633Iteration 17, loss = 0.00925295Iteration 26, loss = 0.00184090Iteration 6, loss = 0.05188571Iteration 22, loss = 0.00277948Iteration 8, loss = 0.04303206\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 7, loss = 0.03203297Iteration 10, loss = 0.02620807Iteration 11, loss = 0.02277263Iteration 18, loss = 0.00808267Iteration 27, loss = 0.00159780Iteration 7, loss = 0.04481641Iteration 23, loss = 0.00282890Iteration 9, loss = 0.03775776\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 8, loss = 0.02667698Iteration 11, loss = 0.02190670Iteration 12, loss = 0.01891412Iteration 19, loss = 0.00641070Iteration 28, loss = 0.00190698Iteration 8, loss = 0.03928691Iteration 24, loss = 0.00223185Iteration 10, loss = 0.03308495\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 9, loss = 0.02178024Iteration 12, loss = 0.01841792Iteration 13, loss = 0.01667697Iteration 20, loss = 0.00545404Iteration 29, loss = 0.01565870Iteration 9, loss = 0.03319568Iteration 25, loss = 0.00178616Iteration 11, loss = 0.02810091\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 10, loss = 0.01859947Iteration 13, loss = 0.01545493Iteration 14, loss = 0.01425935Iteration 21, loss = 0.00501813Iteration 30, loss = 0.01987697Iteration 10, loss = 0.02913584Iteration 26, loss = 0.00135476Iteration 12, loss = 0.02425595\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 11, loss = 0.01478524Iteration 14, loss = 0.01297344Iteration 15, loss = 0.01178992Iteration 22, loss = 0.00414304Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "Iteration 11, loss = 0.02538288Iteration 27, loss = 0.00102527Iteration 13, loss = 0.02061757\n",
      "\n",
      "\n",
      "\n",
      "Iteration 1, loss = 0.24051927\n",
      "\n",
      "\n",
      "Iteration 12, loss = 0.01196467Iteration 15, loss = 0.01077884Iteration 16, loss = 0.00958172Iteration 23, loss = 0.00412031\n",
      "Iteration 12, loss = 0.02193824Iteration 28, loss = 0.00088174Iteration 14, loss = 0.01808088\n",
      "\n",
      "\n",
      "\n",
      "Iteration 2, loss = 0.11701769\n",
      "\n",
      "\n",
      "Iteration 13, loss = 0.01013012Iteration 16, loss = 0.00923516Iteration 17, loss = 0.00774746Iteration 24, loss = 0.00699057\n",
      "Iteration 13, loss = 0.01826434Iteration 29, loss = 0.00072940Iteration 15, loss = 0.01473610\n",
      "\n",
      "\n",
      "\n",
      "Iteration 3, loss = 0.09056853\n",
      "\n",
      "\n",
      "Iteration 14, loss = 0.00810865Iteration 17, loss = 0.00739276Iteration 18, loss = 0.00656339Iteration 25, loss = 0.00604394\n",
      "Iteration 14, loss = 0.01550202Iteration 30, loss = 0.00064411Iteration 16, loss = 0.01216518\n",
      "\n",
      "\n",
      "\n",
      "Iteration 4, loss = 0.07621435\n",
      "\n",
      "\n",
      "Iteration 15, loss = 0.00646228Iteration 18, loss = 0.00675916Iteration 19, loss = 0.00531158Iteration 26, loss = 0.00441139\n",
      "Iteration 15, loss = 0.01275565Iteration 31, loss = 0.00057026Iteration 17, loss = 0.01148712\n",
      "\n",
      "\n",
      "\n",
      "Iteration 5, loss = 0.06464503\n",
      "\n",
      "\n",
      "Iteration 16, loss = 0.00567740Iteration 19, loss = 0.00573294Iteration 20, loss = 0.00474379Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "\n",
      "Iteration 16, loss = 0.01158297Iteration 32, loss = 0.00052861Iteration 18, loss = 0.00911530\n",
      "\n",
      "\n",
      "Iteration 1, loss = 0.17961084Iteration 6, loss = 0.05592746\n",
      "\n",
      "\n",
      "Iteration 17, loss = 0.00433029Iteration 20, loss = 0.00452504Iteration 21, loss = 0.00402913\n",
      "\n",
      "Iteration 17, loss = 0.00950045Iteration 33, loss = 0.02111563Iteration 19, loss = 0.00752471\n",
      "\n",
      "\n",
      "Iteration 2, loss = 0.07837704Iteration 7, loss = 0.04849096\n",
      "\n",
      "\n",
      "Iteration 18, loss = 0.00353007Iteration 21, loss = 0.00366993Iteration 22, loss = 0.00315200\n",
      "\n",
      "Iteration 18, loss = 0.00761751Iteration 34, loss = 0.01926865Iteration 20, loss = 0.00621342\n",
      "\n",
      "\n",
      "Iteration 3, loss = 0.05968312Iteration 8, loss = 0.04237496\n",
      "\n",
      "\n",
      "Iteration 19, loss = 0.00275847Iteration 22, loss = 0.00326141Iteration 23, loss = 0.00289634\n",
      "\n",
      "Iteration 19, loss = 0.00664233Iteration 35, loss = 0.00439313Iteration 21, loss = 0.00555385\n",
      "\n",
      "\n",
      "Iteration 4, loss = 0.04855230Iteration 9, loss = 0.03632930\n",
      "\n",
      "\n",
      "Iteration 20, loss = 0.00220180Iteration 23, loss = 0.00272519Iteration 24, loss = 0.00215055\n",
      "\n",
      "Iteration 20, loss = 0.00552422Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "Iteration 22, loss = 0.00505770\n",
      "\n",
      "\n",
      "Iteration 5, loss = 0.03982435Iteration 10, loss = 0.03168973\n",
      "Iteration 1, loss = 0.20999463\n",
      "Iteration 21, loss = 0.00175020Iteration 24, loss = 0.00255917Iteration 25, loss = 0.00198204\n",
      "\n",
      "Iteration 21, loss = 0.00448269\n",
      "Iteration 23, loss = 0.00391991\n",
      "\n",
      "\n",
      "Iteration 6, loss = 0.03325351Iteration 11, loss = 0.02738148\n",
      "Iteration 2, loss = 0.10381522\n",
      "Iteration 22, loss = 0.00149292Iteration 25, loss = 0.00227267Iteration 26, loss = 0.00165135\n",
      "\n",
      "Iteration 22, loss = 0.00389713\n",
      "Iteration 24, loss = 0.00342666\n",
      "\n",
      "\n",
      "Iteration 7, loss = 0.02716197Iteration 12, loss = 0.02344508\n",
      "Iteration 3, loss = 0.08072004\n",
      "Iteration 23, loss = 0.00128721Iteration 26, loss = 0.00261523Iteration 27, loss = 0.00124400\n",
      "\n",
      "Iteration 23, loss = 0.00385648\n",
      "Iteration 25, loss = 0.00294356\n",
      "\n",
      "\n",
      "Iteration 8, loss = 0.02260689Iteration 13, loss = 0.02032085\n",
      "Iteration 4, loss = 0.06616108\n",
      "Iteration 24, loss = 0.00105642Iteration 27, loss = 0.01976202Iteration 28, loss = 0.02044162\n",
      "\n",
      "Iteration 24, loss = 0.00315174\n",
      "Iteration 26, loss = 0.00229723\n",
      "\n",
      "\n",
      "Iteration 9, loss = 0.01852465Iteration 14, loss = 0.01690228\n",
      "Iteration 5, loss = 0.05623380\n",
      "Iteration 25, loss = 0.00093904Iteration 28, loss = 0.00715242Iteration 29, loss = 0.01166831\n",
      "\n",
      "Iteration 25, loss = 0.00231243\n",
      "Iteration 27, loss = 0.00190712\n",
      "\n",
      "\n",
      "Iteration 10, loss = 0.01549560Iteration 15, loss = 0.01429921\n",
      "Iteration 6, loss = 0.04759660\n",
      "Iteration 26, loss = 0.00086866Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "Iteration 30, loss = 0.00315417\n",
      "\n",
      "Iteration 26, loss = 0.00197924\n",
      "Iteration 28, loss = 0.00171750\n",
      "Iteration 1, loss = 0.22516675\n",
      "Iteration 11, loss = 0.01245663Iteration 16, loss = 0.01249992\n",
      "Iteration 7, loss = 0.04020668\n",
      "Iteration 27, loss = 0.00070141\n",
      "Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "\n",
      "\n",
      "Iteration 27, loss = 0.00163804\n",
      "Iteration 29, loss = 0.00142989\n",
      "Iteration 2, loss = 0.10430397Iteration 1, loss = 0.18856853Iteration 12, loss = 0.00995758Iteration 17, loss = 0.01012820\n",
      "Iteration 8, loss = 0.03481308\n",
      "Iteration 28, loss = 0.00059121\n",
      "\n",
      "\n",
      "\n",
      "Iteration 28, loss = 0.00137235\n",
      "Iteration 30, loss = 0.00113713\n",
      "Iteration 3, loss = 0.08054719Iteration 2, loss = 0.08799095Iteration 13, loss = 0.00827859Iteration 18, loss = 0.00876946\n",
      "Iteration 9, loss = 0.02914422\n",
      "Iteration 29, loss = 0.00050236\n",
      "\n",
      "\n",
      "\n",
      "Iteration 29, loss = 0.00118657\n",
      "Iteration 31, loss = 0.00103983\n",
      "Iteration 4, loss = 0.06658580Iteration 3, loss = 0.06625020Iteration 14, loss = 0.00701009Iteration 19, loss = 0.00766704\n",
      "Iteration 10, loss = 0.02495244\n",
      "Iteration 30, loss = 0.00204103\n",
      "\n",
      "\n",
      "\n",
      "Iteration 30, loss = 0.00111590\n",
      "Iteration 32, loss = 0.00098165\n",
      "Iteration 5, loss = 0.05519297Iteration 4, loss = 0.05481332Iteration 15, loss = 0.00519871Iteration 20, loss = 0.00639656\n",
      "Iteration 11, loss = 0.02064522\n",
      "Iteration 31, loss = 0.03102536\n",
      "\n",
      "\n",
      "\n",
      "Iteration 31, loss = 0.02565391\n",
      "Iteration 33, loss = 0.03543124\n",
      "Iteration 6, loss = 0.04771374Iteration 5, loss = 0.04552327Iteration 16, loss = 0.00436529Iteration 21, loss = 0.00578581\n",
      "Iteration 12, loss = 0.01759904\n",
      "Iteration 32, loss = 0.00532427\n",
      "\n",
      "\n",
      "\n",
      "Iteration 32, loss = 0.01383594\n",
      "Iteration 34, loss = 0.00843989\n",
      "Iteration 7, loss = 0.04041728Iteration 6, loss = 0.03788086Iteration 17, loss = 0.00350780Iteration 22, loss = 0.00479411\n",
      "Iteration 13, loss = 0.01484785\n",
      "Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 33, loss = 0.00268398\n",
      "Iteration 35, loss = 0.00205426Iteration 1, loss = 0.18724063Iteration 8, loss = 0.03429787Iteration 7, loss = 0.03153857Iteration 18, loss = 0.00306378Iteration 23, loss = 0.00503429\n",
      "Iteration 14, loss = 0.01255008\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "\n",
      "Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "Iteration 2, loss = 0.09251075Iteration 9, loss = 0.02908345Iteration 8, loss = 0.02664221Iteration 19, loss = 0.00282302Iteration 24, loss = 0.00456278Iteration 1, loss = 0.22297627Iteration 15, loss = 0.01040024Iteration 1, loss = 0.17522680\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 3, loss = 0.07191413Iteration 10, loss = 0.02547213Iteration 9, loss = 0.02252672Iteration 20, loss = 0.00244635Iteration 25, loss = 0.00384550Iteration 2, loss = 0.10846464Iteration 16, loss = 0.00880301Iteration 2, loss = 0.08370121\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 4, loss = 0.05910402Iteration 11, loss = 0.02139337Iteration 10, loss = 0.01805882Iteration 21, loss = 0.00197209Iteration 26, loss = 0.00327190Iteration 3, loss = 0.08455066Iteration 17, loss = 0.00704173Iteration 3, loss = 0.06370657\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 5, loss = 0.05008156Iteration 12, loss = 0.01785054Iteration 11, loss = 0.01475181Iteration 22, loss = 0.00200622Iteration 27, loss = 0.00226939Iteration 4, loss = 0.06997663Iteration 18, loss = 0.00634115Iteration 4, loss = 0.05142374\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 6, loss = 0.04218252Iteration 13, loss = 0.01530873Iteration 12, loss = 0.01237565Iteration 23, loss = 0.00321227Iteration 28, loss = 0.00217105Iteration 5, loss = 0.05941584Iteration 19, loss = 0.00503858Iteration 5, loss = 0.04292522\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 7, loss = 0.03611476Iteration 14, loss = 0.01288969Iteration 13, loss = 0.01035242Iteration 24, loss = 0.01065615Iteration 29, loss = 0.00373819Iteration 6, loss = 0.05133070Iteration 20, loss = 0.00452729Iteration 6, loss = 0.03586550\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 8, loss = 0.03029380Iteration 15, loss = 0.01074504Iteration 14, loss = 0.00863411Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "Iteration 30, loss = 0.01901665Iteration 7, loss = 0.04396268Iteration 21, loss = 0.00415633Iteration 7, loss = 0.03002476\n",
      "\n",
      "\n",
      "Iteration 1, loss = 0.23627551\n",
      "\n",
      "\n",
      "\n",
      "Iteration 9, loss = 0.02549656Iteration 16, loss = 0.00893760Iteration 15, loss = 0.00638913\n",
      "Iteration 31, loss = 0.00866019Iteration 8, loss = 0.03768509Iteration 22, loss = 0.00390897Iteration 8, loss = 0.02486063\n",
      "\n",
      "\n",
      "Iteration 2, loss = 0.12063520\n",
      "\n",
      "\n",
      "\n",
      "Iteration 10, loss = 0.02157208Iteration 17, loss = 0.00789684Iteration 16, loss = 0.00519630\n",
      "Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "Iteration 9, loss = 0.03236087Iteration 23, loss = 0.00448678Iteration 9, loss = 0.02017771\n",
      "\n",
      "\n",
      "Iteration 3, loss = 0.09421537Iteration 1, loss = 0.21696008\n",
      "\n",
      "\n",
      "Iteration 11, loss = 0.01844858Iteration 18, loss = 0.00677108Iteration 17, loss = 0.00417675\n",
      "\n",
      "Iteration 10, loss = 0.02805341Iteration 24, loss = 0.00373560Iteration 10, loss = 0.01694502\n",
      "\n",
      "\n",
      "Iteration 4, loss = 0.07805868Iteration 2, loss = 0.09868682\n",
      "\n",
      "\n",
      "Iteration 12, loss = 0.01569087Iteration 19, loss = 0.00610357Iteration 18, loss = 0.00347569\n",
      "\n",
      "Iteration 11, loss = 0.02396103Iteration 25, loss = 0.00358871Iteration 11, loss = 0.01416348\n",
      "\n",
      "\n",
      "Iteration 5, loss = 0.06693194Iteration 3, loss = 0.07574766\n",
      "\n",
      "\n",
      "Iteration 13, loss = 0.01283281Iteration 20, loss = 0.00466614Iteration 19, loss = 0.00275537\n",
      "\n",
      "Iteration 12, loss = 0.02015882Iteration 26, loss = 0.00524040Iteration 12, loss = 0.01105298\n",
      "\n",
      "\n",
      "Iteration 6, loss = 0.05791419Iteration 4, loss = 0.06278528\n",
      "\n",
      "\n",
      "Iteration 14, loss = 0.01050813Iteration 21, loss = 0.00423297Iteration 20, loss = 0.00251139\n",
      "\n",
      "Iteration 13, loss = 0.01700150Iteration 27, loss = 0.00652231Iteration 13, loss = 0.00903286\n",
      "\n",
      "\n",
      "Iteration 7, loss = 0.05047639Iteration 5, loss = 0.05334688\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done   2 out of   8 | elapsed:   50.0s remaining:  2.5min\n",
      "[Parallel(n_jobs=8)]: Done   8 out of   8 | elapsed:   52.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 15, loss = 0.00888492Iteration 22, loss = 0.00381504Iteration 21, loss = 0.00205982\n",
      "\n",
      "Iteration 14, loss = 0.01473467Iteration 28, loss = 0.00610312Iteration 14, loss = 0.00746312\n",
      "\n",
      "\n",
      "Iteration 8, loss = 0.04410288Iteration 6, loss = 0.04465835\n",
      "\n",
      "\n",
      "Iteration 16, loss = 0.00723263Iteration 23, loss = 0.00383147Iteration 22, loss = 0.00170723\n",
      "\n",
      "Iteration 15, loss = 0.01217062Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "Iteration 15, loss = 0.00583623\n",
      "\n",
      "\n",
      "Iteration 9, loss = 0.03850089Iteration 7, loss = 0.03866271\n",
      "Iteration 1, loss = 0.21966428\n",
      "Iteration 17, loss = 0.00655162Iteration 24, loss = 0.00369492Iteration 23, loss = 0.00131598\n",
      "\n",
      "Iteration 16, loss = 0.01010394\n",
      "Iteration 16, loss = 0.00456189\n",
      "\n",
      "\n",
      "Iteration 10, loss = 0.03321326Iteration 8, loss = 0.03317765\n",
      "Iteration 2, loss = 0.10391527\n",
      "Iteration 18, loss = 0.00496593Iteration 25, loss = 0.00429986Iteration 24, loss = 0.00101356\n",
      "\n",
      "Iteration 17, loss = 0.00830416\n",
      "Iteration 17, loss = 0.00356907\n",
      "\n",
      "\n",
      "Iteration 11, loss = 0.02861795Iteration 9, loss = 0.02791527\n",
      "Iteration 3, loss = 0.07990162\n",
      "Iteration 19, loss = 0.00445486Iteration 26, loss = 0.00549536Iteration 25, loss = 0.00088388\n",
      "\n",
      "Iteration 18, loss = 0.00714668\n",
      "Iteration 18, loss = 0.00310479\n",
      "\n",
      "\n",
      "Iteration 12, loss = 0.02564992Iteration 10, loss = 0.02354563\n",
      "Iteration 4, loss = 0.06629985\n",
      "Iteration 20, loss = 0.00370121Iteration 27, loss = 0.00687242Iteration 26, loss = 0.00072970\n",
      "\n",
      "Iteration 19, loss = 0.00582029\n",
      "Iteration 19, loss = 0.00264561\n",
      "\n",
      "\n",
      "Iteration 13, loss = 0.02234445Iteration 11, loss = 0.01986119\n",
      "Iteration 5, loss = 0.05576847\n",
      "Iteration 21, loss = 0.00347612Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "Iteration 27, loss = 0.00062434\n",
      "\n",
      "Iteration 20, loss = 0.00496375\n",
      "Iteration 20, loss = 0.00234914\n",
      "Iteration 1, loss = 0.22769808\n",
      "Iteration 14, loss = 0.01950582Iteration 12, loss = 0.01628623\n",
      "Iteration 6, loss = 0.04717904\n",
      "Iteration 22, loss = 0.00283471\n",
      "Iteration 28, loss = 0.00053621\n",
      "\n",
      "Iteration 21, loss = 0.00393304\n",
      "Iteration 21, loss = 0.00206201\n",
      "Iteration 2, loss = 0.10909277\n",
      "Iteration 15, loss = 0.01604589Iteration 13, loss = 0.01349023\n",
      "Iteration 7, loss = 0.03999881\n",
      "Iteration 23, loss = 0.00298135\n",
      "Iteration 29, loss = 0.00046802\n",
      "\n",
      "Iteration 22, loss = 0.00355018\n",
      "Iteration 22, loss = 0.00165610\n",
      "Iteration 3, loss = 0.08535568\n",
      "Iteration 16, loss = 0.01370536Iteration 14, loss = 0.01131512\n",
      "Iteration 8, loss = 0.03454516\n",
      "Iteration 24, loss = 0.00458790\n",
      "Iteration 30, loss = 0.02516620\n",
      "\n",
      "Iteration 23, loss = 0.00344049\n",
      "Iteration 23, loss = 0.00182146\n",
      "Iteration 4, loss = 0.07045186\n",
      "Iteration 17, loss = 0.01206645Iteration 15, loss = 0.00933599\n",
      "Iteration 9, loss = 0.02911932\n",
      "Iteration 25, loss = 0.00839894\n",
      "Iteration 31, loss = 0.01381126\n",
      "\n",
      "Iteration 24, loss = 0.00285126\n",
      "Iteration 24, loss = 0.00690461\n",
      "Iteration 5, loss = 0.05986699\n",
      "Iteration 18, loss = 0.01041097Iteration 16, loss = 0.00735675\n",
      "Iteration 10, loss = 0.02451682\n",
      "Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "\n",
      "Iteration 32, loss = 0.00314090\n",
      "\n",
      "Iteration 25, loss = 0.00266026\n",
      "Iteration 25, loss = 0.01220665Iteration 1, loss = 0.20402228Iteration 6, loss = 0.05056538\n",
      "Iteration 19, loss = 0.00896888Iteration 17, loss = 0.00621095\n",
      "Iteration 11, loss = 0.02094140\n",
      "\n",
      "\n",
      "Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "\n",
      "\n",
      "Iteration 26, loss = 0.00463884\n",
      "Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "Iteration 2, loss = 0.09295271Iteration 7, loss = 0.04358101Iteration 1, loss = 0.22799621Iteration 20, loss = 0.00755454Iteration 18, loss = 0.00492223\n",
      "Iteration 12, loss = 0.01717674Iteration 1, loss = 0.27628548\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 27, loss = 0.01943301\n",
      "\n",
      "Iteration 3, loss = 0.07156542Iteration 8, loss = 0.03783234Iteration 2, loss = 0.10796413Iteration 21, loss = 0.00670569Iteration 19, loss = 0.00404823\n",
      "Iteration 13, loss = 0.01471066Iteration 2, loss = 0.13379639\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 28, loss = 0.00708114\n",
      "\n",
      "Iteration 4, loss = 0.05903163Iteration 9, loss = 0.03232209Iteration 3, loss = 0.08472437Iteration 22, loss = 0.00720763Iteration 20, loss = 0.00322695\n",
      "Iteration 14, loss = 0.01172395Iteration 3, loss = 0.10478148\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "\n",
      "\n",
      "Iteration 5, loss = 0.04926434Iteration 10, loss = 0.02798118Iteration 4, loss = 0.07084695Iteration 23, loss = 0.00559982Iteration 21, loss = 0.00285371Iteration 1, loss = 0.20790095Iteration 15, loss = 0.00983304Iteration 4, loss = 0.08842684\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 6, loss = 0.04175869Iteration 11, loss = 0.02341407Iteration 5, loss = 0.06077967Iteration 24, loss = 0.00437781Iteration 22, loss = 0.00248928Iteration 2, loss = 0.10014116Iteration 16, loss = 0.00817717Iteration 5, loss = 0.07553246\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 7, loss = 0.03505769Iteration 12, loss = 0.01998451Iteration 6, loss = 0.05187273Iteration 25, loss = 0.00324265Iteration 23, loss = 0.00259161Iteration 3, loss = 0.07784575Iteration 17, loss = 0.00656608Iteration 6, loss = 0.06707765\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 8, loss = 0.03024273Iteration 13, loss = 0.01691590Iteration 7, loss = 0.04453534Iteration 26, loss = 0.00389945Iteration 24, loss = 0.00220497Iteration 4, loss = 0.06439239Iteration 18, loss = 0.00595779Iteration 7, loss = 0.05906352\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 9, loss = 0.02544243Iteration 14, loss = 0.01420859Iteration 8, loss = 0.03831493Iteration 27, loss = 0.00401604Iteration 25, loss = 0.00174961Iteration 5, loss = 0.05452914Iteration 19, loss = 0.00504354Iteration 8, loss = 0.05208452\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 10, loss = 0.02131616Iteration 15, loss = 0.01215294Iteration 9, loss = 0.03362546Iteration 28, loss = 0.01064963Iteration 26, loss = 0.00139781Iteration 6, loss = 0.04656951Iteration 20, loss = 0.00412356Iteration 9, loss = 0.04654712\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 11, loss = 0.01819000Iteration 16, loss = 0.00976820Iteration 10, loss = 0.02855286Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "Iteration 27, loss = 0.00096562Iteration 7, loss = 0.04049442Iteration 21, loss = 0.00340112Iteration 10, loss = 0.04065836\n",
      "\n",
      "\n",
      "Iteration 1, loss = 0.21568346\n",
      "\n",
      "\n",
      "\n",
      "Iteration 12, loss = 0.01482720Iteration 17, loss = 0.00816065Iteration 11, loss = 0.02464000\n",
      "Iteration 28, loss = 0.00075980Iteration 8, loss = 0.03453327Iteration 22, loss = 0.00285976Iteration 11, loss = 0.03577307\n",
      "\n",
      "\n",
      "Iteration 2, loss = 0.10272169\n",
      "\n",
      "\n",
      "\n",
      "Iteration 13, loss = 0.01223845Iteration 18, loss = 0.00659305Iteration 12, loss = 0.02093727\n",
      "Iteration 29, loss = 0.00063999Iteration 9, loss = 0.02939173Iteration 23, loss = 0.00273801Iteration 12, loss = 0.03133897\n",
      "\n",
      "\n",
      "Iteration 3, loss = 0.07993918\n",
      "\n",
      "\n",
      "\n",
      "Iteration 14, loss = 0.01014175Iteration 19, loss = 0.00612931Iteration 13, loss = 0.01764756\n",
      "Iteration 30, loss = 0.00054503Iteration 10, loss = 0.02519473Iteration 24, loss = 0.00239482Iteration 13, loss = 0.02819966\n",
      "\n",
      "\n",
      "Iteration 4, loss = 0.06651085\n",
      "\n",
      "\n",
      "\n",
      "Iteration 15, loss = 0.00843668Iteration 20, loss = 0.00490116Iteration 14, loss = 0.01507461\n",
      "Iteration 31, loss = 0.00048695Iteration 11, loss = 0.02129263Iteration 25, loss = 0.00256107Iteration 14, loss = 0.02444917\n",
      "\n",
      "\n",
      "Iteration 5, loss = 0.05676711\n",
      "\n",
      "\n",
      "\n",
      "Iteration 16, loss = 0.00662892Iteration 21, loss = 0.00411308Iteration 15, loss = 0.01346059\n",
      "Iteration 32, loss = 0.00043026Iteration 12, loss = 0.01830475Iteration 26, loss = 0.00368161Iteration 15, loss = 0.02105771\n",
      "\n",
      "\n",
      "Iteration 6, loss = 0.04871606\n",
      "\n",
      "\n",
      "\n",
      "Iteration 17, loss = 0.00588075Iteration 22, loss = 0.00354448Iteration 16, loss = 0.01110916\n",
      "Iteration 33, loss = 0.00038523Iteration 13, loss = 0.01557188Iteration 27, loss = 0.01908022Iteration 16, loss = 0.01814095\n",
      "\n",
      "\n",
      "Iteration 7, loss = 0.04190952\n",
      "\n",
      "\n",
      "\n",
      "Iteration 18, loss = 0.00449982Iteration 23, loss = 0.00329090Iteration 17, loss = 0.00882495\n",
      "Iteration 34, loss = 0.00036675Iteration 14, loss = 0.01335474Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "Iteration 17, loss = 0.01561706\n",
      "\n",
      "\n",
      "Iteration 8, loss = 0.03593489\n",
      "\n",
      "Iteration 1, loss = 0.24708960\n",
      "Iteration 19, loss = 0.00361636Iteration 24, loss = 0.00272893Iteration 18, loss = 0.00732887\n",
      "Iteration 35, loss = 0.00034918Iteration 15, loss = 0.01052916\n",
      "Iteration 18, loss = 0.01327643\n",
      "\n",
      "\n",
      "Iteration 9, loss = 0.03084695\n",
      "\n",
      "Iteration 2, loss = 0.11576729\n",
      "Iteration 20, loss = 0.00327403Iteration 25, loss = 0.00524304Iteration 19, loss = 0.00615651\n",
      "Iteration 36, loss = 0.00030205Iteration 16, loss = 0.00903583\n",
      "Iteration 19, loss = 0.01183555\n",
      "\n",
      "\n",
      "Iteration 10, loss = 0.02605855\n",
      "\n",
      "Iteration 3, loss = 0.08953870\n",
      "Iteration 21, loss = 0.00276795Iteration 26, loss = 0.01359125Iteration 20, loss = 0.00537480\n",
      "Iteration 37, loss = 0.00026304Iteration 17, loss = 0.00758316\n",
      "Iteration 20, loss = 0.01025845\n",
      "\n",
      "\n",
      "Iteration 11, loss = 0.02238027\n",
      "\n",
      "Iteration 4, loss = 0.07457674\n",
      "Iteration 22, loss = 0.00221128Iteration 27, loss = 0.00771202Iteration 21, loss = 0.00423973\n",
      "Iteration 38, loss = 0.00022783Iteration 18, loss = 0.00628691\n",
      "Iteration 21, loss = 0.00886839\n",
      "\n",
      "\n",
      "Iteration 12, loss = 0.01919513\n",
      "\n",
      "Iteration 5, loss = 0.06408266\n",
      "Iteration 23, loss = 0.00181853Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "Iteration 22, loss = 0.00388155\n",
      "Iteration 39, loss = 0.00019306Iteration 19, loss = 0.00510875\n",
      "Iteration 22, loss = 0.00744576\n",
      "Iteration 1, loss = 0.22837192\n",
      "Iteration 13, loss = 0.01541234\n",
      "\n",
      "Iteration 6, loss = 0.05478285\n",
      "Iteration 24, loss = 0.00156387\n",
      "Iteration 23, loss = 0.00421612\n",
      "Iteration 40, loss = 0.00017190Iteration 20, loss = 0.00454777\n",
      "Iteration 23, loss = 0.00647665\n",
      "Iteration 2, loss = 0.10287950\n",
      "Iteration 14, loss = 0.01321201\n",
      "\n",
      "Iteration 7, loss = 0.04792447\n",
      "Iteration 25, loss = 0.00136538\n",
      "Iteration 24, loss = 0.00344064\n",
      "Iteration 41, loss = 0.00015218Iteration 21, loss = 0.00357580\n",
      "Iteration 24, loss = 0.00496411\n",
      "Iteration 3, loss = 0.07875333\n",
      "Iteration 15, loss = 0.01124414\n",
      "\n",
      "Iteration 8, loss = 0.04170362\n",
      "Iteration 26, loss = 0.00114302\n",
      "Iteration 25, loss = 0.00259876\n",
      "Iteration 42, loss = 0.00013456Iteration 22, loss = 0.00345709\n",
      "Iteration 25, loss = 0.00501886\n",
      "Iteration 4, loss = 0.06403173\n",
      "Iteration 16, loss = 0.00903179\n",
      "\n",
      "Iteration 9, loss = 0.03592881\n",
      "Iteration 27, loss = 0.00098881\n",
      "Iteration 26, loss = 0.00200090\n",
      "Iteration 43, loss = 0.00011872Iteration 23, loss = 0.00304785\n",
      "Iteration 26, loss = 0.00453684\n",
      "Iteration 5, loss = 0.05336012\n",
      "Iteration 17, loss = 0.00732015\n",
      "\n",
      "Iteration 10, loss = 0.03072487\n",
      "Iteration 28, loss = 0.00076593\n",
      "Iteration 27, loss = 0.00155341\n",
      "Iteration 44, loss = 0.00010748Iteration 24, loss = 0.00272801\n",
      "Iteration 27, loss = 0.00477382\n",
      "Iteration 6, loss = 0.04557465\n",
      "Iteration 18, loss = 0.00636324\n",
      "\n",
      "Iteration 11, loss = 0.02665742\n",
      "Iteration 29, loss = 0.00060820\n",
      "Iteration 28, loss = 0.00118177\n",
      "Iteration 45, loss = 0.00011421Iteration 25, loss = 0.00331463\n",
      "Iteration 28, loss = 0.00463530\n",
      "Iteration 7, loss = 0.03832411\n",
      "Iteration 19, loss = 0.00518749\n",
      "\n",
      "Iteration 12, loss = 0.02290721\n",
      "Iteration 30, loss = 0.00053767\n",
      "Iteration 29, loss = 0.00097975\n",
      "Iteration 46, loss = 0.04000762Iteration 26, loss = 0.00273074\n",
      "Iteration 29, loss = 0.00641542\n",
      "Iteration 8, loss = 0.03257530\n",
      "Iteration 20, loss = 0.00440687\n",
      "\n",
      "Iteration 13, loss = 0.01939160\n",
      "Iteration 31, loss = 0.00047809\n",
      "Iteration 30, loss = 0.00083731\n",
      "Iteration 47, loss = 0.00794507Iteration 27, loss = 0.00258625\n",
      "Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "\n",
      "Iteration 9, loss = 0.02751208\n",
      "Iteration 21, loss = 0.00365377\n",
      "\n",
      "Iteration 14, loss = 0.01656922Iteration 1, loss = 0.23679591Iteration 32, loss = 0.00043671\n",
      "Iteration 31, loss = 0.00074145\n",
      "Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "Iteration 28, loss = 0.00422876\n",
      "\n",
      "\n",
      "Iteration 10, loss = 0.02294229\n",
      "Iteration 22, loss = 0.00303253Iteration 1, loss = 0.24656065\n",
      "Iteration 15, loss = 0.01410545Iteration 2, loss = 0.11640547Iteration 33, loss = 0.00043032\n",
      "Iteration 32, loss = 0.00067999\n",
      "\n",
      "Iteration 29, loss = 0.01491703\n",
      "\n",
      "\n",
      "Iteration 11, loss = 0.02012801\n",
      "Iteration 23, loss = 0.00239062Iteration 2, loss = 0.11251907\n",
      "Iteration 16, loss = 0.01135322Iteration 3, loss = 0.09098368Iteration 34, loss = 0.01099826\n",
      "Iteration 33, loss = 0.00060545\n",
      "\n",
      "Iteration 30, loss = 0.00593225\n",
      "\n",
      "\n",
      "Iteration 12, loss = 0.01685930\n",
      "Iteration 24, loss = 0.00192811Iteration 3, loss = 0.08779203\n",
      "Iteration 17, loss = 0.01030176Iteration 4, loss = 0.07602419Iteration 35, loss = 0.02741690\n",
      "Iteration 34, loss = 0.00055489\n",
      "\n",
      "Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "\n",
      "\n",
      "\n",
      "Iteration 13, loss = 0.01373025\n",
      "Iteration 25, loss = 0.00167776Iteration 4, loss = 0.07302121Iteration 1, loss = 0.21873399Iteration 18, loss = 0.00887900Iteration 5, loss = 0.06499885Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "\n",
      "Iteration 35, loss = 0.00049509\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 1, loss = 0.21846742Iteration 14, loss = 0.01124055\n",
      "Iteration 26, loss = 0.00144235Iteration 5, loss = 0.06239896Iteration 2, loss = 0.09607326Iteration 19, loss = 0.00743954Iteration 6, loss = 0.05661417\n",
      "\n",
      "Iteration 36, loss = 0.00053287\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 2, loss = 0.10188815Iteration 15, loss = 0.00966524\n",
      "Iteration 27, loss = 0.00126888Iteration 6, loss = 0.05305446Iteration 3, loss = 0.07299352Iteration 20, loss = 0.00608104Iteration 7, loss = 0.04787902\n",
      "\n",
      "Iteration 37, loss = 0.03952856\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 3, loss = 0.07795019Iteration 16, loss = 0.00723566\n",
      "Iteration 28, loss = 0.00097855Iteration 7, loss = 0.04555371Iteration 4, loss = 0.05992188Iteration 21, loss = 0.00499483Iteration 8, loss = 0.04189104\n",
      "\n",
      "Iteration 38, loss = 0.00864660\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 4, loss = 0.06411221Iteration 17, loss = 0.00605909\n",
      "Iteration 29, loss = 0.00081627Iteration 8, loss = 0.03912137Iteration 5, loss = 0.05029628Iteration 22, loss = 0.00401713Iteration 9, loss = 0.03625514\n",
      "\n",
      "Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 5, loss = 0.05418486Iteration 18, loss = 0.00506144Iteration 1, loss = 0.19700944Iteration 30, loss = 0.00072961Iteration 9, loss = 0.03364433Iteration 6, loss = 0.04212719Iteration 23, loss = 0.00322036Iteration 10, loss = 0.03090210\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 6, loss = 0.04616557Iteration 19, loss = 0.00435974Iteration 2, loss = 0.08450602Iteration 31, loss = 0.00065255Iteration 10, loss = 0.02885240Iteration 7, loss = 0.03551708Iteration 24, loss = 0.00280726Iteration 11, loss = 0.02696192\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 7, loss = 0.03967902Iteration 20, loss = 0.00332526Iteration 3, loss = 0.06379384Iteration 32, loss = 0.00056530Iteration 11, loss = 0.02475714Iteration 8, loss = 0.02978770Iteration 25, loss = 0.00282737Iteration 12, loss = 0.02276095\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 8, loss = 0.03367163Iteration 21, loss = 0.00278233Iteration 4, loss = 0.05184353Iteration 33, loss = 0.00048677Iteration 12, loss = 0.02132915Iteration 9, loss = 0.02509579Iteration 26, loss = 0.00380706Iteration 13, loss = 0.01998023\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 9, loss = 0.02896160Iteration 22, loss = 0.00233274Iteration 5, loss = 0.04239217Iteration 34, loss = 0.00044631Iteration 13, loss = 0.01869907Iteration 10, loss = 0.02192934Iteration 27, loss = 0.01438731Iteration 14, loss = 0.01677132\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 10, loss = 0.02428191Iteration 23, loss = 0.00212228Iteration 6, loss = 0.03542072Iteration 35, loss = 0.00059413Iteration 14, loss = 0.01557898Iteration 11, loss = 0.01764414Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "Iteration 15, loss = 0.01397652\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 1, loss = 0.26197228\n",
      "Iteration 11, loss = 0.02089798Iteration 24, loss = 0.00180414Iteration 7, loss = 0.02951296Iteration 36, loss = 0.03688507Iteration 15, loss = 0.01305773Iteration 12, loss = 0.01497739\n",
      "Iteration 16, loss = 0.01174344\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 2, loss = 0.12031076\n",
      "Iteration 12, loss = 0.01700244Iteration 25, loss = 0.00147066Iteration 8, loss = 0.02509137Iteration 37, loss = 0.00760559Iteration 16, loss = 0.01097717Iteration 13, loss = 0.01270269\n",
      "Iteration 17, loss = 0.01039097\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 3, loss = 0.09361409\n",
      "Iteration 13, loss = 0.01459874Iteration 26, loss = 0.00121073Iteration 9, loss = 0.02096144Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "Iteration 17, loss = 0.00908598Iteration 14, loss = 0.00995182\n",
      "Iteration 18, loss = 0.00884146\n",
      "\n",
      "\n",
      "Iteration 1, loss = 0.20661321\n",
      "\n",
      "Iteration 4, loss = 0.07716212\n",
      "Iteration 14, loss = 0.01203259Iteration 27, loss = 0.00108972Iteration 10, loss = 0.01715366\n",
      "Iteration 18, loss = 0.00774274Iteration 15, loss = 0.00826826\n",
      "Iteration 19, loss = 0.00709411\n",
      "\n",
      "\n",
      "Iteration 2, loss = 0.09261081\n",
      "\n",
      "Iteration 5, loss = 0.06622895\n",
      "Iteration 15, loss = 0.01001602Iteration 28, loss = 0.00094829Iteration 11, loss = 0.01398775\n",
      "Iteration 19, loss = 0.00654850Iteration 16, loss = 0.00651729\n",
      "Iteration 20, loss = 0.00576971\n",
      "\n",
      "\n",
      "Iteration 3, loss = 0.07111924\n",
      "\n",
      "Iteration 6, loss = 0.05693848\n",
      "Iteration 16, loss = 0.00799068Iteration 29, loss = 0.00645703Iteration 12, loss = 0.01103902\n",
      "Iteration 20, loss = 0.00536567Iteration 17, loss = 0.00555151\n",
      "Iteration 21, loss = 0.00488704\n",
      "\n",
      "\n",
      "Iteration 4, loss = 0.05803028\n",
      "\n",
      "Iteration 7, loss = 0.04885528\n",
      "Iteration 17, loss = 0.00692995Iteration 30, loss = 0.02926436Iteration 13, loss = 0.00896895\n",
      "Iteration 21, loss = 0.00450630Iteration 18, loss = 0.00494721\n",
      "Iteration 22, loss = 0.00428016\n",
      "\n",
      "\n",
      "Iteration 5, loss = 0.04779919\n",
      "\n",
      "Iteration 8, loss = 0.04255143\n",
      "Iteration 18, loss = 0.00561541Iteration 31, loss = 0.00657806Iteration 14, loss = 0.00745168\n",
      "Iteration 22, loss = 0.00381845Iteration 19, loss = 0.00394060\n",
      "Iteration 23, loss = 0.00351281\n",
      "\n",
      "\n",
      "Iteration 6, loss = 0.04016511\n",
      "\n",
      "Iteration 9, loss = 0.03705807\n",
      "Iteration 19, loss = 0.00453322Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "Iteration 15, loss = 0.00624842\n",
      "Iteration 23, loss = 0.00327485Iteration 20, loss = 0.00352820\n",
      "Iteration 24, loss = 0.00313396\n",
      "Iteration 1, loss = 0.19840985\n",
      "Iteration 7, loss = 0.03377830\n",
      "\n",
      "Iteration 10, loss = 0.03169777\n",
      "Iteration 20, loss = 0.00405549\n",
      "Iteration 16, loss = 0.00514650\n",
      "Iteration 24, loss = 0.00265308Iteration 21, loss = 0.00293100\n",
      "Iteration 25, loss = 0.00329642\n",
      "Iteration 2, loss = 0.09111972\n",
      "Iteration 8, loss = 0.02876537\n",
      "\n",
      "Iteration 11, loss = 0.02708302\n",
      "Iteration 21, loss = 0.00310217\n",
      "Iteration 17, loss = 0.00409590\n",
      "Iteration 25, loss = 0.00212426Iteration 22, loss = 0.00386074\n",
      "Iteration 26, loss = 0.00336477\n",
      "Iteration 3, loss = 0.07065854\n",
      "Iteration 9, loss = 0.02417290\n",
      "\n",
      "Iteration 12, loss = 0.02326415\n",
      "Iteration 22, loss = 0.00252159\n",
      "Iteration 18, loss = 0.00327099\n",
      "Iteration 26, loss = 0.00186761Iteration 23, loss = 0.00273510\n",
      "Iteration 27, loss = 0.01060789\n",
      "Iteration 4, loss = 0.05774866\n",
      "Iteration 10, loss = 0.01953615\n",
      "\n",
      "Iteration 13, loss = 0.02003959\n",
      "Iteration 23, loss = 0.00214714\n",
      "Iteration 19, loss = 0.00265036\n",
      "Iteration 27, loss = 0.00164179Iteration 24, loss = 0.00702792\n",
      "Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "\n",
      "Iteration 5, loss = 0.04791511\n",
      "Iteration 11, loss = 0.01639312\n",
      "\n",
      "Iteration 14, loss = 0.01752431Iteration 1, loss = 0.23705567Iteration 24, loss = 0.00179453\n",
      "Iteration 20, loss = 0.00239362\n",
      "Iteration 28, loss = 0.00132624Iteration 25, loss = 0.01096623\n",
      "\n",
      "\n",
      "Iteration 6, loss = 0.04017928\n",
      "Iteration 12, loss = 0.01329165\n",
      "\n",
      "Iteration 15, loss = 0.01484178Iteration 2, loss = 0.11636528Iteration 25, loss = 0.00157123\n",
      "Iteration 21, loss = 0.00253493\n",
      "Iteration 29, loss = 0.00129726Iteration 26, loss = 0.00338775\n",
      "\n",
      "\n",
      "Iteration 7, loss = 0.03358335\n",
      "Iteration 13, loss = 0.01071322\n",
      "\n",
      "Iteration 16, loss = 0.01196154Iteration 3, loss = 0.09129766Iteration 26, loss = 0.00124050\n",
      "Iteration 22, loss = 0.00349045\n",
      "Iteration 30, loss = 0.00202925Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "\n",
      "\n",
      "\n",
      "Iteration 8, loss = 0.02799802\n",
      "Iteration 14, loss = 0.00884837\n",
      "Iteration 1, loss = 0.19022024Iteration 17, loss = 0.01022607Iteration 4, loss = 0.07641909Iteration 27, loss = 0.00104868\n",
      "Iteration 23, loss = 0.01032598\n",
      "Iteration 31, loss = 0.03380125\n",
      "\n",
      "\n",
      "\n",
      "Iteration 9, loss = 0.02384468\n",
      "Iteration 15, loss = 0.00742634\n",
      "Iteration 2, loss = 0.09048334Iteration 18, loss = 0.00835279Iteration 5, loss = 0.06427975Iteration 28, loss = 0.00090638\n",
      "Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "\n",
      "Iteration 32, loss = 0.00708335\n",
      "\n",
      "\n",
      "\n",
      "Iteration 10, loss = 0.01983494Iteration 1, loss = 0.22981241Iteration 16, loss = 0.00578084\n",
      "Iteration 3, loss = 0.06976200Iteration 19, loss = 0.00741385Iteration 6, loss = 0.05562864Iteration 29, loss = 0.00080953\n",
      "\n",
      "\n",
      "Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 11, loss = 0.01612649Iteration 2, loss = 0.10648946Iteration 17, loss = 0.00527342Iteration 1, loss = 0.23600848Iteration 4, loss = 0.05796140Iteration 20, loss = 0.00605022Iteration 7, loss = 0.04808782Iteration 30, loss = 0.00077362\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 12, loss = 0.01305977Iteration 3, loss = 0.08186652Iteration 18, loss = 0.00485373Iteration 2, loss = 0.10915981Iteration 5, loss = 0.04798929Iteration 21, loss = 0.00594521Iteration 8, loss = 0.04125400Iteration 31, loss = 0.00066949\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 13, loss = 0.01060364Iteration 4, loss = 0.06754479Iteration 19, loss = 0.00397830Iteration 3, loss = 0.08335497Iteration 6, loss = 0.04095294Iteration 22, loss = 0.00514345Iteration 9, loss = 0.03558741Iteration 32, loss = 0.00064489\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 14, loss = 0.00872470Iteration 5, loss = 0.05750306Iteration 20, loss = 0.00332538Iteration 4, loss = 0.06784975Iteration 7, loss = 0.03449849Iteration 23, loss = 0.00449943Iteration 10, loss = 0.03012456Iteration 33, loss = 0.03880837\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 15, loss = 0.00710550Iteration 6, loss = 0.04802266Iteration 21, loss = 0.00304203Iteration 5, loss = 0.05730520Iteration 8, loss = 0.02963823Iteration 24, loss = 0.00432063Iteration 11, loss = 0.02613155Iteration 34, loss = 0.00768682\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 16, loss = 0.00558659Iteration 7, loss = 0.04116053Iteration 22, loss = 0.00280520Iteration 6, loss = 0.04840316Iteration 9, loss = 0.02490449Iteration 25, loss = 0.00426632Iteration 12, loss = 0.02180529Iteration 35, loss = 0.00168042\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 17, loss = 0.00481790Iteration 8, loss = 0.03606093Iteration 23, loss = 0.00197175Iteration 7, loss = 0.04093472Iteration 10, loss = 0.02053017Iteration 26, loss = 0.00452583Iteration 13, loss = 0.01892044Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 1, loss = 0.24188586Iteration 18, loss = 0.00406340Iteration 9, loss = 0.03017435Iteration 24, loss = 0.00167274Iteration 8, loss = 0.03545457Iteration 11, loss = 0.01720063Iteration 27, loss = 0.00428904Iteration 14, loss = 0.01553440\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 2, loss = 0.10869711Iteration 19, loss = 0.00349710Iteration 10, loss = 0.02596240Iteration 25, loss = 0.00241491Iteration 9, loss = 0.02997471Iteration 12, loss = 0.01457607Iteration 28, loss = 0.00527005Iteration 15, loss = 0.01347869\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 3, loss = 0.08424907Iteration 20, loss = 0.00313173Iteration 11, loss = 0.02237998Iteration 26, loss = 0.01688863Iteration 10, loss = 0.02540630Iteration 13, loss = 0.01191658Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "Iteration 16, loss = 0.01095761\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 1, loss = 0.19263667\n",
      "Iteration 4, loss = 0.06949570Iteration 21, loss = 0.00303399Iteration 12, loss = 0.01854053Iteration 27, loss = 0.00717505Iteration 11, loss = 0.02192740Iteration 14, loss = 0.00997064\n",
      "Iteration 17, loss = 0.00933109\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 2, loss = 0.08786609\n",
      "Iteration 5, loss = 0.05908657Iteration 22, loss = 0.00296024Iteration 13, loss = 0.01565821Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "Iteration 12, loss = 0.01878769Iteration 15, loss = 0.00827203\n",
      "Iteration 18, loss = 0.00765540\n",
      "\n",
      "\n",
      "Iteration 1, loss = 0.22568044\n",
      "\n",
      "Iteration 3, loss = 0.06674249\n",
      "Iteration 6, loss = 0.05063916Iteration 23, loss = 0.00232041Iteration 14, loss = 0.01343356\n",
      "Iteration 13, loss = 0.01510462Iteration 16, loss = 0.00640320\n",
      "Iteration 19, loss = 0.00662886\n",
      "\n",
      "\n",
      "Iteration 2, loss = 0.10153260\n",
      "\n",
      "Iteration 4, loss = 0.05419871\n",
      "Iteration 7, loss = 0.04300780Iteration 24, loss = 0.00265205Iteration 15, loss = 0.01106126\n",
      "Iteration 14, loss = 0.01364183Iteration 17, loss = 0.00541525\n",
      "Iteration 20, loss = 0.00567772\n",
      "\n",
      "\n",
      "Iteration 3, loss = 0.07872392\n",
      "\n",
      "Iteration 5, loss = 0.04480717\n",
      "Iteration 8, loss = 0.03750247Iteration 25, loss = 0.00401194Iteration 16, loss = 0.00922660\n",
      "Iteration 15, loss = 0.01052008Iteration 18, loss = 0.00471910\n",
      "Iteration 21, loss = 0.00480759\n",
      "\n",
      "\n",
      "Iteration 4, loss = 0.06382236\n",
      "\n",
      "Iteration 6, loss = 0.03751001\n",
      "Iteration 9, loss = 0.03194696Iteration 26, loss = 0.01558221Iteration 17, loss = 0.00744610\n",
      "Iteration 16, loss = 0.00901792Iteration 19, loss = 0.00372682\n",
      "Iteration 22, loss = 0.00404829\n",
      "\n",
      "\n",
      "Iteration 5, loss = 0.05352138\n",
      "\n",
      "Iteration 7, loss = 0.03166759\n",
      "Iteration 10, loss = 0.02755440Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "Iteration 18, loss = 0.00610240\n",
      "Iteration 17, loss = 0.00736990Iteration 20, loss = 0.00329874\n",
      "Iteration 23, loss = 0.00303617\n",
      "Iteration 1, loss = 0.18908441\n",
      "Iteration 6, loss = 0.04578100\n",
      "\n",
      "Iteration 8, loss = 0.02744767\n",
      "Iteration 11, loss = 0.02351030\n",
      "Iteration 19, loss = 0.00501584\n",
      "Iteration 18, loss = 0.00572756Iteration 21, loss = 0.00276254\n",
      "Iteration 24, loss = 0.00234826\n",
      "Iteration 2, loss = 0.08753034\n",
      "Iteration 7, loss = 0.03874967\n",
      "\n",
      "Iteration 9, loss = 0.02246472\n",
      "Iteration 12, loss = 0.02022192\n",
      "Iteration 20, loss = 0.00408752\n",
      "Iteration 19, loss = 0.00489045Iteration 22, loss = 0.00205203\n",
      "Iteration 25, loss = 0.00211058\n",
      "Iteration 3, loss = 0.06740874\n",
      "Iteration 8, loss = 0.03290597\n",
      "\n",
      "Iteration 10, loss = 0.01850905\n",
      "Iteration 13, loss = 0.01726148\n",
      "Iteration 21, loss = 0.00335663\n",
      "Iteration 20, loss = 0.00441127Iteration 23, loss = 0.00229588\n",
      "Iteration 26, loss = 0.00178318\n",
      "Iteration 4, loss = 0.05583781\n",
      "Iteration 9, loss = 0.02819433\n",
      "\n",
      "Iteration 11, loss = 0.01519086\n",
      "Iteration 14, loss = 0.01382319\n",
      "Iteration 22, loss = 0.00264967\n",
      "Iteration 21, loss = 0.00368236Iteration 24, loss = 0.00240702\n",
      "Iteration 27, loss = 0.00158975\n",
      "Iteration 5, loss = 0.04595420\n",
      "Iteration 10, loss = 0.02337294\n",
      "\n",
      "Iteration 12, loss = 0.01237946\n",
      "Iteration 15, loss = 0.01158331\n",
      "Iteration 23, loss = 0.00226246\n",
      "Iteration 22, loss = 0.00303527Iteration 25, loss = 0.00287557\n",
      "Iteration 28, loss = 0.00138945\n",
      "Iteration 6, loss = 0.03894905\n",
      "Iteration 11, loss = 0.01999930\n",
      "\n",
      "Iteration 13, loss = 0.01058806\n",
      "Iteration 16, loss = 0.00950155\n",
      "Iteration 24, loss = 0.00187953\n",
      "Iteration 23, loss = 0.00259614Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "\n",
      "Iteration 29, loss = 0.00130423\n",
      "Iteration 7, loss = 0.03351361\n",
      "Iteration 12, loss = 0.01650446\n",
      "Iteration 1, loss = 0.25452169Iteration 14, loss = 0.00829772\n",
      "Iteration 17, loss = 0.00818030\n",
      "Iteration 25, loss = 0.00158920\n",
      "Iteration 24, loss = 0.00266740\n",
      "\n",
      "Iteration 30, loss = 0.00400514\n",
      "Iteration 8, loss = 0.02797040\n",
      "Iteration 13, loss = 0.01399178\n",
      "Iteration 2, loss = 0.11560471Iteration 15, loss = 0.00676239\n",
      "Iteration 18, loss = 0.00731650\n",
      "Iteration 26, loss = 0.00128318\n",
      "Iteration 25, loss = 0.00187001\n",
      "\n",
      "Iteration 31, loss = 0.03453179\n",
      "Iteration 9, loss = 0.02374009\n",
      "Iteration 14, loss = 0.01139168\n",
      "Iteration 3, loss = 0.08948307Iteration 16, loss = 0.00550857\n",
      "Iteration 19, loss = 0.00614214\n",
      "Iteration 27, loss = 0.00119433\n",
      "Iteration 26, loss = 0.00177399\n",
      "\n",
      "Iteration 32, loss = 0.00660817\n",
      "Iteration 10, loss = 0.02022600\n",
      "Iteration 15, loss = 0.00959634\n",
      "Iteration 4, loss = 0.07421592Iteration 17, loss = 0.00465843\n",
      "Iteration 20, loss = 0.00512867\n",
      "Iteration 28, loss = 0.00139892\n",
      "Iteration 27, loss = 0.00134128\n",
      "\n",
      "Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "\n",
      "Iteration 11, loss = 0.01658195\n",
      "Iteration 16, loss = 0.00839613\n",
      "Iteration 5, loss = 0.06301533Iteration 18, loss = 0.00375344Iteration 1, loss = 0.19723076Iteration 21, loss = 0.00395481\n",
      "Iteration 29, loss = 0.02736178\n",
      "Iteration 28, loss = 0.00108085\n",
      "\n",
      "\n",
      "\n",
      "Iteration 12, loss = 0.01365837\n",
      "Iteration 17, loss = 0.00671372\n",
      "Iteration 6, loss = 0.05445120Iteration 19, loss = 0.00342882Iteration 2, loss = 0.09215585Iteration 22, loss = 0.00306523\n",
      "Iteration 30, loss = 0.01220369\n",
      "Iteration 29, loss = 0.00082021\n",
      "\n",
      "\n",
      "\n",
      "Iteration 13, loss = 0.01134442\n",
      "Iteration 18, loss = 0.00497495\n",
      "Iteration 7, loss = 0.04744827Iteration 20, loss = 0.00274312Iteration 3, loss = 0.07037979Iteration 23, loss = 0.00279707\n",
      "Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "\n",
      "Iteration 30, loss = 0.00067489\n",
      "\n",
      "\n",
      "\n",
      "Iteration 14, loss = 0.00926178Iteration 1, loss = 0.20388682Iteration 19, loss = 0.00421082\n",
      "Iteration 8, loss = 0.04161261Iteration 21, loss = 0.00218714Iteration 4, loss = 0.05779708Iteration 24, loss = 0.00215211\n",
      "\n",
      "\n",
      "Iteration 31, loss = 0.00058326\n",
      "\n",
      "\n",
      "\n",
      "Iteration 15, loss = 0.00785778Iteration 2, loss = 0.09406674Iteration 20, loss = 0.00337440\n",
      "Iteration 9, loss = 0.03599370Iteration 22, loss = 0.00198920Iteration 5, loss = 0.04834315Iteration 25, loss = 0.00189907\n",
      "\n",
      "\n",
      "Iteration 32, loss = 0.00050993\n",
      "\n",
      "\n",
      "\n",
      "Iteration 16, loss = 0.00668765Iteration 3, loss = 0.07297123Iteration 21, loss = 0.00315769\n",
      "Iteration 10, loss = 0.03081432Iteration 23, loss = 0.00176156Iteration 6, loss = 0.04083168Iteration 26, loss = 0.00165505\n",
      "\n",
      "\n",
      "Iteration 33, loss = 0.00046159\n",
      "\n",
      "\n",
      "\n",
      "Iteration 17, loss = 0.00525553Iteration 4, loss = 0.06048768Iteration 22, loss = 0.00286310\n",
      "Iteration 11, loss = 0.02668543Iteration 24, loss = 0.00130254Iteration 7, loss = 0.03500586Iteration 27, loss = 0.00156734\n",
      "\n",
      "\n",
      "Iteration 34, loss = 0.00041587\n",
      "\n",
      "\n",
      "\n",
      "Iteration 18, loss = 0.00437452Iteration 5, loss = 0.04982742Iteration 23, loss = 0.00242614\n",
      "Iteration 12, loss = 0.02323432Iteration 25, loss = 0.00103598Iteration 8, loss = 0.02884574Iteration 28, loss = 0.00285549\n",
      "\n",
      "\n",
      "Iteration 35, loss = 0.00039380\n",
      "\n",
      "\n",
      "\n",
      "Iteration 19, loss = 0.00320687Iteration 6, loss = 0.04339070Iteration 24, loss = 0.00202774\n",
      "Iteration 13, loss = 0.01982666Iteration 26, loss = 0.00080513Iteration 9, loss = 0.02461736Iteration 29, loss = 0.02843257\n",
      "\n",
      "\n",
      "Iteration 36, loss = 0.00033536\n",
      "\n",
      "\n",
      "\n",
      "Iteration 20, loss = 0.00276764Iteration 7, loss = 0.03665201Iteration 25, loss = 0.00157630\n",
      "Iteration 14, loss = 0.01730834Iteration 27, loss = 0.00064103Iteration 10, loss = 0.02053193Iteration 30, loss = 0.00906889\n",
      "\n",
      "\n",
      "Iteration 37, loss = 0.00032488\n",
      "\n",
      "\n",
      "\n",
      "Iteration 21, loss = 0.00255617Iteration 8, loss = 0.03105357Iteration 26, loss = 0.00128239\n",
      "Iteration 15, loss = 0.01445571Iteration 28, loss = 0.00055799Iteration 11, loss = 0.01711084Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "\n",
      "\n",
      "\n",
      "Iteration 38, loss = 0.00030162\n",
      "\n",
      "\n",
      "Iteration 1, loss = 0.18963845Iteration 22, loss = 0.00203728Iteration 9, loss = 0.02720459Iteration 27, loss = 0.00100134\n",
      "Iteration 16, loss = 0.01193589Iteration 29, loss = 0.00048153Iteration 12, loss = 0.01400823\n",
      "\n",
      "\n",
      "\n",
      "Iteration 39, loss = 0.04084341\n",
      "\n",
      "\n",
      "Iteration 2, loss = 0.08471611Iteration 23, loss = 0.00191817Iteration 10, loss = 0.02255892Iteration 28, loss = 0.00083356\n",
      "Iteration 17, loss = 0.01100153Iteration 30, loss = 0.00042912Iteration 13, loss = 0.01196239\n",
      "\n",
      "\n",
      "\n",
      "Iteration 40, loss = 0.00795405\n",
      "\n",
      "\n",
      "Iteration 3, loss = 0.06506302Iteration 24, loss = 0.00285787Iteration 11, loss = 0.01893751Iteration 29, loss = 0.00067584\n",
      "Iteration 18, loss = 0.00893618Iteration 31, loss = 0.00037014Iteration 14, loss = 0.00950052\n",
      "\n",
      "\n",
      "\n",
      "Iteration 41, loss = 0.00160227\n",
      "\n",
      "\n",
      "Iteration 4, loss = 0.05292700Iteration 25, loss = 0.01196829Iteration 12, loss = 0.01590501Iteration 30, loss = 0.00058666\n",
      "Iteration 19, loss = 0.00775008Iteration 32, loss = 0.00032975Iteration 15, loss = 0.00747921\n",
      "\n",
      "\n",
      "\n",
      "Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "\n",
      "\n",
      "\n",
      "Iteration 5, loss = 0.04453462Iteration 26, loss = 0.00868919Iteration 13, loss = 0.01347895Iteration 31, loss = 0.00053401Iteration 1, loss = 0.17259590Iteration 20, loss = 0.00615593Iteration 33, loss = 0.00029664Iteration 16, loss = 0.00653110\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 6, loss = 0.03781023Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "Iteration 14, loss = 0.01158378Iteration 32, loss = 0.00045990Iteration 2, loss = 0.07911294Iteration 21, loss = 0.00547517Iteration 34, loss = 0.00027045Iteration 17, loss = 0.00539891\n",
      "Iteration 1, loss = 0.22195080\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 7, loss = 0.03159322\n",
      "Iteration 15, loss = 0.00950951Iteration 33, loss = 0.00042388Iteration 3, loss = 0.05910470Iteration 22, loss = 0.00521305Iteration 35, loss = 0.00024457Iteration 18, loss = 0.00406609\n",
      "Iteration 2, loss = 0.10508008\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 8, loss = 0.02711938\n",
      "Iteration 16, loss = 0.00745331Iteration 34, loss = 0.00036944Iteration 4, loss = 0.04756515Iteration 23, loss = 0.00496370Iteration 36, loss = 0.00021593Iteration 19, loss = 0.00338643\n",
      "Iteration 3, loss = 0.08116652\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 9, loss = 0.02261987\n",
      "Iteration 17, loss = 0.00625864Iteration 35, loss = 0.01371011Iteration 5, loss = 0.03887085Iteration 24, loss = 0.00406082Iteration 37, loss = 0.00019105Iteration 20, loss = 0.00264388\n",
      "Iteration 4, loss = 0.06694501\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 10, loss = 0.01882880\n",
      "Iteration 18, loss = 0.00512263Iteration 36, loss = 0.03227258Iteration 6, loss = 0.03203744Iteration 25, loss = 0.00347146Iteration 38, loss = 0.00017335Iteration 21, loss = 0.00212994\n",
      "Iteration 5, loss = 0.05683287\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 11, loss = 0.01613392\n",
      "Iteration 19, loss = 0.00398040Iteration 37, loss = 0.00509455Iteration 7, loss = 0.02601417Iteration 26, loss = 0.00370514Iteration 39, loss = 0.00014834Iteration 22, loss = 0.00181444\n",
      "Iteration 6, loss = 0.04804436\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 12, loss = 0.01289585\n",
      "Iteration 20, loss = 0.00318267Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "Iteration 8, loss = 0.02196172Iteration 27, loss = 0.00460243Iteration 40, loss = 0.00012917Iteration 23, loss = 0.00146117\n",
      "Iteration 7, loss = 0.04158947\n",
      "Iteration 1, loss = 0.24271482\n",
      "\n",
      "\n",
      "\n",
      "Iteration 13, loss = 0.01068105\n",
      "Iteration 21, loss = 0.00293927\n",
      "Iteration 9, loss = 0.01789741Iteration 28, loss = 0.00965727Iteration 41, loss = 0.02911110Iteration 24, loss = 0.00124088\n",
      "Iteration 8, loss = 0.03525960\n",
      "Iteration 2, loss = 0.10922565\n",
      "\n",
      "\n",
      "\n",
      "Iteration 14, loss = 0.00853304\n",
      "Iteration 22, loss = 0.00233175\n",
      "Iteration 10, loss = 0.01447887Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "Iteration 42, loss = 0.01101554Iteration 25, loss = 0.00109054\n",
      "Iteration 9, loss = 0.02963098\n",
      "Iteration 3, loss = 0.08434956\n",
      "Iteration 1, loss = 0.24741917\n",
      "\n",
      "Iteration 15, loss = 0.00711965\n",
      "Iteration 23, loss = 0.00210601\n",
      "Iteration 11, loss = 0.01131311\n",
      "Iteration 43, loss = 0.00227838Iteration 26, loss = 0.00102028\n",
      "Iteration 10, loss = 0.02541500\n",
      "Iteration 4, loss = 0.06969488\n",
      "Iteration 2, loss = 0.11713376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done   2 out of   8 | elapsed:   50.9s remaining:  2.5min\n",
      "[Parallel(n_jobs=8)]: Done   8 out of   8 | elapsed:   53.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score sur le train : 0.081875\n",
      "\n",
      "Iteration 16, loss = 0.00551285\n",
      "Iteration 24, loss = 0.00361632\n",
      "Iteration 12, loss = 0.00916922\n",
      "Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "Iteration 27, loss = 0.00080052\n",
      "Iteration 11, loss = 0.02178972\n",
      "Iteration 5, loss = 0.05995351\n",
      "Iteration 3, loss = 0.09217721Iteration 1, loss = 0.24778102\n",
      "Iteration 17, loss = 0.00454144\n",
      "Iteration 25, loss = 0.01147950\n",
      "Iteration 13, loss = 0.00741384\n",
      "\n",
      "Iteration 28, loss = 0.00071115\n",
      "Iteration 12, loss = 0.01868553\n",
      "Iteration 6, loss = 0.05142327\n",
      "Iteration 4, loss = 0.07705354Iteration 2, loss = 0.12607377\n",
      "Iteration 18, loss = 0.00366162\n",
      "Iteration 26, loss = 0.00893527\n",
      "Iteration 14, loss = 0.00576616\n",
      "\n",
      "Iteration 29, loss = 0.00061564\n",
      "Iteration 13, loss = 0.01538934\n",
      "Iteration 7, loss = 0.04356739\n",
      "Iteration 5, loss = 0.06613701Iteration 3, loss = 0.09987440\n",
      "Iteration 19, loss = 0.00276184\n",
      "Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "\n",
      "Iteration 15, loss = 0.00471078\n",
      "\n",
      "Iteration 30, loss = 0.02775614\n",
      "Iteration 14, loss = 0.01225069Iteration 1, loss = 0.19868577Iteration 8, loss = 0.03773586\n",
      "Iteration 6, loss = 0.05628390Iteration 4, loss = 0.08401985\n",
      "Iteration 20, loss = 0.00233098\n",
      "\n",
      "\n",
      "Iteration 16, loss = 0.00367535\n",
      "\n",
      "Iteration 31, loss = 0.01361296\n",
      "Iteration 15, loss = 0.00997733Iteration 2, loss = 0.09115869Iteration 9, loss = 0.03250038\n",
      "Iteration 7, loss = 0.04982066Iteration 5, loss = 0.07256905\n",
      "Iteration 21, loss = 0.00186171\n",
      "\n",
      "\n",
      "Iteration 17, loss = 0.00324935\n",
      "\n",
      "Iteration 32, loss = 0.00261813\n",
      "Iteration 16, loss = 0.00847470Iteration 3, loss = 0.07026588Iteration 10, loss = 0.02792348\n",
      "Iteration 8, loss = 0.04230812Iteration 6, loss = 0.06293170\n",
      "Iteration 22, loss = 0.00168215\n",
      "\n",
      "\n",
      "Iteration 18, loss = 0.00243998\n",
      "\n",
      "Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "\n",
      "Iteration 17, loss = 0.00704291Iteration 4, loss = 0.05769422Iteration 11, loss = 0.02458095\n",
      "Iteration 9, loss = 0.03683429Iteration 7, loss = 0.05585148Iteration 1, loss = 0.26028920Iteration 23, loss = 0.00150997\n",
      "\n",
      "\n",
      "Iteration 19, loss = 0.00240431\n",
      "\n",
      "\n",
      "\n",
      "Iteration 18, loss = 0.00596141Iteration 5, loss = 0.04806872Iteration 12, loss = 0.02024217\n",
      "Iteration 10, loss = 0.03106866Iteration 8, loss = 0.04798525Iteration 2, loss = 0.12504265Iteration 24, loss = 0.00382051\n",
      "\n",
      "\n",
      "Iteration 20, loss = 0.00175575\n",
      "\n",
      "\n",
      "\n",
      "Iteration 19, loss = 0.00445776Iteration 6, loss = 0.04035001Iteration 13, loss = 0.01760519\n",
      "Iteration 11, loss = 0.02800343Iteration 9, loss = 0.04247944Iteration 3, loss = 0.09833843Iteration 25, loss = 0.02032007\n",
      "\n",
      "\n",
      "Iteration 21, loss = 0.00166517\n",
      "\n",
      "\n",
      "\n",
      "Iteration 20, loss = 0.00381101Iteration 7, loss = 0.03373752Iteration 14, loss = 0.01455350\n",
      "Iteration 12, loss = 0.02358820Iteration 10, loss = 0.03686227Iteration 4, loss = 0.08233231Iteration 26, loss = 0.00581238\n",
      "\n",
      "\n",
      "Iteration 22, loss = 0.00151510\n",
      "\n",
      "\n",
      "\n",
      "Iteration 21, loss = 0.00311688Iteration 8, loss = 0.02889744Iteration 15, loss = 0.01291400\n",
      "Iteration 13, loss = 0.01983892Iteration 11, loss = 0.03167923Iteration 5, loss = 0.07054021Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "\n",
      "\n",
      "\n",
      "Iteration 23, loss = 0.00302070\n",
      "\n",
      "\n",
      "Iteration 1, loss = 0.20401212Iteration 22, loss = 0.00246564Iteration 9, loss = 0.02431869Iteration 16, loss = 0.01054410\n",
      "Iteration 14, loss = 0.01665942Iteration 12, loss = 0.02775630Iteration 6, loss = 0.06200161\n",
      "\n",
      "\n",
      "\n",
      "Iteration 24, loss = 0.01784758\n",
      "\n",
      "\n",
      "Iteration 2, loss = 0.08880395Iteration 23, loss = 0.00205128Iteration 10, loss = 0.02053557Iteration 17, loss = 0.00894998\n",
      "Iteration 15, loss = 0.01467880Iteration 13, loss = 0.02448590Iteration 7, loss = 0.05316192\n",
      "\n",
      "\n",
      "\n",
      "Iteration 25, loss = 0.00582140\n",
      "\n",
      "\n",
      "Iteration 3, loss = 0.06800912Iteration 24, loss = 0.00175571Iteration 11, loss = 0.01682017Iteration 18, loss = 0.00748673\n",
      "Iteration 16, loss = 0.01292873Iteration 14, loss = 0.02025717Iteration 8, loss = 0.04693225\n",
      "\n",
      "\n",
      "\n",
      "Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "\n",
      "\n",
      "\n",
      "Iteration 4, loss = 0.05575120Iteration 25, loss = 0.00148627Iteration 12, loss = 0.01388702Iteration 19, loss = 0.00647986Iteration 1, loss = 0.21495394Iteration 17, loss = 0.01013244Iteration 15, loss = 0.01750468Iteration 9, loss = 0.04036777\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 5, loss = 0.04672431Iteration 26, loss = 0.00122735Iteration 13, loss = 0.01140592Iteration 20, loss = 0.00585045Iteration 2, loss = 0.09602502Iteration 18, loss = 0.00858444Iteration 16, loss = 0.01530407Iteration 10, loss = 0.03513769\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 6, loss = 0.03872640Iteration 27, loss = 0.00128938Iteration 14, loss = 0.00951816Iteration 21, loss = 0.00445070Iteration 3, loss = 0.07267653Iteration 19, loss = 0.00734379Iteration 17, loss = 0.01318820Iteration 11, loss = 0.03067683\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 7, loss = 0.03286266Iteration 28, loss = 0.00133158Iteration 15, loss = 0.00762698Iteration 22, loss = 0.00426010Iteration 4, loss = 0.06012007Iteration 20, loss = 0.00603929Iteration 18, loss = 0.01102946Iteration 12, loss = 0.02666349\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 8, loss = 0.02743268Iteration 29, loss = 0.02741917Iteration 16, loss = 0.00617634Iteration 23, loss = 0.00351058Iteration 5, loss = 0.04973031Iteration 21, loss = 0.00495100Iteration 19, loss = 0.00892385Iteration 13, loss = 0.02234888\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 9, loss = 0.02296861Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "Iteration 17, loss = 0.00515635Iteration 24, loss = 0.00356415Iteration 6, loss = 0.04182169Iteration 22, loss = 0.00426345Iteration 20, loss = 0.00778744Iteration 14, loss = 0.01975003\n",
      "Iteration 1, loss = 0.21071468\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 10, loss = 0.01916993\n",
      "Iteration 18, loss = 0.00448887Iteration 25, loss = 0.00364618Iteration 7, loss = 0.03582000Iteration 23, loss = 0.00379519Iteration 21, loss = 0.00641873Iteration 15, loss = 0.01745835\n",
      "Iteration 2, loss = 0.09540359\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 11, loss = 0.01618250\n",
      "Iteration 19, loss = 0.00389156Iteration 26, loss = 0.00414423Iteration 8, loss = 0.03003845Iteration 24, loss = 0.00307287Iteration 22, loss = 0.00582786Iteration 16, loss = 0.01481575\n",
      "Iteration 3, loss = 0.07331967\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 12, loss = 0.01308367\n",
      "Iteration 20, loss = 0.00400300Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "Iteration 9, loss = 0.02542462Iteration 25, loss = 0.00262399Iteration 23, loss = 0.00513313Iteration 17, loss = 0.01180793\n",
      "Iteration 4, loss = 0.06045725\n",
      "Iteration 1, loss = 0.20876526\n",
      "\n",
      "\n",
      "\n",
      "Iteration 13, loss = 0.01065098\n",
      "Iteration 21, loss = 0.00344571\n",
      "Iteration 10, loss = 0.02121868Iteration 26, loss = 0.00208727Iteration 24, loss = 0.00447310Iteration 18, loss = 0.01036274\n",
      "Iteration 5, loss = 0.05097334\n",
      "Iteration 2, loss = 0.09438352\n",
      "\n",
      "\n",
      "\n",
      "Iteration 14, loss = 0.00889530\n",
      "Iteration 22, loss = 0.00264210\n",
      "Iteration 11, loss = 0.01798455Iteration 27, loss = 0.00184635Iteration 25, loss = 0.00413371Iteration 19, loss = 0.00890959\n",
      "Iteration 6, loss = 0.04360745\n",
      "Iteration 3, loss = 0.07237207\n",
      "\n",
      "\n",
      "\n",
      "Iteration 15, loss = 0.00694264\n",
      "Iteration 23, loss = 0.00301092\n",
      "Iteration 12, loss = 0.01529872Iteration 28, loss = 0.00150585Iteration 26, loss = 0.00396380Iteration 20, loss = 0.00783860\n",
      "Iteration 7, loss = 0.03630445\n",
      "Iteration 4, loss = 0.05943885\n",
      "\n",
      "\n",
      "\n",
      "Iteration 16, loss = 0.00562498\n",
      "Iteration 24, loss = 0.00240003\n",
      "Iteration 13, loss = 0.01223253Iteration 29, loss = 0.00129843Iteration 27, loss = 0.00430641Iteration 21, loss = 0.00689477\n",
      "Iteration 8, loss = 0.03112722\n",
      "Iteration 5, loss = 0.04983797\n",
      "\n",
      "\n",
      "\n",
      "Iteration 17, loss = 0.00463437\n",
      "Iteration 25, loss = 0.00258389\n",
      "Iteration 14, loss = 0.00987806Iteration 30, loss = 0.00109209Iteration 28, loss = 0.00593205Iteration 22, loss = 0.00559210\n",
      "Iteration 9, loss = 0.02671915\n",
      "Iteration 6, loss = 0.04201338\n",
      "\n",
      "\n",
      "\n",
      "Iteration 18, loss = 0.00353733\n",
      "Iteration 26, loss = 0.01174557\n",
      "Iteration 15, loss = 0.00833291Iteration 31, loss = 0.00090273Iteration 29, loss = 0.01252230Iteration 23, loss = 0.00465760\n",
      "Iteration 10, loss = 0.02292427\n",
      "Iteration 7, loss = 0.03578929\n",
      "\n",
      "\n",
      "\n",
      "Iteration 19, loss = 0.00296423\n",
      "Iteration 27, loss = 0.00907778\n",
      "Iteration 16, loss = 0.00711845Iteration 32, loss = 0.00088830Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "Iteration 24, loss = 0.00396149\n",
      "Iteration 11, loss = 0.01851697\n",
      "Iteration 8, loss = 0.03049143\n",
      "\n",
      "Iteration 1, loss = 0.24855341\n",
      "Iteration 20, loss = 0.00253542\n",
      "Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "\n",
      "Iteration 17, loss = 0.00616940Iteration 33, loss = 0.00189067\n",
      "Iteration 25, loss = 0.00305443\n",
      "Iteration 12, loss = 0.01577004Iteration 1, loss = 0.23789169Iteration 9, loss = 0.02525613\n",
      "\n",
      "Iteration 2, loss = 0.12080226\n",
      "Iteration 21, loss = 0.00208234\n",
      "\n",
      "\n",
      "Iteration 18, loss = 0.00503916Iteration 34, loss = 0.03980585\n"
     ]
    }
   ],
   "source": [
    "# Prediction\n",
    "y_pred_train =  bagging.predict(X_train)\n",
    "y_predict_train_proba = bagging.predict_proba(X_train)[:,0]\n",
    "        \n",
    "for i in range(len(y_pred_train)):\n",
    "    if (y_predict_train_proba[i]<0.9)and(y_predict_train_proba[i]>1-0.9):\n",
    "        y_pred_train[i]=0\n",
    "\n",
    "# score\n",
    "score = compute_pred_score(y_train, y_pred_train)\n",
    "print('Score sur le train : %s' % score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Génération de la prédiction sur le test et enregistrement du fichier à soumettre sur le site:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done   2 out of   8 | elapsed:    5.6s remaining:   16.9s\n",
      "[Parallel(n_jobs=8)]: Done   8 out of   8 | elapsed:    7.4s finished\n",
      "[Parallel(n_jobs=8)]: Done   2 out of   8 | elapsed:    6.1s remaining:   18.3s\n",
      "[Parallel(n_jobs=8)]: Done   8 out of   8 | elapsed:    7.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1  0  1]\n"
     ]
    }
   ],
   "source": [
    "y_pred = bagging.predict(X_test)\n",
    "y_predict_proba = bagging.predict_proba(X_test)[:,0]\n",
    "\n",
    "for i in range(len(y_pred)):\n",
    "    if (y_predict_proba[i]<0.75)and(y_predict_proba[i]>1-0.75):\n",
    "        y_pred[i]=0\n",
    "print np.unique(y_pred)\n",
    "\n",
    "np.savetxt('y_pred_bMLP2.txt', y_pred, fmt='%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 28, loss = 0.00064110\n",
      "\n",
      "\n",
      "\n",
      "Iteration 4, loss = 0.07343867Iteration 23, loss = 0.00384640Iteration 11, loss = 0.01275712\n",
      "Iteration 6, loss = 0.04839489Iteration 30, loss = 0.00036893Iteration 31, loss = 0.00092117Iteration 16, loss = 0.00675603\n",
      "\n",
      "\n",
      "Iteration 29, loss = 0.00055248\n",
      "\n",
      "\n",
      "\n",
      "Iteration 5, loss = 0.06286489Iteration 24, loss = 0.00323915Iteration 12, loss = 0.01070236\n",
      "Iteration 7, loss = 0.04108321Iteration 31, loss = 0.00032987Iteration 32, loss = 0.00085890Iteration 17, loss = 0.00545494\n",
      "\n",
      "\n",
      "Iteration 30, loss = 0.00048797\n",
      "\n",
      "\n",
      "\n",
      "Iteration 6, loss = 0.05404613Iteration 25, loss = 0.00259292Iteration 13, loss = 0.00855817\n",
      "Iteration 8, loss = 0.03499962Iteration 32, loss = 0.00029690Iteration 33, loss = 0.02787446Iteration 18, loss = 0.00452491\n",
      "\n",
      "\n",
      "Iteration 31, loss = 0.00041311\n",
      "\n",
      "\n",
      "\n",
      "Iteration 7, loss = 0.04713042Iteration 26, loss = 0.00250727Iteration 14, loss = 0.00669994\n",
      "Iteration 9, loss = 0.02944457Iteration 33, loss = 0.00026317Iteration 34, loss = 0.01677971Iteration 19, loss = 0.00379320\n",
      "\n",
      "\n",
      "Iteration 32, loss = 0.00035298\n",
      "\n",
      "\n",
      "\n",
      "Iteration 8, loss = 0.04096704Iteration 27, loss = 0.00268879Iteration 15, loss = 0.00521287\n",
      "Iteration 10, loss = 0.02494351Iteration 34, loss = 0.00023495Iteration 35, loss = 0.00435410Iteration 20, loss = 0.00299540\n",
      "\n",
      "\n",
      "Iteration 33, loss = 0.00030995\n",
      "\n",
      "\n",
      "\n",
      "Iteration 9, loss = 0.03517463Iteration 28, loss = 0.01655688Iteration 16, loss = 0.00428755\n",
      "Iteration 11, loss = 0.02170159Iteration 35, loss = 0.00021777Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "Iteration 21, loss = 0.00242201\n",
      "\n",
      "\n",
      "Iteration 34, loss = 0.00027212\n",
      "\n",
      "Iteration 1, loss = 0.20480673\n",
      "Iteration 10, loss = 0.03048304Iteration 29, loss = 0.01579408Iteration 17, loss = 0.00346443\n",
      "Iteration 12, loss = 0.01799310Iteration 36, loss = 0.00019054\n",
      "Iteration 22, loss = 0.00199339\n",
      "\n",
      "\n",
      "Iteration 35, loss = 0.00024945\n",
      "\n",
      "Iteration 2, loss = 0.10215383\n",
      "Iteration 11, loss = 0.02703080Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "Iteration 18, loss = 0.00305608\n",
      "Iteration 13, loss = 0.01503093Iteration 37, loss = 0.00016836\n",
      "Iteration 23, loss = 0.00171493\n",
      "Iteration 1, loss = 0.18733654\n",
      "Iteration 36, loss = 0.00023118\n",
      "\n",
      "Iteration 3, loss = 0.07954112\n",
      "Iteration 12, loss = 0.02253260\n",
      "Iteration 19, loss = 0.00230672\n",
      "Iteration 14, loss = 0.01236974Iteration 38, loss = 0.00014473\n",
      "Iteration 24, loss = 0.00138819\n",
      "Iteration 2, loss = 0.08647080\n",
      "Iteration 37, loss = 0.01204027\n",
      "\n",
      "Iteration 4, loss = 0.06526724\n",
      "Iteration 13, loss = 0.01975623\n",
      "Iteration 20, loss = 0.00180780\n",
      "Iteration 15, loss = 0.01010712Iteration 39, loss = 0.00012836\n",
      "Iteration 25, loss = 0.00119483\n",
      "Iteration 3, loss = 0.06541129\n",
      "Iteration 38, loss = 0.02642539\n",
      "\n",
      "Iteration 5, loss = 0.05513149\n",
      "Iteration 14, loss = 0.01645415\n",
      "Iteration 21, loss = 0.00174142\n",
      "Iteration 16, loss = 0.00873314Iteration 40, loss = 0.00011391\n",
      "Iteration 26, loss = 0.00105914\n",
      "Iteration 4, loss = 0.05209883\n",
      "Iteration 39, loss = 0.00397557\n",
      "\n",
      "Iteration 6, loss = 0.04660293\n",
      "Iteration 15, loss = 0.01367582\n",
      "Iteration 22, loss = 0.00145539\n",
      "Iteration 17, loss = 0.00699469Iteration 41, loss = 0.00010317\n",
      "Iteration 27, loss = 0.00085493\n",
      "Iteration 5, loss = 0.04281617\n",
      "Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "\n",
      "\n",
      "Iteration 7, loss = 0.03963748\n",
      "Iteration 16, loss = 0.01216220\n",
      "Iteration 23, loss = 0.00127711Iteration 1, loss = 0.20731679Iteration 18, loss = 0.00589779Iteration 42, loss = 0.00009371\n",
      "Iteration 28, loss = 0.00069653\n",
      "Iteration 6, loss = 0.03571634\n",
      "\n",
      "\n",
      "\n",
      "Iteration 8, loss = 0.03394190\n",
      "Iteration 17, loss = 0.01014354\n",
      "Iteration 24, loss = 0.00107615Iteration 2, loss = 0.09349109Iteration 19, loss = 0.00469421Iteration 43, loss = 0.00008608\n",
      "Iteration 29, loss = 0.00062394\n",
      "Iteration 7, loss = 0.02986505\n",
      "\n",
      "\n",
      "\n",
      "Iteration 9, loss = 0.02885700\n",
      "Iteration 18, loss = 0.00812231\n",
      "Iteration 25, loss = 0.01581563Iteration 3, loss = 0.07097687Iteration 20, loss = 0.00400799Iteration 44, loss = 0.03569407\n",
      "Iteration 30, loss = 0.00057008\n",
      "Iteration 8, loss = 0.02490488\n",
      "\n",
      "\n",
      "\n",
      "Iteration 10, loss = 0.02511136\n",
      "Iteration 19, loss = 0.00715018\n",
      "Iteration 26, loss = 0.00842894Iteration 4, loss = 0.05803498Iteration 21, loss = 0.00389216Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "\n",
      "Iteration 31, loss = 0.00066110\n",
      "Iteration 9, loss = 0.02059484\n",
      "\n",
      "\n",
      "Iteration 1, loss = 0.20818753Iteration 11, loss = 0.02083780\n",
      "Iteration 20, loss = 0.00585821\n",
      "Iteration 27, loss = 0.00226927Iteration 5, loss = 0.04834169Iteration 22, loss = 0.00312867\n",
      "\n",
      "Iteration 32, loss = 0.03685974\n",
      "Iteration 10, loss = 0.01732271\n",
      "\n",
      "\n",
      "Iteration 2, loss = 0.09727299Iteration 12, loss = 0.01780556\n",
      "Iteration 21, loss = 0.00501962\n",
      "Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "Iteration 6, loss = 0.04005878Iteration 23, loss = 0.00244152\n",
      "\n",
      "Iteration 33, loss = 0.00634088\n",
      "Iteration 11, loss = 0.01408904Iteration 1, loss = 0.23538427\n",
      "\n",
      "Iteration 3, loss = 0.07535771Iteration 13, loss = 0.01452122\n",
      "Iteration 22, loss = 0.00460302\n",
      "\n",
      "Iteration 7, loss = 0.03393110Iteration 24, loss = 0.00194368\n",
      "\n",
      "Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "\n",
      "Iteration 12, loss = 0.01102857Iteration 2, loss = 0.11481435\n",
      "\n",
      "Iteration 4, loss = 0.06235125Iteration 14, loss = 0.01225419Iteration 1, loss = 0.22168484Iteration 23, loss = 0.00454748\n",
      "\n",
      "Iteration 8, loss = 0.02892413Iteration 25, loss = 0.00159285\n",
      "\n",
      "\n",
      "\n",
      "Iteration 13, loss = 0.00914340Iteration 3, loss = 0.09054216\n",
      "\n",
      "Iteration 5, loss = 0.05206426Iteration 15, loss = 0.01032080Iteration 2, loss = 0.10281727Iteration 24, loss = 0.00405073\n",
      "\n",
      "Iteration 9, loss = 0.02401903Iteration 26, loss = 0.00123875\n",
      "\n",
      "\n",
      "\n",
      "Iteration 14, loss = 0.00740170Iteration 4, loss = 0.07581266\n",
      "\n",
      "Iteration 6, loss = 0.04382477Iteration 16, loss = 0.00885729Iteration 3, loss = 0.07910341Iteration 25, loss = 0.00381090\n",
      "\n",
      "Iteration 10, loss = 0.02020174Iteration 27, loss = 0.00107764\n",
      "\n",
      "\n",
      "\n",
      "Iteration 15, loss = 0.00594334Iteration 5, loss = 0.06467880\n",
      "\n",
      "Iteration 7, loss = 0.03722565Iteration 17, loss = 0.00755797Iteration 4, loss = 0.06592008Iteration 26, loss = 0.00329613\n",
      "\n",
      "Iteration 11, loss = 0.01651276Iteration 28, loss = 0.00090453\n",
      "\n",
      "\n",
      "\n",
      "Iteration 16, loss = 0.00455458Iteration 6, loss = 0.05604073\n",
      "\n",
      "Iteration 8, loss = 0.03182362Iteration 18, loss = 0.00605951Iteration 5, loss = 0.05558368Iteration 27, loss = 0.00258511\n",
      "\n",
      "Iteration 12, loss = 0.01356523Iteration 29, loss = 0.00076134\n",
      "\n",
      "\n",
      "\n",
      "Iteration 17, loss = 0.00388579Iteration 7, loss = 0.04812649\n",
      "\n",
      "Iteration 9, loss = 0.02662755Iteration 19, loss = 0.00523712Iteration 6, loss = 0.04724438Iteration 28, loss = 0.00182699\n",
      "\n",
      "Iteration 13, loss = 0.01150783Iteration 30, loss = 0.00067502\n",
      "\n",
      "\n",
      "\n",
      "Iteration 18, loss = 0.00284839Iteration 8, loss = 0.04293788\n",
      "\n",
      "Iteration 10, loss = 0.02299889Iteration 20, loss = 0.00440096Iteration 7, loss = 0.04037127Iteration 29, loss = 0.00147465\n",
      "\n",
      "Iteration 14, loss = 0.00910828Iteration 31, loss = 0.00062242\n",
      "\n",
      "\n",
      "\n",
      "Iteration 19, loss = 0.00233430Iteration 9, loss = 0.03683775\n",
      "\n",
      "Iteration 11, loss = 0.01954001Iteration 21, loss = 0.00333162Iteration 8, loss = 0.03458284Iteration 30, loss = 0.00142922\n",
      "\n",
      "Iteration 15, loss = 0.00748681Iteration 32, loss = 0.00053710\n",
      "\n",
      "\n",
      "\n",
      "Iteration 20, loss = 0.00188347Iteration 10, loss = 0.03197308\n",
      "\n",
      "Iteration 12, loss = 0.01560050Iteration 22, loss = 0.00304528Iteration 9, loss = 0.02920705Iteration 31, loss = 0.00164885\n",
      "\n",
      "Iteration 16, loss = 0.00608814Iteration 33, loss = 0.00047803\n",
      "\n",
      "\n",
      "\n",
      "Iteration 21, loss = 0.00158140Iteration 11, loss = 0.02743404\n",
      "\n",
      "Iteration 13, loss = 0.01310842Iteration 23, loss = 0.00256255Iteration 10, loss = 0.02470531Iteration 32, loss = 0.02834095\n",
      "\n",
      "Iteration 17, loss = 0.00555567Iteration 34, loss = 0.01981838\n",
      "\n",
      "\n",
      "\n",
      "Iteration 22, loss = 0.00124236Iteration 12, loss = 0.02371595\n",
      "\n",
      "Iteration 14, loss = 0.01107808Iteration 24, loss = 0.00214390Iteration 11, loss = 0.02084597Iteration 33, loss = 0.01031396\n",
      "\n",
      "Iteration 18, loss = 0.00478642Iteration 35, loss = 0.02194833\n",
      "\n",
      "\n",
      "\n",
      "Iteration 23, loss = 0.00107296Iteration 13, loss = 0.02042888\n",
      "\n",
      "Iteration 15, loss = 0.00926091Iteration 25, loss = 0.00259444Iteration 12, loss = 0.01777227Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "\n",
      "\n",
      "Iteration 19, loss = 0.00401501Iteration 36, loss = 0.00372747\n",
      "\n",
      "\n",
      "Iteration 1, loss = 0.20569249Iteration 24, loss = 0.00091150Iteration 14, loss = 0.01773642\n",
      "\n",
      "Iteration 16, loss = 0.00771215Iteration 26, loss = 0.01579413Iteration 13, loss = 0.01449506\n",
      "\n",
      "\n",
      "Iteration 20, loss = 0.00358362Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "\n",
      "\n",
      "\n",
      "Iteration 2, loss = 0.09572625Iteration 25, loss = 0.00080693Iteration 15, loss = 0.01493407"
     ]
    }
   ],
   "source": [
    "# 0.164312617702"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
