{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prédiction du genre d'une personne à partir de sa photo\n",
    "## MLPClassifier\n",
    "\n",
    "auteur : Rui SONG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Imports and initializations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Critere de performance\n",
    "def compute_pred_score(y_true, y_pred):\n",
    "    y_pred_unq =  np.unique(y_pred)\n",
    "    for i in y_pred_unq:\n",
    "        if((i != -1) & (i!= 1) & (i!= 0) ):\n",
    "            raise ValueError('The predictions can contain only -1, 1, or 0!')\n",
    "    y_comp = y_true * y_pred\n",
    "    score = float(10*np.sum(y_comp == -1) + np.sum(y_comp == 0))\n",
    "    score /= y_comp.shape[0]\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "X_train_fname = 'training_templates.csv'\n",
    "y_train_fname = 'training_labels.txt'\n",
    "X_test_fname  = 'testing_templates.csv'\n",
    "X_train = pd.read_csv(X_train_fname, sep=',', header=None).values\n",
    "X_test  = pd.read_csv(X_test_fname,  sep=',', header=None).values\n",
    "y_train = np.loadtxt(y_train_fname, dtype=np.int)\n",
    "\n",
    "X_scaler = StandardScaler()\n",
    "X_train = X_scaler.fit_transform(X_train)\n",
    "X_test = X_scaler.transform(X_test)\n",
    "\n",
    "pca=PCA()\n",
    "X_train = pca.fit_transform(X_train)\n",
    "X_test = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done   2 out of   8 | elapsed: 28.3min remaining: 84.8min\n",
      "[Parallel(n_jobs=8)]: Done   8 out of   8 | elapsed: 29.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 2.02080720\n",
      "Iteration 1, loss = 2.01190016\n",
      "Iteration 1, loss = 2.03285140\n",
      "Iteration 1, loss = 2.01236032\n",
      "Iteration 1, loss = 2.03513861\n",
      "Iteration 1, loss = 2.06590968\n",
      "Iteration 1, loss = 2.07643542\n",
      "Iteration 1, loss = 2.02164731\n",
      "Iteration 2, loss = 0.45733635Iteration 2, loss = 0.45483234Iteration 2, loss = 0.47323915Iteration 2, loss = 0.46857374Iteration 2, loss = 0.45639762Iteration 2, loss = 0.50072342Iteration 2, loss = 0.50232935Iteration 2, loss = 0.44577002\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 3, loss = 0.44422306Iteration 3, loss = 0.44224560Iteration 3, loss = 0.46033944Iteration 3, loss = 0.45645499Iteration 3, loss = 0.44241689Iteration 3, loss = 0.48850006Iteration 3, loss = 0.48725742Iteration 3, loss = 0.43314300\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 4, loss = 0.44153567Iteration 4, loss = 0.43817343Iteration 4, loss = 0.45647364Iteration 4, loss = 0.45318471Iteration 4, loss = 0.43841733Iteration 4, loss = 0.48508105Iteration 4, loss = 0.48317568Iteration 4, loss = 0.42989731\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 5, loss = 0.44002648Iteration 5, loss = 0.43678851Iteration 5, loss = 0.45509277Iteration 5, loss = 0.45203080Iteration 5, loss = 0.43731435Iteration 5, loss = 0.48308342Iteration 5, loss = 0.48183472Iteration 5, loss = 0.42823483\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 6, loss = 0.43955594Iteration 6, loss = 0.43637930Iteration 6, loss = 0.45437378Iteration 6, loss = 0.45077107Iteration 6, loss = 0.43525922Iteration 6, loss = 0.48161487Iteration 6, loss = 0.48098081Iteration 6, loss = 0.42674907\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 7, loss = 0.43869088Iteration 7, loss = 0.43542896Iteration 7, loss = 0.45347250Iteration 7, loss = 0.44975302Iteration 7, loss = 0.43455992Iteration 7, loss = 0.48129047Iteration 7, loss = 0.48031273Iteration 7, loss = 0.42584653\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 8, loss = 0.43841624Iteration 8, loss = 0.43470679Iteration 8, loss = 0.45371873Iteration 8, loss = 0.44881399Iteration 8, loss = 0.43443834Iteration 8, loss = 0.48096732Iteration 8, loss = 0.47957528Iteration 8, loss = 0.42579690\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 9, loss = 0.43748952Iteration 9, loss = 0.43444320Iteration 9, loss = 0.45218618Iteration 9, loss = 0.44903492Iteration 9, loss = 0.43388639Iteration 9, loss = 0.48035071Iteration 9, loss = 0.47918834Iteration 9, loss = 0.42560785\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 10, loss = 0.43691817Iteration 10, loss = 0.43521373Iteration 10, loss = 0.45156529Iteration 10, loss = 0.44817587Iteration 10, loss = 0.43407008Iteration 10, loss = 0.48048803Iteration 10, loss = 0.47900037Iteration 10, loss = 0.42505439\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 11, loss = 0.43660340Iteration 11, loss = 0.43385252Iteration 11, loss = 0.45159217Iteration 11, loss = 0.44851887Iteration 11, loss = 0.43343046Iteration 11, loss = 0.48023353Iteration 11, loss = 0.47779601Iteration 11, loss = 0.42569153\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 12, loss = 0.43739332Iteration 12, loss = 0.43371348Iteration 12, loss = 0.45204624Iteration 12, loss = 0.44828120Iteration 12, loss = 0.43347539Iteration 12, loss = 0.48031869Iteration 12, loss = 0.47767584Iteration 12, loss = 0.42459554\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 13, loss = 0.43623527Iteration 13, loss = 0.43387363Iteration 13, loss = 0.45154768Iteration 13, loss = 0.44794106Iteration 13, loss = 0.43275407Iteration 13, loss = 0.48043933Iteration 13, loss = 0.47779196Iteration 13, loss = 0.42498117\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 14, loss = 0.43684836Iteration 14, loss = 0.43326851Iteration 14, loss = 0.45194156Iteration 14, loss = 0.44840229Iteration 14, loss = 0.43256351Iteration 14, loss = 0.47989165Iteration 14, loss = 0.47759752Iteration 14, loss = 0.42401353\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 15, loss = 0.43703517Iteration 15, loss = 0.43331170Iteration 15, loss = 0.45131185Iteration 15, loss = 0.44729629Iteration 15, loss = 0.43263453Iteration 15, loss = 0.47932615Iteration 15, loss = 0.47784467Iteration 15, loss = 0.42402540\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 16, loss = 0.43668810Iteration 16, loss = 0.43335890Iteration 16, loss = 0.45117108Iteration 16, loss = 0.44830540Iteration 16, loss = 0.43288522Iteration 16, loss = 0.47869064Iteration 16, loss = 0.47706498Iteration 16, loss = 0.42446419\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "Iteration 17, loss = 0.43370564Iteration 17, loss = 0.45077753Iteration 17, loss = 0.44729957Iteration 17, loss = 0.43289051Iteration 17, loss = 0.47923313Iteration 17, loss = 0.47847626Iteration 17, loss = 0.42404701"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=MLPClassifier(activation='relu', alpha=10, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100, 100, 100), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=42, shuffle=True,\n",
       "       solver='adam', tol=1e-05, validation_fraction=0.1, verbose=True,\n",
       "       warm_start=False),\n",
       "         bootstrap=True, bootstrap_features=False, max_features=0.7,\n",
       "         max_samples=0.5, n_estimators=200, n_jobs=-1, oob_score=False,\n",
       "         random_state=None, verbose=True, warm_start=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 2.05293660\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "Iteration 18, loss = 0.45098637Iteration 18, loss = 0.44765833Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "Iteration 18, loss = 0.47922829Iteration 18, loss = 0.47723591Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "Iteration 2, loss = 0.51505363Iteration 1, loss = 2.01637421\n",
      "\n",
      "Iteration 1, loss = 2.01868964\n",
      "\n",
      "Iteration 1, loss = 2.04095181\n",
      "\n",
      "Iteration 19, loss = 0.45086153Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "\n",
      "Iteration 19, loss = 0.47877928Iteration 19, loss = 0.47715182\n",
      "Iteration 3, loss = 0.50233086Iteration 2, loss = 0.43692592\n",
      "Iteration 1, loss = 2.03169939Iteration 2, loss = 0.45265451\n",
      "\n",
      "Iteration 2, loss = 0.47939286\n",
      "\n",
      "Iteration 20, loss = 0.45056814\n",
      "\n",
      "Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "\n",
      "Iteration 4, loss = 0.49874434Iteration 3, loss = 0.42267779\n",
      "Iteration 2, loss = 0.47765970Iteration 3, loss = 0.43854779Iteration 1, loss = 2.04458474Iteration 1, loss = 2.01244976Iteration 3, loss = 0.46723978\n",
      "\n",
      "Iteration 21, loss = 0.45053825\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 5, loss = 0.49705027Iteration 4, loss = 0.41896043\n",
      "Iteration 3, loss = 0.46478633Iteration 4, loss = 0.43453957Iteration 2, loss = 0.49202960Iteration 2, loss = 0.47113811Iteration 4, loss = 0.46319692\n",
      "\n",
      "Iteration 22, loss = 0.45025708\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 6, loss = 0.49652098Iteration 5, loss = 0.41772344\n",
      "Iteration 4, loss = 0.46188633Iteration 5, loss = 0.43376337Iteration 3, loss = 0.47799443Iteration 3, loss = 0.45941124Iteration 5, loss = 0.46211308\n",
      "\n",
      "Iteration 23, loss = 0.45069525\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 7, loss = 0.49500025Iteration 6, loss = 0.41584129\n",
      "Iteration 5, loss = 0.45951433Iteration 6, loss = 0.43197281Iteration 4, loss = 0.47472641Iteration 4, loss = 0.45606319Iteration 6, loss = 0.46093966\n",
      "\n",
      "Iteration 24, loss = 0.45064262\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 8, loss = 0.49539484Iteration 7, loss = 0.41538928\n",
      "Iteration 6, loss = 0.45936445Iteration 7, loss = 0.43139968Iteration 5, loss = 0.47348775Iteration 5, loss = 0.45558159Iteration 7, loss = 0.46035346\n",
      "\n",
      "Iteration 25, loss = 0.45020350\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 9, loss = 0.49458758Iteration 8, loss = 0.41470711\n",
      "Iteration 7, loss = 0.45847630Iteration 8, loss = 0.43095674Iteration 6, loss = 0.47281290Iteration 6, loss = 0.45379579Iteration 8, loss = 0.45958292\n",
      "\n",
      "Iteration 26, loss = 0.45024701\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 10, loss = 0.49405129Iteration 9, loss = 0.41424520\n",
      "Iteration 8, loss = 0.45822615Iteration 9, loss = 0.43058462Iteration 7, loss = 0.47137076Iteration 7, loss = 0.45375764Iteration 9, loss = 0.45871615\n",
      "\n",
      "Iteration 27, loss = 0.45066674\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 11, loss = 0.49347216Iteration 10, loss = 0.41496822\n",
      "Iteration 9, loss = 0.45729886Iteration 10, loss = 0.43007164Iteration 8, loss = 0.47083711Iteration 8, loss = 0.45365019Iteration 10, loss = 0.45900965\n",
      "\n",
      "Iteration 28, loss = 0.45018605\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 12, loss = 0.49446433Iteration 11, loss = 0.41439745\n",
      "Iteration 10, loss = 0.45759730Iteration 11, loss = 0.43004637Iteration 9, loss = 0.46971531Iteration 9, loss = 0.45303681Iteration 11, loss = 0.45869829\n",
      "\n",
      "Iteration 29, loss = 0.44997304\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 13, loss = 0.49434122Iteration 12, loss = 0.41352729\n",
      "Iteration 11, loss = 0.45746706Iteration 12, loss = 0.43007272Iteration 10, loss = 0.47031680Iteration 10, loss = 0.45263573Iteration 12, loss = 0.45796041\n",
      "\n",
      "Iteration 30, loss = 0.45013913\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 14, loss = 0.49291662Iteration 13, loss = 0.41399771\n",
      "Iteration 12, loss = 0.45700588Iteration 13, loss = 0.42999601Iteration 11, loss = 0.46932732Iteration 11, loss = 0.45230823Iteration 13, loss = 0.45794707\n",
      "\n",
      "Iteration 31, loss = 0.45006665\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 15, loss = 0.49279087Iteration 14, loss = 0.41308562\n",
      "Iteration 13, loss = 0.45680009Iteration 14, loss = 0.42958321Iteration 12, loss = 0.47004418Iteration 12, loss = 0.45254534Iteration 14, loss = 0.45744599\n",
      "\n",
      "Iteration 32, loss = 0.45063031\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 16, loss = 0.49252636Iteration 15, loss = 0.41377881\n",
      "Iteration 14, loss = 0.45657116Iteration 15, loss = 0.42958798Iteration 13, loss = 0.46900996Iteration 13, loss = 0.45235227Iteration 15, loss = 0.45792492\n",
      "\n",
      "Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 17, loss = 0.49274087Iteration 16, loss = 0.41351597Iteration 1, loss = 2.07876222Iteration 15, loss = 0.45720241Iteration 16, loss = 0.42893922Iteration 14, loss = 0.46879519Iteration 14, loss = 0.45176510Iteration 16, loss = 0.45780723\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 18, loss = 0.49250850Iteration 17, loss = 0.41291100Iteration 2, loss = 0.48541227Iteration 16, loss = 0.45615385Iteration 17, loss = 0.42892024Iteration 15, loss = 0.46838119Iteration 15, loss = 0.45206620Iteration 17, loss = 0.45740959\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 19, loss = 0.49188813Iteration 18, loss = 0.41247386Iteration 3, loss = 0.47186928Iteration 17, loss = 0.45591876Iteration 18, loss = 0.42942671Iteration 16, loss = 0.46857782Iteration 16, loss = 0.45152732Iteration 18, loss = 0.45779963\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 20, loss = 0.49267858Iteration 19, loss = 0.41266466Iteration 4, loss = 0.46913332Iteration 18, loss = 0.45575228Iteration 19, loss = 0.42864825Iteration 17, loss = 0.46910199Iteration 17, loss = 0.45172728Iteration 19, loss = 0.45818861\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 21, loss = 0.49272943Iteration 20, loss = 0.41252415Iteration 5, loss = 0.46671411Iteration 19, loss = 0.45597328Iteration 20, loss = 0.42839775Iteration 18, loss = 0.46869613Iteration 18, loss = 0.45149570Iteration 20, loss = 0.45691870\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 22, loss = 0.49213476Iteration 21, loss = 0.41266144Iteration 6, loss = 0.46582945Iteration 20, loss = 0.45646179Iteration 21, loss = 0.42838227Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "Iteration 19, loss = 0.45181827Iteration 21, loss = 0.45730968\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 1, loss = 2.06872904\n",
      "\n",
      "Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "Iteration 7, loss = 0.46587950Iteration 21, loss = 0.45611847Iteration 22, loss = 0.42908230\n",
      "Iteration 20, loss = 0.45146434Iteration 22, loss = 0.45708222Iteration 1, loss = 2.09907662Iteration 1, loss = 2.04240568\n",
      "\n",
      "\n",
      "Iteration 2, loss = 0.51419088\n",
      "\n",
      "\n",
      "\n",
      "Iteration 8, loss = 0.46489145Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "Iteration 23, loss = 0.42848158\n",
      "Iteration 21, loss = 0.45127440Iteration 23, loss = 0.45691278Iteration 2, loss = 0.46939112Iteration 2, loss = 0.43043285\n",
      "Iteration 1, loss = 2.05509212\n",
      "Iteration 3, loss = 0.50233376\n",
      "\n",
      "\n",
      "\n",
      "Iteration 9, loss = 0.46424605\n",
      "Iteration 24, loss = 0.42826904\n",
      "Iteration 22, loss = 0.45113999Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "Iteration 3, loss = 0.45502939Iteration 3, loss = 0.41712942\n",
      "Iteration 2, loss = 0.50891125\n",
      "Iteration 4, loss = 0.49955996\n",
      "Iteration 1, loss = 2.17052284\n",
      "\n",
      "Iteration 10, loss = 0.46430478\n",
      "Iteration 25, loss = 0.42775062\n",
      "Iteration 23, loss = 0.45176942\n",
      "Iteration 4, loss = 0.45118063Iteration 4, loss = 0.41419345\n",
      "Iteration 3, loss = 0.49420972\n",
      "Iteration 5, loss = 0.49776172\n",
      "Iteration 2, loss = 0.56486750\n",
      "\n",
      "Iteration 11, loss = 0.46364940\n",
      "Iteration 26, loss = 0.42846581\n",
      "Iteration 24, loss = 0.45078991\n",
      "Iteration 5, loss = 0.44907953Iteration 5, loss = 0.41229986\n",
      "Iteration 4, loss = 0.49099612\n",
      "Iteration 6, loss = 0.49668613\n",
      "Iteration 3, loss = 0.55148921\n",
      "\n",
      "Iteration 12, loss = 0.46392653\n",
      "Iteration 27, loss = 0.42839736\n",
      "Iteration 25, loss = 0.45054649\n",
      "Iteration 6, loss = 0.44928181Iteration 6, loss = 0.41088932\n",
      "Iteration 5, loss = 0.48850185\n",
      "Iteration 7, loss = 0.49641052\n",
      "Iteration 4, loss = 0.54676575\n",
      "\n",
      "Iteration 13, loss = 0.46315549\n",
      "Iteration 28, loss = 0.42800167\n",
      "Iteration 26, loss = 0.45089581\n",
      "Iteration 7, loss = 0.44887211Iteration 7, loss = 0.40999956\n",
      "Iteration 6, loss = 0.48821820\n",
      "Iteration 8, loss = 0.49636352\n",
      "Iteration 5, loss = 0.54642009\n",
      "\n",
      "Iteration 14, loss = 0.46293744\n",
      "Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "\n",
      "Iteration 27, loss = 0.45085922\n",
      "Iteration 8, loss = 0.44824466Iteration 8, loss = 0.40960729\n",
      "Iteration 7, loss = 0.48737766Iteration 1, loss = 2.04268944Iteration 9, loss = 0.49570169\n",
      "Iteration 6, loss = 0.54497414\n",
      "\n",
      "Iteration 15, loss = 0.46325544\n",
      "\n",
      "\n",
      "Iteration 28, loss = 0.45100593\n",
      "Iteration 9, loss = 0.44792021Iteration 9, loss = 0.40930364\n",
      "Iteration 8, loss = 0.48691793Iteration 2, loss = 0.49749410Iteration 10, loss = 0.49516952\n",
      "Iteration 7, loss = 0.54398614\n",
      "\n",
      "Iteration 16, loss = 0.46370802\n",
      "\n",
      "\n",
      "Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "\n",
      "Iteration 10, loss = 0.44740051Iteration 10, loss = 0.40931527\n",
      "Iteration 9, loss = 0.48718295Iteration 3, loss = 0.48669947Iteration 11, loss = 0.49538735Iteration 1, loss = 2.07678906Iteration 8, loss = 0.54394498"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "clf = MLPClassifier(alpha=10, hidden_layer_sizes=(100,100,100), tol=0.00001, random_state=42, verbose=True)\n",
    "bagging = BaggingClassifier(base_estimator=clf,n_estimators=200,max_samples=0.5, max_features=0.7,verbose=True,n_jobs=-1)\n",
    "\n",
    "bagging.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Iteration 17, loss = 0.46259578\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 11, loss = 0.44720251Iteration 11, loss = 0.40938772\n",
      "Iteration 10, loss = 0.48670979Iteration 4, loss = 0.48307312Iteration 12, loss = 0.49505125Iteration 2, loss = 0.50659349Iteration 9, loss = 0.54393550\n",
      "\n",
      "Iteration 18, loss = 0.46243916\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 12, loss = 0.44730490Iteration 12, loss = 0.40874448\n",
      "Iteration 11, loss = 0.48674757Iteration 5, loss = 0.48078020Iteration 13, loss = 0.49436882Iteration 3, loss = 0.49322389Iteration 10, loss = 0.54261963\n",
      "\n",
      "Iteration 19, loss = 0.46269326\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 13, loss = 0.44690319Iteration 13, loss = 0.40834904\n",
      "Iteration 12, loss = 0.48601248Iteration 6, loss = 0.48101734Iteration 14, loss = 0.49453841Iteration 4, loss = 0.48895181Iteration 11, loss = 0.54310587\n",
      "\n",
      "Iteration 20, loss = 0.46236056\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 14, loss = 0.44696021Iteration 14, loss = 0.40809205\n",
      "Iteration 13, loss = 0.48566207Iteration 7, loss = 0.47935060Iteration 15, loss = 0.49422036Iteration 5, loss = 0.48696146Iteration 12, loss = 0.54312967\n",
      "\n",
      "Iteration 21, loss = 0.46246508\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 15, loss = 0.44624256Iteration 15, loss = 0.40843765\n",
      "Iteration 14, loss = 0.48525829Iteration 8, loss = 0.47914326Iteration 16, loss = 0.49452687Iteration 6, loss = 0.48589984Iteration 13, loss = 0.54254793\n",
      "\n",
      "Iteration 22, loss = 0.46286612\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 16, loss = 0.44610838Iteration 16, loss = 0.40826877\n",
      "Iteration 15, loss = 0.48575728Iteration 9, loss = 0.47898508Iteration 17, loss = 0.49364519Iteration 7, loss = 0.48525905Iteration 14, loss = 0.54191802\n",
      "\n",
      "Iteration 23, loss = 0.46240466\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 17, loss = 0.44582106Iteration 17, loss = 0.40775519\n",
      "Iteration 16, loss = 0.48559184Iteration 10, loss = 0.47797559Iteration 18, loss = 0.49418175Iteration 8, loss = 0.48506214Iteration 15, loss = 0.54165355\n",
      "\n",
      "Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 18, loss = 0.44590416Iteration 18, loss = 0.40861375Iteration 1, loss = 2.02921579Iteration 17, loss = 0.48508390Iteration 11, loss = 0.47838124Iteration 19, loss = 0.49341658Iteration 9, loss = 0.48450008Iteration 16, loss = 0.54183984\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 19, loss = 0.44566678Iteration 19, loss = 0.40831734Iteration 2, loss = 0.46006937Iteration 18, loss = 0.48469588Iteration 12, loss = 0.47770570Iteration 20, loss = 0.49340783Iteration 10, loss = 0.48453329Iteration 17, loss = 0.54148468\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 20, loss = 0.44550810Iteration 20, loss = 0.40777667Iteration 3, loss = 0.44695887Iteration 19, loss = 0.48516690Iteration 13, loss = 0.47813146Iteration 21, loss = 0.49325937Iteration 11, loss = 0.48402299Iteration 18, loss = 0.54217035\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 21, loss = 0.44599993Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "Iteration 4, loss = 0.44407425Iteration 20, loss = 0.48484534Iteration 14, loss = 0.47816600Iteration 22, loss = 0.49369040Iteration 12, loss = 0.48363987Iteration 19, loss = 0.54186653\n",
      "Iteration 1, loss = 2.03941971\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 22, loss = 0.44574104\n",
      "Iteration 5, loss = 0.44264123Iteration 21, loss = 0.48473495Iteration 15, loss = 0.47795652Iteration 23, loss = 0.49387226Iteration 13, loss = 0.48368955Iteration 20, loss = 0.54101198\n",
      "Iteration 2, loss = 0.46968861\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 23, loss = 0.44486114\n",
      "Iteration 6, loss = 0.44318973Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "Iteration 24, loss = 0.49360933Iteration 14, loss = 0.48322249Iteration 21, loss = 0.54130923\n",
      "Iteration 3, loss = 0.45715913\n",
      "Iteration 1, loss = 2.04656034Iteration 1, loss = 2.03581059\n",
      "\n",
      "\n",
      "Iteration 24, loss = 0.44527925\n",
      "Iteration 7, loss = 0.44203234\n",
      "\n",
      "Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "Iteration 15, loss = 0.48340504Iteration 22, loss = 0.54165163\n",
      "Iteration 4, loss = 0.45441207\n",
      "Iteration 2, loss = 0.42221905Iteration 2, loss = 0.47233283Iteration 1, loss = 2.04723488\n",
      "\n",
      "Iteration 25, loss = 0.44530619\n",
      "Iteration 8, loss = 0.44049966\n",
      "\n",
      "\n",
      "Iteration 16, loss = 0.48295853Iteration 23, loss = 0.54096709\n",
      "Iteration 5, loss = 0.45301094\n",
      "Iteration 3, loss = 0.40813432Iteration 3, loss = 0.45932954Iteration 2, loss = 0.48644353\n",
      "\n",
      "Iteration 26, loss = 0.44524243\n",
      "Iteration 9, loss = 0.44041621\n",
      "\n",
      "\n",
      "Iteration 17, loss = 0.48239337Iteration 24, loss = 0.54110530\n",
      "Iteration 6, loss = 0.45221863\n",
      "Iteration 4, loss = 0.40530148Iteration 4, loss = 0.45655061Iteration 3, loss = 0.47375645\n",
      "\n",
      "Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "\n",
      "Iteration 10, loss = 0.44025694\n",
      "\n",
      "\n",
      "Iteration 18, loss = 0.48255147Iteration 25, loss = 0.54106482Iteration 1, loss = 2.09159764Iteration 7, loss = 0.45088501\n",
      "Iteration 5, loss = 0.40192206Iteration 5, loss = 0.45469598Iteration 4, loss = 0.47050485\n",
      "\n",
      "\n",
      "\n",
      "Iteration 11, loss = 0.44075633\n",
      "\n",
      "\n",
      "Iteration 19, loss = 0.48242511Iteration 26, loss = 0.54143641Iteration 2, loss = 0.52345839Iteration 8, loss = 0.45164454\n",
      "Iteration 6, loss = 0.40021284Iteration 6, loss = 0.45407670Iteration 5, loss = 0.46851308\n",
      "\n",
      "\n",
      "\n",
      "Iteration 12, loss = 0.43981269\n",
      "\n",
      "\n",
      "Iteration 20, loss = 0.48318724Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "Iteration 3, loss = 0.51061843Iteration 9, loss = 0.45033960\n",
      "Iteration 7, loss = 0.40004629Iteration 7, loss = 0.45296520Iteration 6, loss = 0.46696902\n",
      "Iteration 1, loss = 2.02801289\n",
      "\n",
      "Iteration 13, loss = 0.43986294\n",
      "\n",
      "\n",
      "Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "\n",
      "Iteration 4, loss = 0.50746036Iteration 10, loss = 0.45047423\n",
      "Iteration 8, loss = 0.39933639Iteration 8, loss = 0.45244461Iteration 7, loss = 0.46669999Iteration 1, loss = 2.06051664Iteration 2, loss = 0.42187210\n",
      "\n",
      "Iteration 14, loss = 0.43941906\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 5, loss = 0.50650929Iteration 11, loss = 0.44981023\n",
      "Iteration 9, loss = 0.39917920Iteration 9, loss = 0.45250074Iteration 8, loss = 0.46606429Iteration 2, loss = 0.46352578Iteration 3, loss = 0.40832283\n",
      "\n",
      "Iteration 15, loss = 0.43937322\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 6, loss = 0.50514843Iteration 12, loss = 0.45003074\n",
      "Iteration 10, loss = 0.39903999Iteration 10, loss = 0.45228578Iteration 9, loss = 0.46583234Iteration 3, loss = 0.44906265Iteration 4, loss = 0.40449737\n",
      "\n",
      "Iteration 16, loss = 0.43953403\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 7, loss = 0.50404026Iteration 13, loss = 0.45002119\n",
      "Iteration 11, loss = 0.39801353Iteration 11, loss = 0.45232997Iteration 10, loss = 0.46574660Iteration 4, loss = 0.44492795Iteration 5, loss = 0.40263594\n",
      "\n",
      "Iteration 17, loss = 0.43874615\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 8, loss = 0.50395862Iteration 14, loss = 0.44982609\n",
      "Iteration 12, loss = 0.39814745Iteration 12, loss = 0.45179155Iteration 11, loss = 0.46498855Iteration 5, loss = 0.44339428Iteration 6, loss = 0.40182709\n",
      "\n",
      "Iteration 18, loss = 0.43920283\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 9, loss = 0.50314073Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "\n",
      "Iteration 13, loss = 0.39778594Iteration 13, loss = 0.45163296Iteration 12, loss = 0.46475987Iteration 6, loss = 0.44214190Iteration 7, loss = 0.40045756\n",
      "Iteration 1, loss = 2.06920783Iteration 19, loss = 0.43900471\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 10, loss = 0.50334102\n",
      "\n",
      "Iteration 14, loss = 0.39829881Iteration 14, loss = 0.45171314Iteration 13, loss = 0.46511795Iteration 7, loss = 0.44137195Iteration 8, loss = 0.39951623\n",
      "Iteration 2, loss = 0.51902689Iteration 20, loss = 0.43875709\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 11, loss = 0.50294520\n",
      "\n",
      "Iteration 15, loss = 0.39794594Iteration 15, loss = 0.45157182Iteration 14, loss = 0.46478392Iteration 8, loss = 0.44108545Iteration 9, loss = 0.39891214\n",
      "Iteration 3, loss = 0.50761412Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 12, loss = 0.50273275\n",
      "Iteration 1, loss = 2.10844026Iteration 16, loss = 0.39750219Iteration 16, loss = 0.45111849Iteration 15, loss = 0.46473315Iteration 9, loss = 0.44067498Iteration 10, loss = 0.39876890\n",
      "Iteration 4, loss = 0.50412351\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 13, loss = 0.50242577\n",
      "Iteration 2, loss = 0.54336765Iteration 17, loss = 0.39735000Iteration 17, loss = 0.45149603Iteration 16, loss = 0.46420700Iteration 10, loss = 0.44056581Iteration 11, loss = 0.39888284\n",
      "Iteration 5, loss = 0.50255377\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 14, loss = 0.50242828\n",
      "Iteration 3, loss = 0.53022117Iteration 18, loss = 0.39691830Iteration 18, loss = 0.45129183Iteration 17, loss = 0.46431783Iteration 11, loss = 0.43968989Iteration 12, loss = 0.39945916\n",
      "Iteration 6, loss = 0.50143856\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 15, loss = 0.50277441\n",
      "Iteration 4, loss = 0.52773231Iteration 19, loss = 0.39707767Iteration 19, loss = 0.45147539Iteration 18, loss = 0.46403918Iteration 12, loss = 0.44012553Iteration 13, loss = 0.39818673\n",
      "Iteration 7, loss = 0.50116495\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 16, loss = 0.50183412\n",
      "Iteration 5, loss = 0.52571352Iteration 20, loss = 0.39682935Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "Iteration 19, loss = 0.46419855Iteration 13, loss = 0.43966896Iteration 14, loss = 0.39819578\n",
      "Iteration 8, loss = 0.49957715\n",
      "\n",
      "Iteration 1, loss = 2.01225358\n",
      "\n",
      "\n",
      "Iteration 17, loss = 0.50181797\n",
      "Iteration 6, loss = 0.52458126Iteration 21, loss = 0.39760241\n",
      "Iteration 20, loss = 0.46383423Iteration 14, loss = 0.43924620Iteration 15, loss = 0.39829682\n",
      "Iteration 9, loss = 0.49931331\n",
      "\n",
      "Iteration 2, loss = 0.43830127\n",
      "\n",
      "\n",
      "Iteration 18, loss = 0.50183224\n",
      "Iteration 7, loss = 0.52420137Iteration 22, loss = 0.39673754\n",
      "Iteration 21, loss = 0.46416984Iteration 15, loss = 0.43906671Iteration 16, loss = 0.39780267\n",
      "Iteration 10, loss = 0.49862173\n",
      "\n",
      "Iteration 3, loss = 0.42475776\n",
      "\n",
      "\n",
      "Iteration 19, loss = 0.50241287\n",
      "Iteration 8, loss = 0.52369224Iteration 23, loss = 0.39650117\n",
      "Iteration 22, loss = 0.46387639Iteration 16, loss = 0.43925996Iteration 17, loss = 0.39780163\n",
      "Iteration 11, loss = 0.49860650\n",
      "\n",
      "Iteration 4, loss = 0.42103195\n",
      "\n",
      "\n",
      "Iteration 20, loss = 0.50115679\n",
      "Iteration 9, loss = 0.52262076Iteration 24, loss = 0.39715540\n",
      "Iteration 23, loss = 0.46371024Iteration 17, loss = 0.43970929Iteration 18, loss = 0.39804713\n",
      "Iteration 12, loss = 0.49859331\n",
      "\n",
      "Iteration 5, loss = 0.41929322\n",
      "\n",
      "\n",
      "Iteration 21, loss = 0.50110092\n",
      "Iteration 10, loss = 0.52297589Iteration 25, loss = 0.39715924\n",
      "Iteration 24, loss = 0.46379096Iteration 18, loss = 0.43853279Iteration 19, loss = 0.39787345\n",
      "Iteration 13, loss = 0.49796112\n",
      "\n",
      "Iteration 6, loss = 0.41839788\n",
      "\n",
      "\n",
      "Iteration 22, loss = 0.50104008\n",
      "Iteration 11, loss = 0.52268911Iteration 26, loss = 0.39695520\n",
      "Iteration 25, loss = 0.46399487Iteration 19, loss = 0.43962942Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "\n",
      "Iteration 14, loss = 0.49769514\n",
      "\n",
      "Iteration 7, loss = 0.41804567\n",
      "\n",
      "Iteration 1, loss = 2.08959001Iteration 23, loss = 0.50147187\n",
      "Iteration 12, loss = 0.52218104Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "\n",
      "Iteration 26, loss = 0.46356375Iteration 20, loss = 0.43878865\n",
      "\n",
      "Iteration 15, loss = 0.49848709\n",
      "Iteration 1, loss = 1.98280643Iteration 8, loss = 0.41694277\n",
      "\n",
      "Iteration 2, loss = 0.49820488Iteration 24, loss = 0.50162765\n",
      "Iteration 13, loss = 0.52151754\n",
      "\n",
      "Iteration 27, loss = 0.46309221Iteration 21, loss = 0.43807026\n",
      "\n",
      "Iteration 16, loss = 0.49731646\n",
      "Iteration 2, loss = 0.43818182Iteration 9, loss = 0.41692972\n",
      "\n",
      "Iteration 3, loss = 0.48351284Iteration 25, loss = 0.50083151\n",
      "Iteration 14, loss = 0.52170614\n",
      "\n",
      "Iteration 28, loss = 0.46343495Iteration 22, loss = 0.43845362\n",
      "\n",
      "Iteration 17, loss = 0.49762796\n",
      "Iteration 3, loss = 0.42606301Iteration 10, loss = 0.41669358\n",
      "\n",
      "Iteration 4, loss = 0.48025021Iteration 26, loss = 0.50124286\n",
      "Iteration 15, loss = 0.52105616\n",
      "\n",
      "Iteration 29, loss = 0.46371143Iteration 23, loss = 0.43845693\n",
      "\n",
      "Iteration 18, loss = 0.49749268\n",
      "Iteration 4, loss = 0.42356406Iteration 11, loss = 0.41617240\n",
      "\n",
      "Iteration 5, loss = 0.47870207Iteration 27, loss = 0.50083700\n",
      "Iteration 16, loss = 0.52141062\n",
      "\n",
      "Iteration 30, loss = 0.46395544Iteration 24, loss = 0.43856653\n",
      "\n",
      "Iteration 19, loss = 0.49673645\n",
      "Iteration 5, loss = 0.42128043Iteration 12, loss = 0.41665089\n",
      "\n",
      "Iteration 6, loss = 0.47685546Iteration 28, loss = 0.50105405\n",
      "Iteration 17, loss = 0.52120089\n",
      "\n",
      "Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "\n",
      "\n",
      "Iteration 20, loss = 0.49737769\n",
      "Iteration 6, loss = 0.42123136Iteration 13, loss = 0.41627641Iteration 1, loss = 2.02842081Iteration 1, loss = 2.05293068Iteration 7, loss = 0.47560528Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "\n",
      "Iteration 18, loss = 0.52171898\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 1, loss = 2.05637625Iteration 21, loss = 0.49664724\n",
      "Iteration 7, loss = 0.42065872Iteration 14, loss = 0.41571502Iteration 2, loss = 0.46905667Iteration 2, loss = 0.50226883Iteration 8, loss = 0.47521419\n",
      "\n",
      "Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 2, loss = 0.49283243Iteration 22, loss = 0.49640744Iteration 1, loss = 2.04612100Iteration 8, loss = 0.42020919Iteration 15, loss = 0.41578476Iteration 3, loss = 0.45554089Iteration 3, loss = 0.49093265Iteration 9, loss = 0.47467046\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 3, loss = 0.47972492Iteration 23, loss = 0.49693271Iteration 2, loss = 0.50046010Iteration 9, loss = 0.41911899Iteration 16, loss = 0.41667953Iteration 4, loss = 0.45211999Iteration 4, loss = 0.48790299Iteration 10, loss = 0.47400694\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 4, loss = 0.47682966Iteration 24, loss = 0.49649716Iteration 3, loss = 0.48767011Iteration 10, loss = 0.41897117Iteration 17, loss = 0.41622166Iteration 5, loss = 0.45078564Iteration 5, loss = 0.48708917Iteration 11, loss = 0.47464379\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 5, loss = 0.47550996Iteration 25, loss = 0.49715475Iteration 4, loss = 0.48555680Iteration 11, loss = 0.41862617Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "Iteration 6, loss = 0.45016785Iteration 6, loss = 0.48630271Iteration 12, loss = 0.47421327\n",
      "\n",
      "\n",
      "\n",
      "Iteration 1, loss = 2.01142331\n",
      "\n",
      "\n",
      "Iteration 6, loss = 0.47411883Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "Iteration 5, loss = 0.48400814Iteration 12, loss = 0.41892080\n",
      "Iteration 7, loss = 0.44898479Iteration 7, loss = 0.48614210Iteration 13, loss = 0.47385450\n",
      "Iteration 1, loss = 2.02250488\n",
      "\n",
      "Iteration 2, loss = 0.44365335\n",
      "\n",
      "\n",
      "Iteration 7, loss = 0.47278091\n",
      "Iteration 6, loss = 0.48228300Iteration 13, loss = 0.41887721\n",
      "Iteration 8, loss = 0.44919372Iteration 8, loss = 0.48447612Iteration 14, loss = 0.47383015\n",
      "Iteration 2, loss = 0.45643635\n",
      "\n",
      "Iteration 3, loss = 0.43173365\n",
      "\n",
      "\n",
      "Iteration 8, loss = 0.47417168\n",
      "Iteration 7, loss = 0.48207470Iteration 14, loss = 0.41838614\n",
      "Iteration 9, loss = 0.44864357Iteration 9, loss = 0.48540268Iteration 15, loss = 0.47320816\n",
      "Iteration 3, loss = 0.44127737\n",
      "\n",
      "Iteration 4, loss = 0.42876830\n",
      "\n",
      "\n",
      "Iteration 9, loss = 0.47245215\n",
      "Iteration 8, loss = 0.48154928Iteration 15, loss = 0.41822004\n",
      "Iteration 10, loss = 0.44849695Iteration 10, loss = 0.48438597Iteration 16, loss = 0.47310560\n",
      "Iteration 4, loss = 0.43642316\n",
      "\n",
      "Iteration 5, loss = 0.42699199\n",
      "\n",
      "\n",
      "Iteration 10, loss = 0.47289266\n",
      "Iteration 9, loss = 0.48141092Iteration 16, loss = 0.41852974\n",
      "Iteration 11, loss = 0.44752260Iteration 11, loss = 0.48390155Iteration 17, loss = 0.47319329\n",
      "Iteration 5, loss = 0.43485369\n",
      "\n",
      "Iteration 6, loss = 0.42704502\n",
      "\n",
      "\n",
      "Iteration 11, loss = 0.47261408\n",
      "Iteration 10, loss = 0.48083701Iteration 17, loss = 0.41843993\n",
      "Iteration 12, loss = 0.44784978Iteration 12, loss = 0.48371739Iteration 18, loss = 0.47339760\n",
      "Iteration 6, loss = 0.43385668\n",
      "\n",
      "Iteration 7, loss = 0.42540645\n",
      "\n",
      "\n",
      "Iteration 12, loss = 0.47236717\n",
      "Iteration 11, loss = 0.48117674Iteration 18, loss = 0.41805881\n",
      "Iteration 13, loss = 0.44756589Iteration 13, loss = 0.48383870Iteration 19, loss = 0.47327667\n",
      "Iteration 7, loss = 0.43284909\n",
      "\n",
      "Iteration 8, loss = 0.42533690\n",
      "\n",
      "\n",
      "Iteration 13, loss = 0.47214650\n",
      "Iteration 12, loss = 0.48028211Iteration 19, loss = 0.41817568\n",
      "Iteration 14, loss = 0.44784483Iteration 14, loss = 0.48317868Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "\n",
      "Iteration 8, loss = 0.43209613\n",
      "\n",
      "Iteration 9, loss = 0.42466033\n",
      "\n",
      "Iteration 1, loss = 2.04849715Iteration 14, loss = 0.47187124\n",
      "Iteration 13, loss = 0.48046409Iteration 20, loss = 0.41833282\n",
      "Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "Iteration 15, loss = 0.48410287\n",
      "\n",
      "Iteration 9, loss = 0.43153255\n",
      "\n",
      "Iteration 10, loss = 0.42484385Iteration 1, loss = 2.05741914\n",
      "Iteration 2, loss = 0.47493337Iteration 15, loss = 0.47154544\n",
      "Iteration 14, loss = 0.48112829Iteration 21, loss = 0.41775009\n",
      "\n",
      "Iteration 16, loss = 0.48349883\n",
      "\n",
      "Iteration 10, loss = 0.43174890\n",
      "\n",
      "Iteration 11, loss = 0.42418854Iteration 2, loss = 0.50541790\n",
      "Iteration 3, loss = 0.46219647Iteration 16, loss = 0.47146060\n",
      "Iteration 15, loss = 0.48014655Iteration 22, loss = 0.41733560\n",
      "\n",
      "Iteration 17, loss = 0.48339240\n",
      "\n",
      "Iteration 11, loss = 0.43115697\n",
      "\n",
      "Iteration 12, loss = 0.42457567Iteration 3, loss = 0.49101890\n",
      "Iteration 4, loss = 0.45822594Iteration 17, loss = 0.47129088\n",
      "Iteration 16, loss = 0.48017935Iteration 23, loss = 0.41768898\n",
      "\n",
      "Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "\n",
      "\n",
      "Iteration 12, loss = 0.43092592\n",
      "\n",
      "Iteration 13, loss = 0.42412694Iteration 4, loss = 0.48765414Iteration 1, loss = 2.07401472Iteration 5, loss = 0.45672124Iteration 18, loss = 0.47154102\n",
      "Iteration 17, loss = 0.47964181Iteration 24, loss = 0.41764201\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 13, loss = 0.43093947\n",
      "\n",
      "Iteration 14, loss = 0.42384592Iteration 5, loss = 0.48628490Iteration 2, loss = 0.50630897Iteration 6, loss = 0.45570695Iteration 19, loss = 0.47111161\n",
      "Iteration 18, loss = 0.47925060Iteration 25, loss = 0.41845171\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 14, loss = 0.43088944\n",
      "\n",
      "Iteration 15, loss = 0.42376705Iteration 6, loss = 0.48485321Iteration 3, loss = 0.49258758Iteration 7, loss = 0.45462876Iteration 20, loss = 0.47143843\n",
      "Iteration 19, loss = 0.47948189Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 15, loss = 0.43064632\n",
      "Iteration 1, loss = 2.06730920Iteration 16, loss = 0.42327608Iteration 7, loss = 0.48352200Iteration 4, loss = 0.48934791Iteration 8, loss = 0.45467568Iteration 21, loss = 0.47150474\n",
      "Iteration 20, loss = 0.47974901\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 16, loss = 0.43104653\n",
      "Iteration 2, loss = 0.50035913Iteration 17, loss = 0.42407646Iteration 8, loss = 0.48364109Iteration 5, loss = 0.48851142Iteration 9, loss = 0.45445119Iteration 22, loss = 0.47072428\n",
      "Iteration 21, loss = 0.47953243\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 17, loss = 0.43040422\n",
      "Iteration 3, loss = 0.48479046Iteration 18, loss = 0.42364931Iteration 9, loss = 0.48306439Iteration 6, loss = 0.48746345Iteration 10, loss = 0.45432507Iteration 23, loss = 0.47112743\n",
      "Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 18, loss = 0.43026681Iteration 1, loss = 2.00676082Iteration 4, loss = 0.48037812Iteration 19, loss = 0.42337522Iteration 10, loss = 0.48215315Iteration 7, loss = 0.48685738Iteration 11, loss = 0.45362162Iteration 24, loss = 0.47065794\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 19, loss = 0.43152807Iteration 2, loss = 0.46549576Iteration 5, loss = 0.47948780Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "Iteration 11, loss = 0.48145163Iteration 8, loss = 0.48618799Iteration 12, loss = 0.45342878Iteration 25, loss = 0.47065793\n",
      "\n",
      "\n",
      "Iteration 1, loss = 2.02151027\n",
      "\n",
      "\n",
      "\n",
      "Iteration 20, loss = 0.43041446Iteration 3, loss = 0.45227032Iteration 6, loss = 0.47807482\n",
      "Iteration 12, loss = 0.48187873Iteration 9, loss = 0.48586350Iteration 13, loss = 0.45274353Iteration 26, loss = 0.47056325\n",
      "\n",
      "\n",
      "Iteration 2, loss = 0.48821410\n",
      "\n",
      "\n",
      "\n",
      "Iteration 21, loss = 0.42974346Iteration 4, loss = 0.44978720Iteration 7, loss = 0.47730900\n",
      "Iteration 13, loss = 0.48128580Iteration 10, loss = 0.48554820Iteration 14, loss = 0.45385842Iteration 27, loss = 0.47054909\n",
      "\n",
      "\n",
      "Iteration 3, loss = 0.47517444\n",
      "\n",
      "\n",
      "\n",
      "Iteration 22, loss = 0.43029932Iteration 5, loss = 0.44788733Iteration 8, loss = 0.47627911\n",
      "Iteration 14, loss = 0.48208554Iteration 11, loss = 0.48571912Iteration 15, loss = 0.45317712Iteration 28, loss = 0.47055751\n",
      "\n",
      "\n",
      "Iteration 4, loss = 0.47267677\n",
      "\n",
      "\n",
      "\n",
      "Iteration 23, loss = 0.43019786Iteration 6, loss = 0.44756124Iteration 9, loss = 0.47621155\n",
      "Iteration 15, loss = 0.48080456Iteration 12, loss = 0.48556357Iteration 16, loss = 0.45247902Iteration 29, loss = 0.47085283\n",
      "\n",
      "\n",
      "Iteration 5, loss = 0.47170982\n",
      "\n",
      "\n",
      "\n",
      "Iteration 24, loss = 0.43000091Iteration 7, loss = 0.44598914Iteration 10, loss = 0.47608703\n",
      "Iteration 16, loss = 0.48131704Iteration 13, loss = 0.48540945Iteration 17, loss = 0.45293317Iteration 30, loss = 0.47018110\n",
      "\n",
      "\n",
      "Iteration 6, loss = 0.47007628\n",
      "\n",
      "\n",
      "\n",
      "Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "Iteration 8, loss = 0.44521262Iteration 11, loss = 0.47515226\n",
      "Iteration 17, loss = 0.48037839Iteration 14, loss = 0.48538634Iteration 18, loss = 0.45335340Iteration 31, loss = 0.47039535Iteration 1, loss = 2.05963419\n",
      "\n",
      "Iteration 7, loss = 0.46991509\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 9, loss = 0.44526095Iteration 12, loss = 0.47516168\n",
      "Iteration 18, loss = 0.48109478Iteration 15, loss = 0.48502270Iteration 19, loss = 0.45284914Iteration 32, loss = 0.47070177Iteration 2, loss = 0.52025920\n",
      "\n",
      "Iteration 8, loss = 0.46882515\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 10, loss = 0.44411358Iteration 13, loss = 0.47493332\n",
      "Iteration 19, loss = 0.48026247Iteration 16, loss = 0.48462219Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "Iteration 33, loss = 0.47021924Iteration 3, loss = 0.50822879\n",
      "\n",
      "Iteration 9, loss = 0.46849406\n",
      "\n",
      "Iteration 1, loss = 2.04272633\n",
      "\n",
      "Iteration 11, loss = 0.44394253Iteration 14, loss = 0.47465431\n",
      "Iteration 20, loss = 0.48129638Iteration 17, loss = 0.48462848\n",
      "Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "Iteration 4, loss = 0.50534402\n",
      "\n",
      "Iteration 10, loss = 0.46835198\n",
      "\n",
      "Iteration 2, loss = 0.46673001Iteration 1, loss = 2.06706901\n",
      "Iteration 12, loss = 0.44382261Iteration 15, loss = 0.47498841\n",
      "Iteration 21, loss = 0.48022128Iteration 18, loss = 0.48495314\n",
      "\n",
      "Iteration 5, loss = 0.50383606\n",
      "\n",
      "Iteration 11, loss = 0.46826964\n",
      "\n",
      "Iteration 3, loss = 0.45284713Iteration 2, loss = 0.50891912\n",
      "Iteration 13, loss = 0.44380891Iteration 16, loss = 0.47452900\n",
      "Iteration 22, loss = 0.48042904Iteration 19, loss = 0.48491828\n",
      "\n",
      "Iteration 6, loss = 0.50210143\n",
      "\n",
      "Iteration 12, loss = 0.46780180\n",
      "\n",
      "Iteration 4, loss = 0.44987732Iteration 3, loss = 0.49569681\n",
      "Iteration 14, loss = 0.44415512Iteration 17, loss = 0.47420229\n",
      "Iteration 23, loss = 0.48012424Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "\n",
      "\n",
      "Iteration 7, loss = 0.50156967\n",
      "\n",
      "Iteration 13, loss = 0.46749990\n",
      "Iteration 1, loss = 2.05143490Iteration 5, loss = 0.44755633Iteration 4, loss = 0.49216128\n",
      "Iteration 15, loss = 0.44317293Iteration 18, loss = 0.47458357\n",
      "Iteration 24, loss = 0.48064184\n",
      "\n",
      "\n",
      "Iteration 8, loss = 0.50121570\n",
      "\n",
      "Iteration 14, loss = 0.46773293\n",
      "Iteration 2, loss = 0.47708421Iteration 6, loss = 0.44703862Iteration 5, loss = 0.49082306\n",
      "Iteration 16, loss = 0.44310464Iteration 19, loss = 0.47423042\n",
      "Iteration 25, loss = 0.48018885\n",
      "\n",
      "\n",
      "Iteration 9, loss = 0.50105192\n",
      "\n",
      "Iteration 15, loss = 0.46710644\n",
      "Iteration 3, loss = 0.46204284Iteration 7, loss = 0.44613183Iteration 6, loss = 0.49008989\n",
      "Iteration 17, loss = 0.44276989Iteration 20, loss = 0.47377039\n",
      "Iteration 26, loss = 0.47996080\n",
      "\n",
      "\n",
      "Iteration 10, loss = 0.50125140\n",
      "\n",
      "Iteration 16, loss = 0.46736578\n",
      "Iteration 4, loss = 0.45822353Iteration 8, loss = 0.44557039Iteration 7, loss = 0.48949343\n",
      "Iteration 18, loss = 0.44312964Iteration 21, loss = 0.47392529\n",
      "Iteration 27, loss = 0.48036634\n",
      "\n",
      "\n",
      "Iteration 11, loss = 0.50077176\n",
      "\n",
      "Iteration 17, loss = 0.46770048\n",
      "Iteration 5, loss = 0.45629900Iteration 9, loss = 0.44520701Iteration 8, loss = 0.48870301\n",
      "Iteration 19, loss = 0.44316698Iteration 22, loss = 0.47370460\n",
      "Iteration 28, loss = 0.48031974\n",
      "\n",
      "\n",
      "Iteration 12, loss = 0.49980987\n",
      "\n",
      "Iteration 18, loss = 0.46706196\n",
      "Iteration 6, loss = 0.45513548Iteration 10, loss = 0.44505320Iteration 9, loss = 0.48901925\n",
      "Iteration 20, loss = 0.44311728Iteration 23, loss = 0.47401050\n",
      "Iteration 29, loss = 0.48031199\n",
      "\n",
      "\n",
      "Iteration 13, loss = 0.50060754\n",
      "\n",
      "Iteration 19, loss = 0.46712821\n",
      "Iteration 7, loss = 0.45510275Iteration 11, loss = 0.44444872Iteration 10, loss = 0.48827506\n",
      "Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "Iteration 24, loss = 0.47419180\n",
      "Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "\n",
      "\n",
      "\n",
      "Iteration 14, loss = 0.50003049Iteration 1, loss = 2.00489289\n",
      "Iteration 20, loss = 0.46676819Iteration 1, loss = 2.02695717Iteration 8, loss = 0.45449581Iteration 12, loss = 0.44525141Iteration 11, loss = 0.48799356\n",
      "\n",
      "Iteration 25, loss = 0.47341191\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 15, loss = 0.50022565Iteration 2, loss = 0.45945119\n",
      "Iteration 21, loss = 0.46690303Iteration 2, loss = 0.44189580Iteration 9, loss = 0.45366446Iteration 13, loss = 0.44377280Iteration 12, loss = 0.48760048\n",
      "\n",
      "Iteration 26, loss = 0.47372860\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "Iteration 3, loss = 0.44767167\n",
      "Iteration 22, loss = 0.46678257Iteration 3, loss = 0.42877205Iteration 10, loss = 0.45350335Iteration 14, loss = 0.44360275Iteration 13, loss = 0.48746871Iteration 1, loss = 2.04898995\n",
      "Iteration 27, loss = 0.47361879\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 4, loss = 0.44401936\n",
      "Iteration 23, loss = 0.46702490Iteration 4, loss = 0.42468874Iteration 11, loss = 0.45319711Iteration 15, loss = 0.44405740Iteration 14, loss = 0.48828831Iteration 2, loss = 0.49636826\n",
      "Iteration 28, loss = 0.47365355\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 5, loss = 0.44183432\n",
      "Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "Iteration 5, loss = 0.42293895Iteration 12, loss = 0.45357320Iteration 16, loss = 0.44361378Iteration 15, loss = 0.48726362Iteration 3, loss = 0.48391752\n",
      "Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 2.05306500\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 6, loss = 0.44113926Iteration 1, loss = 2.04535658\n",
      "Iteration 6, loss = 0.42162004Iteration 13, loss = 0.45301410Iteration 17, loss = 0.44325645Iteration 16, loss = 0.48750797Iteration 4, loss = 0.48058685\n",
      "\n",
      "Iteration 2, loss = 0.48001304\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 7, loss = 0.44043685Iteration 2, loss = 0.47993128\n",
      "Iteration 7, loss = 0.42064797Iteration 14, loss = 0.45306552Iteration 18, loss = 0.44329786Iteration 17, loss = 0.48745619Iteration 5, loss = 0.47918253\n",
      "\n",
      "Iteration 3, loss = 0.46737073\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 8, loss = 0.43956031Iteration 3, loss = 0.46559516\n",
      "Iteration 8, loss = 0.42028436Iteration 15, loss = 0.45285840Iteration 19, loss = 0.44342573Iteration 18, loss = 0.48696793Iteration 6, loss = 0.47817111\n",
      "\n",
      "Iteration 4, loss = 0.46319710\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 9, loss = 0.43932307Iteration 4, loss = 0.46126379\n",
      "Iteration 9, loss = 0.42047014Iteration 16, loss = 0.45285367Iteration 20, loss = 0.44358511Iteration 19, loss = 0.48737675Iteration 7, loss = 0.47820165\n",
      "\n",
      "Iteration 5, loss = 0.46164215\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 10, loss = 0.43921697Iteration 5, loss = 0.45951694\n",
      "Iteration 10, loss = 0.41938074Iteration 17, loss = 0.45267168Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "Iteration 20, loss = 0.48682981Iteration 8, loss = 0.47688516\n",
      "\n",
      "Iteration 6, loss = 0.46109391\n",
      "\n",
      "Iteration 1, loss = 2.02253769\n",
      "\n",
      "Iteration 11, loss = 0.43888006Iteration 6, loss = 0.45822783\n",
      "Iteration 11, loss = 0.41936585Iteration 18, loss = 0.45245396\n",
      "Iteration 21, loss = 0.48707828Iteration 9, loss = 0.47609391\n",
      "\n",
      "Iteration 7, loss = 0.45951895\n",
      "\n",
      "Iteration 2, loss = 0.46855395\n",
      "\n",
      "Iteration 12, loss = 0.43872624Iteration 7, loss = 0.45763948\n",
      "Iteration 12, loss = 0.41933423Iteration 19, loss = 0.45236929\n",
      "Iteration 22, loss = 0.48850940Iteration 10, loss = 0.47662674\n",
      "\n",
      "Iteration 8, loss = 0.45935047\n",
      "\n",
      "Iteration 3, loss = 0.45594030\n",
      "\n",
      "Iteration 13, loss = 0.43863447Iteration 8, loss = 0.45676844\n",
      "Iteration 13, loss = 0.41898489Iteration 20, loss = 0.45240287\n",
      "Iteration 23, loss = 0.48669436Iteration 11, loss = 0.47608227\n",
      "\n",
      "Iteration 9, loss = 0.45950454\n",
      "\n",
      "Iteration 4, loss = 0.45300859\n",
      "\n",
      "Iteration 14, loss = 0.43825791Iteration 9, loss = 0.45591692\n",
      "Iteration 14, loss = 0.41874720Iteration 21, loss = 0.45196783\n",
      "Iteration 24, loss = 0.48697193Iteration 12, loss = 0.47548525\n",
      "\n",
      "Iteration 10, loss = 0.45874197\n",
      "\n",
      "Iteration 5, loss = 0.45116460\n",
      "\n",
      "Iteration 15, loss = 0.43811292Iteration 10, loss = 0.45585013\n",
      "Iteration 15, loss = 0.41849818Iteration 22, loss = 0.45215853\n",
      "Iteration 25, loss = 0.48676223Iteration 13, loss = 0.47530201\n",
      "\n",
      "Iteration 11, loss = 0.45846659\n",
      "\n",
      "Iteration 6, loss = 0.45013452\n",
      "\n",
      "Iteration 16, loss = 0.43826712Iteration 11, loss = 0.45607345\n",
      "Iteration 16, loss = 0.41797492Iteration 23, loss = 0.45197283\n",
      "Iteration 26, loss = 0.48670354Iteration 14, loss = 0.47505064\n",
      "\n",
      "Iteration 12, loss = 0.45812639\n",
      "\n",
      "Iteration 7, loss = 0.44964533\n",
      "\n",
      "Iteration 17, loss = 0.43790252Iteration 12, loss = 0.45589099\n",
      "Iteration 17, loss = 0.41851580Iteration 24, loss = 0.45206971\n",
      "Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "Iteration 15, loss = 0.47487950\n",
      "\n",
      "Iteration 13, loss = 0.45855572\n",
      "\n",
      "Iteration 8, loss = 0.44865063Iteration 1, loss = 2.09247692\n",
      "Iteration 18, loss = 0.43834703Iteration 13, loss = 0.45552770\n",
      "Iteration 18, loss = 0.41802556Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "\n",
      "\n",
      "Iteration 16, loss = 0.47515349\n",
      "\n",
      "Iteration 14, loss = 0.45935775\n",
      "Iteration 1, loss = 2.02660930Iteration 9, loss = 0.44829900Iteration 2, loss = 0.53268900\n",
      "Iteration 19, loss = 0.43776056Iteration 14, loss = 0.45527694\n",
      "Iteration 19, loss = 0.41817566\n",
      "\n",
      "\n",
      "Iteration 17, loss = 0.47501763\n",
      "\n",
      "Iteration 15, loss = 0.45832503\n",
      "Iteration 2, loss = 0.49022135Iteration 10, loss = 0.44868663Iteration 3, loss = 0.51790608\n",
      "Iteration 20, loss = 0.43774318Iteration 15, loss = 0.45538980\n",
      "Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "\n",
      "\n",
      "\n",
      "Iteration 18, loss = 0.47458994\n",
      "\n",
      "Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 2.03991275Iteration 3, loss = 0.47724718Iteration 11, loss = 0.44793423Iteration 4, loss = 0.51455154\n",
      "Iteration 21, loss = 0.43782611Iteration 16, loss = 0.45521369Iteration 1, loss = 2.05459343\n",
      "\n",
      "\n",
      "\n",
      "Iteration 19, loss = 0.47579958\n",
      "\n",
      "\n",
      "Iteration 2, loss = 0.49492284Iteration 4, loss = 0.47378933Iteration 12, loss = 0.44811785Iteration 5, loss = 0.51190627\n",
      "Iteration 22, loss = 0.43796806Iteration 17, loss = 0.45539674Iteration 2, loss = 0.51495380\n",
      "\n",
      "\n",
      "\n",
      "Iteration 20, loss = 0.47453752\n",
      "\n",
      "\n",
      "Iteration 3, loss = 0.48352832Iteration 5, loss = 0.47285450Iteration 13, loss = 0.44756997Iteration 6, loss = 0.51138017\n",
      "Iteration 23, loss = 0.43770798Iteration 18, loss = 0.45495214Iteration 3, loss = 0.50307922\n",
      "\n",
      "\n",
      "\n",
      "Iteration 21, loss = 0.47437532\n",
      "\n",
      "\n",
      "Iteration 4, loss = 0.47897387Iteration 6, loss = 0.47086254Iteration 14, loss = 0.44711033Iteration 7, loss = 0.51038887\n",
      "Iteration 24, loss = 0.43755044Iteration 19, loss = 0.45488112Iteration 4, loss = 0.50013304\n",
      "\n",
      "\n",
      "\n",
      "Iteration 22, loss = 0.47406076\n",
      "\n",
      "\n",
      "Iteration 5, loss = 0.47692253Iteration 7, loss = 0.47011916Iteration 15, loss = 0.44719884Iteration 8, loss = 0.50975375\n",
      "Iteration 25, loss = 0.43767198Iteration 20, loss = 0.45541673Iteration 5, loss = 0.49817013\n",
      "\n",
      "\n",
      "\n",
      "Iteration 23, loss = 0.47404330\n",
      "\n",
      "\n",
      "Iteration 6, loss = 0.47652860Iteration 8, loss = 0.46985987Iteration 16, loss = 0.44700884Iteration 9, loss = 0.50945555\n",
      "Iteration 26, loss = 0.43790137Iteration 21, loss = 0.45484570Iteration 6, loss = 0.49724183\n",
      "\n",
      "\n",
      "\n",
      "Iteration 24, loss = 0.47399793\n",
      "\n",
      "\n",
      "Iteration 7, loss = 0.47614149Iteration 9, loss = 0.46960250Iteration 17, loss = 0.44681334Iteration 10, loss = 0.51003866\n",
      "Iteration 27, loss = 0.43789009Iteration 22, loss = 0.45460452Iteration 7, loss = 0.49644977\n",
      "\n",
      "\n",
      "\n",
      "Iteration 25, loss = 0.47443364\n",
      "\n",
      "\n",
      "Iteration 8, loss = 0.47515354Iteration 10, loss = 0.46965271Iteration 18, loss = 0.44719276Iteration 11, loss = 0.50863162\n",
      "Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "Iteration 23, loss = 0.45457850Iteration 8, loss = 0.49563481\n",
      "\n",
      "\n",
      "\n",
      "Iteration 26, loss = 0.47407105Iteration 1, loss = 2.07577330\n",
      "\n",
      "Iteration 9, loss = 0.47476858Iteration 11, loss = 0.46887346Iteration 19, loss = 0.44661194Iteration 12, loss = 0.50871202\n",
      "\n",
      "Iteration 24, loss = 0.45472319Iteration 9, loss = 0.49541114\n",
      "\n",
      "\n",
      "\n",
      "Iteration 27, loss = 0.47372060Iteration 2, loss = 0.51761331\n",
      "\n",
      "Iteration 10, loss = 0.47355191Iteration 12, loss = 0.46907528Iteration 20, loss = 0.44717390Iteration 13, loss = 0.50893303\n",
      "\n",
      "Iteration 25, loss = 0.45436838Iteration 10, loss = 0.49513971\n",
      "\n",
      "\n",
      "\n",
      "Iteration 28, loss = 0.47405199Iteration 3, loss = 0.50411471\n",
      "\n",
      "Iteration 11, loss = 0.47392153Iteration 13, loss = 0.46883313Iteration 21, loss = 0.44671827Iteration 14, loss = 0.50862143\n",
      "\n",
      "Iteration 26, loss = 0.45429210Iteration 11, loss = 0.49480233\n",
      "\n",
      "\n",
      "\n",
      "Iteration 29, loss = 0.47370271Iteration 4, loss = 0.50164131\n",
      "\n",
      "Iteration 12, loss = 0.47384732Iteration 14, loss = 0.46855204Iteration 22, loss = 0.44611959Iteration 15, loss = 0.50852348\n",
      "\n",
      "Iteration 27, loss = 0.45427034Iteration 12, loss = 0.49479112\n",
      "\n",
      "\n",
      "\n",
      "Iteration 30, loss = 0.47338646Iteration 5, loss = 0.49947729\n",
      "\n",
      "Iteration 13, loss = 0.47366324Iteration 15, loss = 0.46854065Iteration 23, loss = 0.44640561Iteration 16, loss = 0.50811325\n",
      "\n",
      "Iteration 28, loss = 0.45482439Iteration 13, loss = 0.49464009\n",
      "\n",
      "\n",
      "\n",
      "Iteration 31, loss = 0.47438875Iteration 6, loss = 0.49793727\n",
      "\n",
      "Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "Iteration 16, loss = 0.46771203Iteration 24, loss = 0.44631521Iteration 17, loss = 0.50820399\n",
      "\n",
      "Iteration 29, loss = 0.45431130Iteration 14, loss = 0.49432409Iteration 1, loss = 2.09112655\n",
      "\n",
      "\n",
      "Iteration 32, loss = 0.47389227Iteration 7, loss = 0.49750317\n",
      "\n",
      "\n",
      "Iteration 17, loss = 0.46789292Iteration 25, loss = 0.44626805Iteration 18, loss = 0.50817175\n",
      "\n",
      "Iteration 30, loss = 0.45396608Iteration 15, loss = 0.49431523Iteration 2, loss = 0.48636450\n",
      "\n",
      "\n",
      "Iteration 33, loss = 0.47326584Iteration 8, loss = 0.49683966\n",
      "\n",
      "\n",
      "Iteration 18, loss = 0.46785468Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "Iteration 19, loss = 0.50763230\n",
      "\n",
      "Iteration 31, loss = 0.45460764Iteration 16, loss = 0.49449818Iteration 3, loss = 0.47169003\n",
      "Iteration 1, loss = 2.04231729\n",
      "Iteration 34, loss = 0.47325189Iteration 9, loss = 0.49657851\n",
      "\n",
      "\n",
      "Iteration 19, loss = 0.46800037\n",
      "Iteration 20, loss = 0.50746926\n",
      "\n",
      "Iteration 32, loss = 0.45445528Iteration 17, loss = 0.49360187Iteration 4, loss = 0.47014596\n",
      "Iteration 2, loss = 0.46164252\n",
      "Iteration 35, loss = 0.47327787Iteration 10, loss = 0.49672326\n",
      "\n",
      "\n",
      "Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "\n",
      "Iteration 21, loss = 0.50803892\n",
      "\n",
      "Iteration 33, loss = 0.45425732Iteration 18, loss = 0.49365306Iteration 5, loss = 0.46691783Iteration 1, loss = 2.02062864Iteration 3, loss = 0.44820639\n",
      "Iteration 36, loss = 0.47336308Iteration 11, loss = 0.49648884\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 22, loss = 0.50760822\n",
      "\n",
      "Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "Iteration 19, loss = 0.49356356Iteration 6, loss = 0.46578118Iteration 2, loss = 0.46120545Iteration 4, loss = 0.44440679\n",
      "Iteration 37, loss = 0.47372859Iteration 12, loss = 0.49663733Iteration 1, loss = 2.10381680\n",
      "\n",
      "\n",
      "\n",
      "Iteration 23, loss = 0.50828432\n",
      "\n",
      "\n",
      "Iteration 20, loss = 0.49422350Iteration 7, loss = 0.46444437Iteration 3, loss = 0.44920459Iteration 5, loss = 0.44375668"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done   2 out of   8 | elapsed:   29.4s remaining:  1.5min\n",
      "[Parallel(n_jobs=8)]: Done   8 out of   8 | elapsed:   32.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "Iteration 13, loss = 0.49523042Iteration 2, loss = 0.53501898\n",
      "\n",
      "\n",
      "\n",
      "Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 2.10278636\n",
      "\n",
      "Iteration 21, loss = 0.49439718Iteration 8, loss = 0.46458272Iteration 4, loss = 0.44446520Iteration 6, loss = 0.44262359Iteration 1, loss = 2.02348490\n",
      "Iteration 14, loss = 0.49571701Iteration 3, loss = 0.52168720\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 2, loss = 0.49222488\n",
      "\n",
      "Iteration 22, loss = 0.49372906Iteration 9, loss = 0.46347025Iteration 5, loss = 0.44359590Iteration 7, loss = 0.44153590Iteration 2, loss = 0.47807399\n",
      "Iteration 15, loss = 0.49518530Iteration 4, loss = 0.51789588\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 3, loss = 0.47882989\n",
      "\n",
      "Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "Iteration 10, loss = 0.46331190Iteration 6, loss = 0.44135557Iteration 8, loss = 0.44073328Iteration 3, loss = 0.46507289\n",
      "Iteration 16, loss = 0.49500841Iteration 5, loss = 0.51564809Iteration 1, loss = 1.99258247\n",
      "\n",
      "\n",
      "\n",
      "Iteration 4, loss = 0.47508930\n",
      "\n",
      "\n",
      "Iteration 11, loss = 0.46407370Iteration 7, loss = 0.44138988Iteration 9, loss = 0.44026195Iteration 4, loss = 0.46205885\n",
      "Iteration 17, loss = 0.49507097Iteration 6, loss = 0.51447442Iteration 2, loss = 0.42608293\n",
      "\n",
      "\n",
      "\n",
      "Iteration 5, loss = 0.47292762\n",
      "\n",
      "\n",
      "Iteration 12, loss = 0.46316296Iteration 8, loss = 0.44033316Iteration 10, loss = 0.44001558Iteration 5, loss = 0.46007855\n",
      "Iteration 18, loss = 0.49496189Iteration 7, loss = 0.51437089Iteration 3, loss = 0.41370009\n",
      "\n",
      "\n",
      "\n",
      "Iteration 6, loss = 0.47205743\n",
      "\n",
      "\n",
      "Iteration 13, loss = 0.46303717Iteration 9, loss = 0.44012803Iteration 11, loss = 0.43955139Iteration 6, loss = 0.45892721\n",
      "Iteration 19, loss = 0.49439721Iteration 8, loss = 0.51294023Iteration 4, loss = 0.40906143\n",
      "\n",
      "\n",
      "\n",
      "Iteration 7, loss = 0.47110827\n",
      "\n",
      "\n",
      "Iteration 14, loss = 0.46277724Iteration 10, loss = 0.43992048Iteration 12, loss = 0.43971573Iteration 7, loss = 0.45819732\n",
      "Iteration 20, loss = 0.49484854Iteration 9, loss = 0.51395897Iteration 5, loss = 0.40785385\n",
      "\n",
      "\n",
      "\n",
      "Iteration 8, loss = 0.47037218\n",
      "\n",
      "\n",
      "Iteration 15, loss = 0.46250918Iteration 11, loss = 0.43939906Iteration 13, loss = 0.43921155Iteration 8, loss = 0.45792191\n",
      "Iteration 21, loss = 0.49523897Iteration 10, loss = 0.51318932Iteration 6, loss = 0.40668825\n",
      "\n",
      "\n",
      "\n",
      "Iteration 9, loss = 0.47099925\n",
      "\n",
      "\n",
      "Iteration 16, loss = 0.46226569Iteration 12, loss = 0.43834336Iteration 14, loss = 0.43916669Iteration 9, loss = 0.45714694\n",
      "Iteration 22, loss = 0.49465476Iteration 11, loss = 0.51190461Iteration 7, loss = 0.40585705\n",
      "\n",
      "\n",
      "\n",
      "Iteration 10, loss = 0.47052833\n",
      "\n",
      "\n",
      "Iteration 17, loss = 0.46230578Iteration 13, loss = 0.43891672Iteration 15, loss = 0.43889212Iteration 10, loss = 0.45751627\n",
      "Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "Iteration 12, loss = 0.51223046Iteration 8, loss = 0.40575214\n",
      "\n",
      "\n",
      "\n",
      "Iteration 11, loss = 0.47026881Iteration 1, loss = 2.03448948\n",
      "\n",
      "Iteration 18, loss = 0.46193959Iteration 14, loss = 0.43917294Iteration 16, loss = 0.43894430Iteration 11, loss = 0.45665679\n",
      "\n",
      "Iteration 13, loss = 0.51147551Iteration 9, loss = 0.40507478\n",
      "\n",
      "\n",
      "\n",
      "Iteration 12, loss = 0.47010373Iteration 2, loss = 0.44746653\n",
      "\n",
      "Iteration 19, loss = 0.46139625Iteration 15, loss = 0.43861990Iteration 17, loss = 0.43960008Iteration 12, loss = 0.45712009\n",
      "\n",
      "Iteration 14, loss = 0.51259238Iteration 10, loss = 0.40516375\n",
      "\n",
      "\n",
      "\n",
      "Iteration 13, loss = 0.47010113Iteration 3, loss = 0.43335024\n",
      "\n",
      "Iteration 20, loss = 0.46174124Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "Iteration 18, loss = 0.43874317Iteration 13, loss = 0.45591513\n",
      "\n",
      "Iteration 15, loss = 0.51198451Iteration 11, loss = 0.40485300\n",
      "Iteration 1, loss = 2.04040690\n",
      "\n",
      "Iteration 14, loss = 0.46966644Iteration 4, loss = 0.42995554\n",
      "\n",
      "Iteration 21, loss = 0.46142675\n",
      "Iteration 19, loss = 0.43831724Iteration 14, loss = 0.45588330\n",
      "\n",
      "Iteration 16, loss = 0.51138853Iteration 12, loss = 0.40468262\n",
      "Iteration 2, loss = 0.47287361\n",
      "\n",
      "Iteration 15, loss = 0.46969211Iteration 5, loss = 0.42758741\n",
      "\n",
      "Iteration 22, loss = 0.46201241\n",
      "Iteration 20, loss = 0.43826030Iteration 15, loss = 0.45645264\n",
      "\n",
      "Iteration 17, loss = 0.51172611Iteration 13, loss = 0.40410507\n",
      "Iteration 3, loss = 0.45962973\n",
      "\n",
      "Iteration 16, loss = 0.46960238Iteration 6, loss = 0.42739525\n",
      "\n",
      "Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "\n",
      "Iteration 21, loss = 0.43838454Iteration 16, loss = 0.45566115\n",
      "\n",
      "Iteration 18, loss = 0.51185326Iteration 14, loss = 0.40498628Iteration 1, loss = 2.03084997Iteration 4, loss = 0.45628946\n",
      "\n",
      "Iteration 17, loss = 0.47028098Iteration 7, loss = 0.42678173\n",
      "\n",
      "\n",
      "\n",
      "Iteration 22, loss = 0.43832036Iteration 17, loss = 0.45617164\n",
      "\n",
      "Iteration 19, loss = 0.51151010Iteration 15, loss = 0.40423547Iteration 2, loss = 0.48980998Iteration 5, loss = 0.45462499\n",
      "\n",
      "Iteration 18, loss = 0.46926903Iteration 8, loss = 0.42653812\n",
      "\n",
      "\n",
      "\n",
      "Iteration 23, loss = 0.43831361Iteration 18, loss = 0.45546097\n",
      "\n",
      "Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "Iteration 16, loss = 0.40378623Iteration 3, loss = 0.47845573Iteration 6, loss = 0.45420974\n",
      "\n",
      "Iteration 19, loss = 0.46946346Iteration 9, loss = 0.42584840Iteration 1, loss = 2.08743088\n",
      "\n",
      "\n",
      "Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "Iteration 19, loss = 0.45556919\n",
      "\n",
      "\n",
      "Iteration 17, loss = 0.40400082Iteration 4, loss = 0.47511618Iteration 7, loss = 0.45218810Iteration 1, loss = 2.01301877\n",
      "Iteration 20, loss = 0.46927989Iteration 10, loss = 0.42617405Iteration 2, loss = 0.53833829\n",
      "\n",
      "\n",
      "\n",
      "Iteration 20, loss = 0.45550605\n",
      "\n",
      "\n",
      "Iteration 18, loss = 0.40380761Iteration 5, loss = 0.47361425Iteration 8, loss = 0.45300954Iteration 2, loss = 0.47315423\n",
      "Iteration 21, loss = 0.46907515Iteration 11, loss = 0.42611925Iteration 3, loss = 0.52479744\n",
      "\n",
      "\n",
      "\n",
      "Iteration 21, loss = 0.45575141\n",
      "\n",
      "\n",
      "Iteration 19, loss = 0.40321132Iteration 6, loss = 0.47306983Iteration 9, loss = 0.45188776Iteration 3, loss = 0.46113744\n",
      "Iteration 22, loss = 0.46865862Iteration 12, loss = 0.42556928Iteration 4, loss = 0.52168128\n",
      "\n",
      "\n",
      "\n",
      "Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "\n",
      "\n",
      "\n",
      "Iteration 20, loss = 0.40362684Iteration 7, loss = 0.47201550Iteration 10, loss = 0.45177619Iteration 4, loss = 0.45804960Iteration 1, loss = 2.06560084Iteration 23, loss = 0.46846998Iteration 13, loss = 0.42500942Iteration 5, loss = 0.52023449\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 21, loss = 0.40362319Iteration 8, loss = 0.47191645Iteration 11, loss = 0.45121415Iteration 5, loss = 0.45625401Iteration 2, loss = 0.48385207Iteration 24, loss = 0.46867101Iteration 14, loss = 0.42537212Iteration 6, loss = 0.51995876\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 22, loss = 0.40334664Iteration 9, loss = 0.47150613Iteration 12, loss = 0.45098787Iteration 6, loss = 0.45558073Iteration 3, loss = 0.47029051Iteration 25, loss = 0.46934042Iteration 15, loss = 0.42396573Iteration 7, loss = 0.51837613\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "Iteration 10, loss = 0.47149603Iteration 13, loss = 0.45074803Iteration 7, loss = 0.45429912Iteration 4, loss = 0.46681560Iteration 26, loss = 0.46894987Iteration 16, loss = 0.42490472Iteration 8, loss = 0.51786205Iteration 1, loss = 2.11340350\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 11, loss = 0.47093496Iteration 14, loss = 0.45068342Iteration 8, loss = 0.45425522Iteration 5, loss = 0.46507122Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "Iteration 17, loss = 0.42487086Iteration 9, loss = 0.51744432Iteration 2, loss = 0.56695821\n",
      "\n",
      "\n",
      "\n",
      "Iteration 1, loss = 2.10659652\n",
      "\n",
      "\n",
      "Iteration 12, loss = 0.47047718Iteration 15, loss = 0.45073107Iteration 9, loss = 0.45429946Iteration 6, loss = 0.46391953\n",
      "Iteration 18, loss = 0.42516539Iteration 10, loss = 0.51777142Iteration 3, loss = 0.55274434\n",
      "\n",
      "\n",
      "\n",
      "Iteration 2, loss = 0.51061035\n",
      "\n",
      "\n",
      "Iteration 13, loss = 0.46981202Iteration 16, loss = 0.44963363Iteration 10, loss = 0.45309212Iteration 7, loss = 0.46414832\n",
      "Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "Iteration 11, loss = 0.51785163Iteration 4, loss = 0.54980422\n",
      "\n",
      "\n",
      "\n",
      "Iteration 3, loss = 0.49561195Iteration 1, loss = 2.08969570\n",
      "\n",
      "Iteration 14, loss = 0.47097198Iteration 17, loss = 0.45006382Iteration 11, loss = 0.45379699Iteration 8, loss = 0.46240719\n",
      "\n",
      "Iteration 12, loss = 0.51714392Iteration 5, loss = 0.54698181\n",
      "\n",
      "\n",
      "\n",
      "Iteration 4, loss = 0.49288092Iteration 2, loss = 0.54443465\n",
      "\n",
      "Iteration 15, loss = 0.47009803Iteration 18, loss = 0.44942076Iteration 12, loss = 0.45341494Iteration 9, loss = 0.46313604\n",
      "\n",
      "Iteration 13, loss = 0.51721069Iteration 6, loss = 0.54630327\n",
      "\n",
      "\n",
      "\n",
      "Iteration 5, loss = 0.49077650Iteration 3, loss = 0.53060403\n",
      "\n",
      "Iteration 16, loss = 0.47053935Iteration 19, loss = 0.45012972Iteration 13, loss = 0.45231704Iteration 10, loss = 0.46212098\n",
      "\n",
      "Iteration 14, loss = 0.51705283Iteration 7, loss = 0.54639108\n",
      "\n",
      "\n",
      "\n",
      "Iteration 6, loss = 0.49041159Iteration 4, loss = 0.52722926\n",
      "\n",
      "Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "Iteration 20, loss = 0.44930043Iteration 14, loss = 0.45222763Iteration 11, loss = 0.46226764\n",
      "\n",
      "Iteration 15, loss = 0.51628535Iteration 8, loss = 0.54499043Iteration 1, loss = 2.03767816\n",
      "\n",
      "\n",
      "Iteration 7, loss = 0.48996422Iteration 5, loss = 0.52587076\n",
      "\n",
      "\n",
      "Iteration 21, loss = 0.44971043Iteration 15, loss = 0.45251553Iteration 12, loss = 0.46160580\n",
      "\n",
      "Iteration 16, loss = 0.51718024Iteration 9, loss = 0.54493153Iteration 2, loss = 0.46148951\n",
      "\n",
      "\n",
      "Iteration 8, loss = 0.48896310Iteration 6, loss = 0.52422344\n",
      "\n",
      "\n",
      "Iteration 22, loss = 0.44966333Iteration 16, loss = 0.45210659Iteration 13, loss = 0.46157043\n",
      "\n",
      "Iteration 17, loss = 0.51621793Iteration 10, loss = 0.54443433Iteration 3, loss = 0.44806074\n",
      "\n",
      "\n",
      "Iteration 9, loss = 0.48822214Iteration 7, loss = 0.52330324\n",
      "\n",
      "\n",
      "Iteration 23, loss = 0.44965934Iteration 17, loss = 0.45317955Iteration 14, loss = 0.46122917\n",
      "\n",
      "Iteration 18, loss = 0.51606498Iteration 11, loss = 0.54397987Iteration 4, loss = 0.44487118\n",
      "\n",
      "\n",
      "Iteration 10, loss = 0.48866354Iteration 8, loss = 0.52274134\n",
      "\n",
      "\n",
      "Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "Iteration 18, loss = 0.45191695Iteration 15, loss = 0.46193301\n",
      "\n",
      "Iteration 19, loss = 0.51620443Iteration 12, loss = 0.54397659Iteration 5, loss = 0.44280767Iteration 1, loss = 2.03965497\n",
      "\n",
      "Iteration 11, loss = 0.48759774Iteration 9, loss = 0.52235701\n",
      "\n",
      "\n",
      "\n",
      "Iteration 19, loss = 0.45247419Iteration 16, loss = 0.46089252\n",
      "\n",
      "Iteration 20, loss = 0.51683387Iteration 13, loss = 0.54399767Iteration 6, loss = 0.44196408Iteration 2, loss = 0.50150801\n",
      "\n",
      "Iteration 12, loss = 0.48743832Iteration 10, loss = 0.52221496\n",
      "\n",
      "\n",
      "\n",
      "Iteration 20, loss = 0.45251120Iteration 17, loss = 0.46173582\n",
      "\n",
      "Iteration 21, loss = 0.51594316Iteration 14, loss = 0.54380595Iteration 7, loss = 0.44083423Iteration 3, loss = 0.48728762\n",
      "\n",
      "Iteration 13, loss = 0.48783578Iteration 11, loss = 0.52201559\n",
      "\n",
      "\n",
      "\n",
      "Iteration 21, loss = 0.45185791Iteration 18, loss = 0.46116031\n",
      "\n",
      "Iteration 22, loss = 0.51578372Iteration 15, loss = 0.54346044Iteration 8, loss = 0.44055171Iteration 4, loss = 0.48338891\n",
      "\n",
      "Iteration 14, loss = 0.48745482Iteration 12, loss = 0.52248115\n",
      "\n",
      "\n",
      "\n",
      "Iteration 22, loss = 0.45240378Iteration 19, loss = 0.46105485\n",
      "\n",
      "Iteration 23, loss = 0.51559699Iteration 16, loss = 0.54248542Iteration 9, loss = 0.44014302Iteration 5, loss = 0.48289795\n",
      "\n",
      "Iteration 15, loss = 0.48722568Iteration 13, loss = 0.52170447\n",
      "\n",
      "\n",
      "\n",
      "Iteration 23, loss = 0.45202189Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "\n",
      "\n",
      "Iteration 24, loss = 0.51542399Iteration 17, loss = 0.54298336Iteration 10, loss = 0.43991159Iteration 6, loss = 0.48081325\n",
      "Iteration 1, loss = 2.03108729Iteration 16, loss = 0.48670379Iteration 14, loss = 0.52141482\n",
      "\n",
      "\n",
      "\n",
      "Iteration 24, loss = 0.45177835\n",
      "\n",
      "\n",
      "Iteration 25, loss = 0.51565054Iteration 18, loss = 0.54259299Iteration 11, loss = 0.43938828Iteration 7, loss = 0.47967642\n",
      "Iteration 2, loss = 0.43679439Iteration 17, loss = 0.48608400Iteration 15, loss = 0.52122205\n",
      "\n",
      "\n",
      "\n",
      "Iteration 25, loss = 0.45211319\n",
      "\n",
      "\n",
      "Iteration 26, loss = 0.51552049Iteration 19, loss = 0.54338152Iteration 12, loss = 0.43965832Iteration 8, loss = 0.47911571\n",
      "Iteration 3, loss = 0.42257304Iteration 18, loss = 0.48677292Iteration 16, loss = 0.52159184\n",
      "\n",
      "\n",
      "\n",
      "Iteration 26, loss = 0.45130871\n",
      "\n",
      "\n",
      "Iteration 27, loss = 0.51635126Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "Iteration 13, loss = 0.43905442Iteration 9, loss = 0.47924573\n",
      "Iteration 4, loss = 0.41924985Iteration 19, loss = 0.48674440Iteration 17, loss = 0.52082547\n",
      "Iteration 1, loss = 2.03853244\n",
      "\n",
      "Iteration 27, loss = 0.45216776\n",
      "\n",
      "\n",
      "Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "\n",
      "Iteration 14, loss = 0.43987088Iteration 10, loss = 0.47929365\n",
      "Iteration 5, loss = 0.41715997Iteration 20, loss = 0.48671305Iteration 18, loss = 0.52116199Iteration 1, loss = 2.00614036Iteration 2, loss = 0.47041697\n",
      "\n",
      "Iteration 28, loss = 0.45160440\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 15, loss = 0.43873325Iteration 11, loss = 0.47860178\n",
      "Iteration 6, loss = 0.41634890Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "Iteration 19, loss = 0.52036041Iteration 2, loss = 0.43292019Iteration 3, loss = 0.45789014\n",
      "\n",
      "Iteration 29, loss = 0.45186953\n",
      "Iteration 1, loss = 2.03701910\n",
      "\n",
      "\n",
      "Iteration 16, loss = 0.43890543Iteration 12, loss = 0.47818448\n",
      "Iteration 7, loss = 0.41561314\n",
      "Iteration 20, loss = 0.52071317Iteration 3, loss = 0.41834417Iteration 4, loss = 0.45562734\n",
      "\n",
      "Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "\n",
      "Iteration 2, loss = 0.47921187\n",
      "\n",
      "\n",
      "Iteration 17, loss = 0.43885198Iteration 13, loss = 0.47829788Iteration 1, loss = 2.02237780Iteration 8, loss = 0.41550814\n",
      "Iteration 21, loss = 0.52035633Iteration 4, loss = 0.41446024Iteration 5, loss = 0.45392164\n",
      "\n",
      "\n",
      "\n",
      "Iteration 3, loss = 0.46597697\n",
      "\n",
      "\n",
      "Iteration 18, loss = 0.43898135Iteration 14, loss = 0.47771478Iteration 2, loss = 0.45180390Iteration 9, loss = 0.41470654\n",
      "Iteration 22, loss = 0.52062778Iteration 5, loss = 0.41349477Iteration 6, loss = 0.45283980\n",
      "\n",
      "\n",
      "\n",
      "Iteration 4, loss = 0.46317811\n",
      "\n",
      "\n",
      "Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "Iteration 15, loss = 0.47762853Iteration 3, loss = 0.43787585Iteration 10, loss = 0.41461308\n",
      "Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "Iteration 6, loss = 0.41165433Iteration 7, loss = 0.45281292Iteration 1, loss = 2.12131143\n",
      "\n",
      "\n",
      "Iteration 5, loss = 0.46141067Iteration 1, loss = 2.04964450\n",
      "\n",
      "\n",
      "Iteration 16, loss = 0.47775097Iteration 4, loss = 0.43315588Iteration 11, loss = 0.41393535\n",
      "\n",
      "Iteration 7, loss = 0.41115996Iteration 8, loss = 0.45201050Iteration 2, loss = 0.56624946\n",
      "\n",
      "\n",
      "Iteration 6, loss = 0.46118326Iteration 2, loss = 0.46917484\n",
      "\n",
      "\n",
      "Iteration 17, loss = 0.47801886Iteration 5, loss = 0.43077241Iteration 12, loss = 0.41348147\n",
      "\n",
      "Iteration 8, loss = 0.41071419Iteration 9, loss = 0.45237126Iteration 3, loss = 0.55274197\n",
      "\n",
      "\n",
      "Iteration 7, loss = 0.46021916Iteration 3, loss = 0.45543266\n",
      "\n",
      "\n",
      "Iteration 18, loss = 0.47734969Iteration 6, loss = 0.43016835Iteration 13, loss = 0.41361705\n",
      "\n",
      "Iteration 9, loss = 0.40986224Iteration 10, loss = 0.45135460Iteration 4, loss = 0.54958436\n",
      "\n",
      "\n",
      "Iteration 8, loss = 0.45971556Iteration 4, loss = 0.45192200\n",
      "\n",
      "\n",
      "Iteration 19, loss = 0.47691015Iteration 7, loss = 0.42870062Iteration 14, loss = 0.41360898\n",
      "\n",
      "Iteration 10, loss = 0.40927037Iteration 11, loss = 0.45081875Iteration 5, loss = 0.54760637\n",
      "\n",
      "\n",
      "Iteration 9, loss = 0.45971627Iteration 5, loss = 0.45047932\n",
      "\n",
      "\n",
      "Iteration 20, loss = 0.47681118Iteration 8, loss = 0.42852853Iteration 15, loss = 0.41272592\n",
      "\n",
      "Iteration 11, loss = 0.40978860Iteration 12, loss = 0.45157745Iteration 6, loss = 0.54691663\n",
      "\n",
      "\n",
      "Iteration 10, loss = 0.45904624Iteration 6, loss = 0.44893134\n",
      "\n",
      "\n",
      "Iteration 21, loss = 0.47723279Iteration 9, loss = 0.42795337Iteration 16, loss = 0.41344341\n",
      "\n",
      "Iteration 12, loss = 0.40974079Iteration 13, loss = 0.45080463Iteration 7, loss = 0.54568431\n",
      "\n",
      "\n",
      "Iteration 11, loss = 0.45884289Iteration 7, loss = 0.44862918\n",
      "\n",
      "\n",
      "Iteration 22, loss = 0.47675602Iteration 10, loss = 0.42863536Iteration 17, loss = 0.41300369\n",
      "\n",
      "Iteration 13, loss = 0.40923637Iteration 14, loss = 0.45015761Iteration 8, loss = 0.54521233\n",
      "\n",
      "\n",
      "Iteration 12, loss = 0.45870600Iteration 8, loss = 0.44876858\n",
      "\n",
      "\n",
      "Iteration 23, loss = 0.47706279Iteration 11, loss = 0.42711343Iteration 18, loss = 0.41295318\n",
      "\n",
      "Iteration 14, loss = 0.40895331Iteration 15, loss = 0.45066690Iteration 9, loss = 0.54488243\n",
      "\n",
      "\n",
      "Iteration 13, loss = 0.45819992Iteration 9, loss = 0.44758358\n",
      "\n",
      "\n",
      "Iteration 24, loss = 0.47661065Iteration 12, loss = 0.42701895Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "\n",
      "\n",
      "Iteration 15, loss = 0.40883580Iteration 16, loss = 0.44960431Iteration 10, loss = 0.54325348\n",
      "\n",
      "Iteration 1, loss = 2.05850221Iteration 14, loss = 0.45782604Iteration 10, loss = 0.44725806\n",
      "\n",
      "\n",
      "Iteration 25, loss = 0.47637699Iteration 13, loss = 0.42743476\n",
      "\n",
      "\n",
      "Iteration 16, loss = 0.40942072Iteration 17, loss = 0.45044659Iteration 11, loss = 0.54380766\n",
      "\n",
      "Iteration 2, loss = 0.49740592Iteration 15, loss = 0.45794708Iteration 11, loss = 0.44727370\n",
      "\n",
      "\n",
      "Iteration 26, loss = 0.47602844Iteration 14, loss = 0.42670965\n",
      "\n",
      "\n",
      "Iteration 17, loss = 0.40831113Iteration 18, loss = 0.45003876Iteration 12, loss = 0.54440644\n",
      "\n",
      "Iteration 3, loss = 0.48541870Iteration 16, loss = 0.45767629Iteration 12, loss = 0.44663471\n",
      "\n",
      "\n",
      "Iteration 27, loss = 0.47593485Iteration 15, loss = 0.42680926\n",
      "\n",
      "\n",
      "Iteration 18, loss = 0.40838573Iteration 19, loss = 0.44967060Iteration 13, loss = 0.54360526\n",
      "\n",
      "Iteration 4, loss = 0.48201521Iteration 17, loss = 0.45786956Iteration 13, loss = 0.44637292\n",
      "\n",
      "\n",
      "Iteration 28, loss = 0.47685119Iteration 16, loss = 0.42617666\n",
      "\n",
      "\n",
      "Iteration 19, loss = 0.40840894Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "\n",
      "\n",
      "Iteration 5, loss = 0.48123426Iteration 18, loss = 0.45717659Iteration 14, loss = 0.44631240\n",
      "Iteration 1, loss = 2.00355446Iteration 1, loss = 2.03865730Iteration 29, loss = 0.47611421Iteration 17, loss = 0.42649118\n",
      "\n",
      "\n",
      "Iteration 20, loss = 0.40812394\n",
      "\n",
      "\n",
      "\n",
      "Iteration 6, loss = 0.47952945Iteration 19, loss = 0.45741022Iteration 15, loss = 0.44677143\n",
      "Iteration 2, loss = 0.46411034Iteration 2, loss = 0.46911492Iteration 30, loss = 0.47604476Iteration 18, loss = 0.42623753\n",
      "\n",
      "\n",
      "Iteration 21, loss = 0.40819830\n",
      "\n",
      "\n",
      "\n",
      "Iteration 7, loss = 0.47918940Iteration 20, loss = 0.45764968Iteration 16, loss = 0.44607560\n",
      "Iteration 3, loss = 0.44931773Iteration 3, loss = 0.45543553Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "Iteration 19, loss = 0.42639128\n",
      "\n",
      "\n",
      "Iteration 22, loss = 0.40811664\n",
      "\n",
      "Iteration 1, loss = 2.05879284\n",
      "Iteration 8, loss = 0.47880495Iteration 21, loss = 0.45778677Iteration 17, loss = 0.44670762\n",
      "Iteration 4, loss = 0.44599195Iteration 4, loss = 0.45176799\n",
      "Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "\n",
      "\n",
      "\n",
      "Iteration 23, loss = 0.40830383\n",
      "\n",
      "Iteration 2, loss = 0.48170959Iteration 1, loss = 2.01633651Iteration 9, loss = 0.47824216Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "Iteration 18, loss = 0.44604167\n",
      "Iteration 5, loss = 0.44355285Iteration 5, loss = 0.45030479\n",
      "\n",
      "\n",
      "Iteration 1, loss = 2.12341399\n",
      "Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "\n",
      "\n",
      "Iteration 3, loss = 0.46867472Iteration 2, loss = 0.46160389Iteration 10, loss = 0.47757702\n",
      "Iteration 19, loss = 0.44611212Iteration 1, loss = 2.06088260Iteration 6, loss = 0.44291346Iteration 6, loss = 0.44881571\n",
      "\n",
      "\n",
      "Iteration 2, loss = 0.54881304\n",
      "\n",
      "\n",
      "\n",
      "Iteration 4, loss = 0.46622073Iteration 3, loss = 0.44918276Iteration 11, loss = 0.47754125\n",
      "Iteration 20, loss = 0.44615677Iteration 2, loss = 0.48925282Iteration 7, loss = 0.44174579Iteration 7, loss = 0.44792440\n",
      "\n",
      "\n",
      "Iteration 3, loss = 0.53466994\n",
      "\n",
      "\n",
      "\n",
      "Iteration 5, loss = 0.46377146Iteration 4, loss = 0.44521926Iteration 12, loss = 0.47774158\n",
      "Iteration 21, loss = 0.44580258Iteration 3, loss = 0.47589928Iteration 8, loss = 0.44153835Iteration 8, loss = 0.44795432\n",
      "\n",
      "\n",
      "Iteration 4, loss = 0.53043684\n",
      "\n",
      "\n",
      "\n",
      "Iteration 6, loss = 0.46306340Iteration 5, loss = 0.44381676Iteration 13, loss = 0.47669679\n",
      "Iteration 22, loss = 0.44567160Iteration 4, loss = 0.47212192Iteration 9, loss = 0.44114217Iteration 9, loss = 0.44759142\n",
      "\n",
      "\n",
      "Iteration 5, loss = 0.52796613\n",
      "\n",
      "\n",
      "\n",
      "Iteration 7, loss = 0.46162351Iteration 6, loss = 0.44272297Iteration 14, loss = 0.47631799\n",
      "Iteration 23, loss = 0.44559521Iteration 5, loss = 0.47085698Iteration 10, loss = 0.44094439Iteration 10, loss = 0.44710806\n",
      "\n",
      "\n",
      "Iteration 6, loss = 0.52648962\n",
      "\n",
      "\n",
      "\n",
      "Iteration 8, loss = 0.46117798Iteration 7, loss = 0.44256882Iteration 15, loss = 0.47661151\n",
      "Iteration 24, loss = 0.44547515Iteration 6, loss = 0.47007077Iteration 11, loss = 0.44139817Iteration 11, loss = 0.44706009\n",
      "\n",
      "\n",
      "Iteration 7, loss = 0.52616776\n",
      "\n",
      "\n",
      "\n",
      "Iteration 9, loss = 0.46082686Iteration 8, loss = 0.44178244Iteration 16, loss = 0.47666550\n",
      "Iteration 25, loss = 0.44563124Iteration 7, loss = 0.46894708Iteration 12, loss = 0.44056219Iteration 12, loss = 0.44671649\n",
      "\n",
      "\n",
      "Iteration 8, loss = 0.52574690\n",
      "\n",
      "\n",
      "\n",
      "Iteration 10, loss = 0.45992079Iteration 9, loss = 0.44176706Iteration 17, loss = 0.47597834\n",
      "Iteration 26, loss = 0.44566771Iteration 8, loss = 0.46843846Iteration 13, loss = 0.44042264Iteration 13, loss = 0.44617760\n",
      "\n",
      "\n",
      "Iteration 9, loss = 0.52533856\n",
      "\n",
      "\n",
      "\n",
      "Iteration 11, loss = 0.46061722Iteration 10, loss = 0.44096487Iteration 18, loss = 0.47693754\n",
      "Iteration 27, loss = 0.44563104Iteration 9, loss = 0.46817699Iteration 14, loss = 0.43982509Iteration 14, loss = 0.44719203\n",
      "\n",
      "\n",
      "Iteration 10, loss = 0.52496973\n",
      "\n",
      "\n",
      "\n",
      "Iteration 12, loss = 0.46042769Iteration 11, loss = 0.44143466Iteration 19, loss = 0.47602156\n",
      "Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "Iteration 10, loss = 0.46742039Iteration 15, loss = 0.44040493Iteration 15, loss = 0.44630524\n",
      "\n",
      "\n",
      "Iteration 11, loss = 0.52500784Iteration 1, loss = 2.01852794\n",
      "\n",
      "\n",
      "Iteration 13, loss = 0.45940965Iteration 12, loss = 0.44072732Iteration 20, loss = 0.47595844\n",
      "\n",
      "Iteration 11, loss = 0.46725976Iteration 16, loss = 0.43985187Iteration 16, loss = 0.44597663\n",
      "\n",
      "\n",
      "Iteration 12, loss = 0.52438557Iteration 2, loss = 0.46438419\n",
      "\n",
      "\n",
      "Iteration 14, loss = 0.46036012Iteration 13, loss = 0.44116307Iteration 21, loss = 0.47632566\n",
      "\n",
      "Iteration 12, loss = 0.46759433Iteration 17, loss = 0.43908679Iteration 17, loss = 0.44501847\n",
      "\n",
      "\n",
      "Iteration 13, loss = 0.52435953Iteration 3, loss = 0.45275777\n",
      "\n",
      "\n",
      "Iteration 15, loss = 0.45949478Iteration 14, loss = 0.44031556Iteration 22, loss = 0.47589884\n",
      "\n",
      "Iteration 13, loss = 0.46689478Iteration 18, loss = 0.44010126Iteration 18, loss = 0.44579973\n",
      "\n",
      "\n",
      "Iteration 14, loss = 0.52389754Iteration 4, loss = 0.44937720\n",
      "\n",
      "\n",
      "Iteration 16, loss = 0.45903269Iteration 15, loss = 0.44043969Iteration 23, loss = 0.47555339\n",
      "\n",
      "Iteration 14, loss = 0.46662753Iteration 19, loss = 0.43968513Iteration 19, loss = 0.44496525\n",
      "\n",
      "\n",
      "Iteration 15, loss = 0.52362162Iteration 5, loss = 0.44802569\n",
      "\n",
      "\n",
      "Iteration 17, loss = 0.45936914Iteration 16, loss = 0.43989593Iteration 24, loss = 0.47570612\n",
      "\n",
      "Iteration 15, loss = 0.46678678Iteration 20, loss = 0.43919601Iteration 20, loss = 0.44588995\n",
      "\n",
      "\n",
      "Iteration 16, loss = 0.52432303Iteration 6, loss = 0.44634694\n",
      "\n",
      "\n",
      "Iteration 18, loss = 0.45949965Iteration 17, loss = 0.44038463Iteration 25, loss = 0.47570110\n",
      "\n",
      "Iteration 16, loss = 0.46674206Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "Iteration 21, loss = 0.44539942\n",
      "\n",
      "\n",
      "Iteration 17, loss = 0.52317923Iteration 7, loss = 0.44590330\n",
      "Iteration 1, loss = 2.06420793\n",
      "Iteration 19, loss = 0.45864829Iteration 18, loss = 0.43948900Iteration 26, loss = 0.47579841\n",
      "\n",
      "Iteration 17, loss = 0.46599998\n",
      "Iteration 22, loss = 0.44486403\n",
      "\n",
      "\n",
      "Iteration 18, loss = 0.52362500Iteration 8, loss = 0.44550946\n",
      "Iteration 2, loss = 0.48156820\n",
      "Iteration 20, loss = 0.45958300Iteration 19, loss = 0.44012634Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "\n",
      "\n",
      "Iteration 18, loss = 0.46642320\n",
      "Iteration 23, loss = 0.44506714\n",
      "\n",
      "Iteration 1, loss = 2.08098568Iteration 19, loss = 0.52332545Iteration 9, loss = 0.44573794\n",
      "Iteration 3, loss = 0.47007016\n",
      "Iteration 21, loss = 0.45918442Iteration 20, loss = 0.43917694\n",
      "\n",
      "\n",
      "Iteration 19, loss = 0.46596869\n",
      "Iteration 24, loss = 0.44530003\n",
      "\n",
      "Iteration 2, loss = 0.48105785Iteration 20, loss = 0.52325705Iteration 10, loss = 0.44513763\n",
      "Iteration 4, loss = 0.46674514\n",
      "Iteration 22, loss = 0.45967236Iteration 21, loss = 0.43969155\n",
      "\n",
      "\n",
      "Iteration 20, loss = 0.46629164\n",
      "Iteration 25, loss = 0.44477131\n",
      "\n",
      "Iteration 3, loss = 0.46793775Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "Iteration 11, loss = 0.44442377\n",
      "Iteration 5, loss = 0.46449273\n",
      "Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "Iteration 22, loss = 0.43991073\n",
      "Iteration 1, loss = 2.00838313\n",
      "Iteration 21, loss = 0.46571075\n",
      "Iteration 26, loss = 0.44445676Iteration 1, loss = 2.07880052\n",
      "Iteration 4, loss = 0.46391208\n",
      "Iteration 12, loss = 0.44436294\n",
      "Iteration 6, loss = 0.46398904\n",
      "\n",
      "Iteration 23, loss = 0.44008999\n",
      "Iteration 2, loss = 0.44550048\n",
      "Iteration 22, loss = 0.46577437\n",
      "Iteration 27, loss = 0.44478971Iteration 2, loss = 0.51949899\n",
      "Iteration 5, loss = 0.46243626\n",
      "Iteration 13, loss = 0.44438998\n",
      "Iteration 7, loss = 0.46294803\n",
      "\n",
      "Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "\n",
      "Iteration 3, loss = 0.43285544\n",
      "Iteration 23, loss = 0.46567320\n",
      "Iteration 28, loss = 0.44464929Iteration 3, loss = 0.50430137Iteration 1, loss = 2.08551258Iteration 6, loss = 0.46231502\n",
      "Iteration 14, loss = 0.44472330\n",
      "Iteration 8, loss = 0.46215681\n",
      "\n",
      "\n",
      "\n",
      "Iteration 4, loss = 0.42905092\n",
      "Iteration 24, loss = 0.46535586\n",
      "Iteration 29, loss = 0.44471978Iteration 4, loss = 0.50094924Iteration 2, loss = 0.53840379Iteration 7, loss = 0.46142157\n",
      "Iteration 15, loss = 0.44348650\n",
      "Iteration 9, loss = 0.46204833\n",
      "\n",
      "\n",
      "\n",
      "Iteration 5, loss = 0.42777826\n",
      "Iteration 25, loss = 0.46562265\n",
      "Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "Iteration 5, loss = 0.49999513Iteration 3, loss = 0.52704215Iteration 8, loss = 0.46076021\n",
      "Iteration 16, loss = 0.44362603\n",
      "Iteration 10, loss = 0.46204285Iteration 1, loss = 2.04078301\n",
      "\n",
      "\n",
      "Iteration 6, loss = 0.42693010\n",
      "Iteration 26, loss = 0.46558518\n",
      "\n",
      "Iteration 6, loss = 0.49829807Iteration 4, loss = 0.52262861Iteration 9, loss = 0.45991771\n",
      "Iteration 17, loss = 0.44308514\n",
      "Iteration 11, loss = 0.46198313Iteration 2, loss = 0.48543148\n",
      "\n",
      "\n",
      "Iteration 7, loss = 0.42614885\n",
      "Iteration 27, loss = 0.46542952\n",
      "\n",
      "Iteration 7, loss = 0.49741017Iteration 5, loss = 0.52142521Iteration 10, loss = 0.46012704\n",
      "Iteration 18, loss = 0.44340798\n",
      "Iteration 12, loss = 0.46174408Iteration 3, loss = 0.47139986\n",
      "\n",
      "\n",
      "Iteration 8, loss = 0.42549005\n",
      "Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "\n",
      "\n",
      "Iteration 8, loss = 0.49724576Iteration 6, loss = 0.51988945Iteration 11, loss = 0.46027459\n",
      "Iteration 19, loss = 0.44354780Iteration 1, loss = 2.07799548Iteration 13, loss = 0.46120938Iteration 4, loss = 0.46862533\n",
      "\n",
      "\n",
      "Iteration 9, loss = 0.42477058\n",
      "\n",
      "\n",
      "\n",
      "Iteration 9, loss = 0.49667517Iteration 7, loss = 0.51917076Iteration 12, loss = 0.45958697\n",
      "Iteration 20, loss = 0.44334212Iteration 2, loss = 0.48417465Iteration 14, loss = 0.46171048Iteration 5, loss = 0.46596808\n",
      "\n",
      "\n",
      "Iteration 10, loss = 0.42449780\n",
      "\n",
      "\n",
      "\n",
      "Iteration 10, loss = 0.49580586Iteration 8, loss = 0.51942759Iteration 13, loss = 0.45958298\n",
      "Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "Iteration 3, loss = 0.47031335Iteration 15, loss = 0.46113565Iteration 6, loss = 0.46526910\n",
      "\n",
      "\n",
      "Iteration 11, loss = 0.42403570Iteration 1, loss = 2.02266212\n",
      "\n",
      "\n",
      "Iteration 11, loss = 0.49548888Iteration 9, loss = 0.51780998Iteration 14, loss = 0.45953027\n",
      "\n",
      "Iteration 4, loss = 0.46699837Iteration 16, loss = 0.46104094Iteration 7, loss = 0.46493793\n",
      "\n",
      "\n",
      "Iteration 12, loss = 0.42392154Iteration 2, loss = 0.45297760\n",
      "\n",
      "\n",
      "Iteration 12, loss = 0.49541722Iteration 10, loss = 0.51820534Iteration 15, loss = 0.45911387\n",
      "\n",
      "Iteration 5, loss = 0.46580897Iteration 17, loss = 0.46068434Iteration 8, loss = 0.46345165\n",
      "\n",
      "\n",
      "Iteration 13, loss = 0.42381254Iteration 3, loss = 0.43843625\n",
      "\n",
      "\n",
      "Iteration 13, loss = 0.49560830Iteration 11, loss = 0.51777582Iteration 16, loss = 0.45930830\n",
      "\n",
      "Iteration 6, loss = 0.46422485Iteration 18, loss = 0.46080661Iteration 9, loss = 0.46311623\n",
      "\n",
      "\n",
      "Iteration 14, loss = 0.42371531Iteration 4, loss = 0.43434388\n",
      "\n",
      "\n",
      "Iteration 14, loss = 0.49519840Iteration 12, loss = 0.51754909Iteration 17, loss = 0.45936241\n",
      "\n",
      "Iteration 7, loss = 0.46381990Iteration 19, loss = 0.46089048Iteration 10, loss = 0.46359738\n",
      "\n",
      "\n",
      "Iteration 15, loss = 0.42417649Iteration 5, loss = 0.43299856\n",
      "\n",
      "\n",
      "Iteration 15, loss = 0.49466165Iteration 13, loss = 0.51780962Iteration 18, loss = 0.45858081\n",
      "\n",
      "Iteration 8, loss = 0.46335950Iteration 20, loss = 0.46063241Iteration 11, loss = 0.46319935\n",
      "\n",
      "\n",
      "Iteration 16, loss = 0.42309062Iteration 6, loss = 0.43152252\n",
      "\n",
      "\n",
      "Iteration 16, loss = 0.49472757Iteration 14, loss = 0.51739905Iteration 19, loss = 0.45867050\n",
      "\n",
      "Iteration 9, loss = 0.46347125Iteration 21, loss = 0.46048242Iteration 12, loss = 0.46270138\n",
      "\n",
      "\n",
      "Iteration 17, loss = 0.42343681Iteration 7, loss = 0.43061562\n",
      "\n",
      "\n",
      "Iteration 17, loss = 0.49482014Iteration 15, loss = 0.51688820Iteration 20, loss = 0.45871876\n",
      "\n",
      "Iteration 10, loss = 0.46280735Iteration 22, loss = 0.46048647Iteration 13, loss = 0.46291934\n",
      "\n",
      "\n",
      "Iteration 18, loss = 0.42345635Iteration 8, loss = 0.43101924\n",
      "\n",
      "\n",
      "Iteration 18, loss = 0.49417101Iteration 16, loss = 0.51766176Iteration 21, loss = 0.45880355\n",
      "\n",
      "Iteration 11, loss = 0.46216770Iteration 23, loss = 0.46076436Iteration 14, loss = 0.46267935\n",
      "\n",
      "\n",
      "Iteration 19, loss = 0.42327656Iteration 9, loss = 0.42989819\n",
      "\n",
      "\n",
      "Iteration 19, loss = 0.49425212Iteration 17, loss = 0.51689775Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "\n",
      "\n",
      "Iteration 12, loss = 0.46206326Iteration 24, loss = 0.46001019Iteration 15, loss = 0.46208492\n",
      "\n",
      "Iteration 1, loss = 2.03058399Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "Iteration 10, loss = 0.42981290\n",
      "\n",
      "\n",
      "Iteration 20, loss = 0.49472974Iteration 18, loss = 0.51712147\n",
      "Iteration 1, loss = 2.09147228\n",
      "Iteration 13, loss = 0.46134048Iteration 25, loss = 0.46023301Iteration 16, loss = 0.46200538\n",
      "\n",
      "Iteration 2, loss = 0.48329751\n",
      "Iteration 11, loss = 0.42931227\n",
      "\n",
      "\n",
      "Iteration 21, loss = 0.49414864Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "\n",
      "Iteration 2, loss = 0.54417995\n",
      "Iteration 14, loss = 0.46173117Iteration 26, loss = 0.46021666Iteration 17, loss = 0.46170645\n",
      "Iteration 1, loss = 2.04920563Iteration 3, loss = 0.47075254\n",
      "Iteration 12, loss = 0.42886851\n",
      "\n",
      "\n",
      "Iteration 22, loss = 0.49374939\n",
      "\n",
      "Iteration 3, loss = 0.53272899\n",
      "Iteration 15, loss = 0.46174485Iteration 27, loss = 0.46075149Iteration 18, loss = 0.46131812\n",
      "Iteration 2, loss = 0.49408279Iteration 4, loss = 0.46785909\n",
      "Iteration 13, loss = 0.42938998\n",
      "\n",
      "\n",
      "Iteration 23, loss = 0.49357004\n",
      "\n",
      "Iteration 4, loss = 0.53000187\n",
      "Iteration 16, loss = 0.46106826Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "Iteration 19, loss = 0.46165983\n",
      "Iteration 3, loss = 0.47998926Iteration 5, loss = 0.46631031\n",
      "Iteration 14, loss = 0.42867199\n",
      "Iteration 1, loss = 2.03130074\n",
      "Iteration 24, loss = 0.49355833\n",
      "\n",
      "Iteration 5, loss = 0.52805185\n",
      "Iteration 17, loss = 0.46068333\n",
      "Iteration 20, loss = 0.46170999\n",
      "Iteration 4, loss = 0.47559421Iteration 6, loss = 0.46583920\n",
      "Iteration 15, loss = 0.42881780\n",
      "Iteration 2, loss = 0.47251854\n",
      "Iteration 25, loss = 0.49350411\n",
      "\n",
      "Iteration 6, loss = 0.52697879\n",
      "Iteration 18, loss = 0.46128991\n",
      "Iteration 21, loss = 0.46187706\n",
      "Iteration 5, loss = 0.47372524Iteration 7, loss = 0.46445069\n",
      "Iteration 16, loss = 0.42826790\n",
      "Iteration 3, loss = 0.45814919\n",
      "Iteration 26, loss = 0.49362804\n",
      "\n",
      "Iteration 7, loss = 0.52555874\n",
      "Iteration 19, loss = 0.46155739\n",
      "Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "\n",
      "Iteration 6, loss = 0.47269361Iteration 8, loss = 0.46450239\n",
      "Iteration 17, loss = 0.42817951\n",
      "Iteration 4, loss = 0.45416574Iteration 1, loss = 2.08999761Iteration 27, loss = 0.49349004\n",
      "\n",
      "Iteration 8, loss = 0.52525400\n",
      "Iteration 20, loss = 0.46148647\n",
      "\n",
      "\n",
      "Iteration 7, loss = 0.47229333Iteration 9, loss = 0.46461175\n",
      "Iteration 18, loss = 0.42854575\n",
      "Iteration 5, loss = 0.45268368Iteration 2, loss = 0.48001633Iteration 28, loss = 0.49339837\n",
      "\n",
      "Iteration 9, loss = 0.52553031\n",
      "Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "\n",
      "\n",
      "\n",
      "Iteration 8, loss = 0.47087051Iteration 10, loss = 0.46421224\n",
      "Iteration 19, loss = 0.42857666Iteration 1, loss = 2.03591300Iteration 6, loss = 0.45142771Iteration 3, loss = 0.46598176Iteration 29, loss = 0.49322177\n",
      "\n",
      "Iteration 10, loss = 0.52538337\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 9, loss = 0.47045903Iteration 11, loss = 0.46341653\n",
      "Iteration 20, loss = 0.42843759Iteration 2, loss = 0.49362571Iteration 7, loss = 0.44986257Iteration 4, loss = 0.46278367Iteration 30, loss = 0.49312887\n",
      "\n",
      "Iteration 11, loss = 0.52520703\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 10, loss = 0.47030848Iteration 12, loss = 0.46331029\n",
      "Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "Iteration 3, loss = 0.48153523Iteration 8, loss = 0.45015414Iteration 5, loss = 0.46045750Iteration 31, loss = 0.49287462\n",
      "\n",
      "Iteration 12, loss = 0.52504650Iteration 1, loss = 2.07465174\n",
      "\n",
      "\n",
      "\n",
      "Iteration 11, loss = 0.47035995Iteration 13, loss = 0.46390599\n",
      "\n",
      "Iteration 4, loss = 0.47776758Iteration 9, loss = 0.44994482Iteration 6, loss = 0.45926785Iteration 32, loss = 0.49270490\n",
      "\n",
      "Iteration 13, loss = 0.52422328Iteration 2, loss = 0.46976924\n",
      "\n",
      "\n",
      "\n",
      "Iteration 12, loss = 0.46944902Iteration 14, loss = 0.46301060\n",
      "\n",
      "Iteration 5, loss = 0.47662672Iteration 10, loss = 0.44886141Iteration 7, loss = 0.45909777Iteration 33, loss = 0.49321087\n",
      "\n",
      "Iteration 14, loss = 0.52493223Iteration 3, loss = 0.45552542\n",
      "\n",
      "\n",
      "\n",
      "Iteration 13, loss = 0.46991536Iteration 15, loss = 0.46296253\n",
      "\n",
      "Iteration 6, loss = 0.47453884Iteration 11, loss = 0.44809994Iteration 8, loss = 0.45908950Iteration 34, loss = 0.49258516\n",
      "\n",
      "Iteration 15, loss = 0.52415708Iteration 4, loss = 0.45238372\n",
      "\n",
      "\n",
      "\n",
      "Iteration 14, loss = 0.46960965Iteration 16, loss = 0.46266328\n",
      "\n",
      "Iteration 7, loss = 0.47406465Iteration 12, loss = 0.44864998Iteration 9, loss = 0.45849608Iteration 35, loss = 0.49288238\n",
      "\n",
      "Iteration 16, loss = 0.52393208Iteration 5, loss = 0.45082493\n",
      "\n",
      "\n",
      "\n",
      "Iteration 15, loss = 0.46940743Iteration 17, loss = 0.46292193\n",
      "\n",
      "Iteration 8, loss = 0.47404117Iteration 13, loss = 0.44867765Iteration 10, loss = 0.45849642Iteration 36, loss = 0.49281184\n",
      "\n",
      "Iteration 17, loss = 0.52424257Iteration 6, loss = 0.44963704\n",
      "\n",
      "\n",
      "\n",
      "Iteration 16, loss = 0.46867050Iteration 18, loss = 0.46286794\n",
      "\n",
      "Iteration 9, loss = 0.47330321Iteration 14, loss = 0.44815620Iteration 11, loss = 0.45699869Iteration 37, loss = 0.49255852\n",
      "\n",
      "Iteration 18, loss = 0.52370163Iteration 7, loss = 0.44942726\n",
      "\n",
      "\n",
      "\n",
      "Iteration 17, loss = 0.46870947Iteration 19, loss = 0.46237762\n",
      "\n",
      "Iteration 10, loss = 0.47307261Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "Iteration 12, loss = 0.45714241Iteration 38, loss = 0.49281394\n",
      "\n",
      "Iteration 19, loss = 0.52351446Iteration 8, loss = 0.44818879\n",
      "Iteration 1, loss = 2.05631220\n",
      "\n",
      "Iteration 18, loss = 0.46871112Iteration 20, loss = 0.46253287\n",
      "\n",
      "Iteration 11, loss = 0.47314937\n",
      "Iteration 13, loss = 0.45688557Iteration 39, loss = 0.49352997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done   2 out of   8 | elapsed:   28.4s remaining:  1.4min\n",
      "[Parallel(n_jobs=8)]: Done   8 out of   8 | elapsed:   32.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score sur le train : 0.649753787879\n",
      "\n",
      "Iteration 20, loss = 0.52361860Iteration 9, loss = 0.44780776\n",
      "Iteration 2, loss = 0.48049994\n",
      "\n",
      "Iteration 19, loss = 0.46869123Iteration 21, loss = 0.46181057\n",
      "\n",
      "Iteration 12, loss = 0.47298860\n",
      "Iteration 14, loss = 0.45708644Iteration 40, loss = 0.49290611\n",
      "\n",
      "Iteration 21, loss = 0.52356466Iteration 10, loss = 0.44752698\n",
      "Iteration 3, loss = 0.46878936\n",
      "\n",
      "Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "Iteration 22, loss = 0.46248372\n",
      "\n",
      "Iteration 13, loss = 0.47238169\n",
      "Iteration 15, loss = 0.45734972Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 2.02002492\n",
      "Iteration 22, loss = 0.52311067Iteration 11, loss = 0.44705315\n",
      "Iteration 4, loss = 0.46545160\n",
      "Iteration 1, loss = 2.06533127\n",
      "Iteration 23, loss = 0.46241417\n",
      "\n",
      "Iteration 14, loss = 0.47217343\n",
      "Iteration 16, loss = 0.45652370\n",
      "Iteration 2, loss = 0.45027909\n",
      "Iteration 23, loss = 0.52333401Iteration 12, loss = 0.44699599\n",
      "Iteration 5, loss = 0.46458861\n",
      "Iteration 2, loss = 0.46842796\n",
      "Iteration 24, loss = 0.46193449\n",
      "\n",
      "Iteration 15, loss = 0.47222851\n",
      "Iteration 17, loss = 0.45636307\n",
      "Iteration 3, loss = 0.43754204\n",
      "Iteration 24, loss = 0.52323320Iteration 13, loss = 0.44712154\n",
      "Iteration 6, loss = 0.46438702\n",
      "Iteration 3, loss = 0.45477344\n",
      "Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "\n",
      "\n",
      "Iteration 16, loss = 0.47259927\n",
      "Iteration 18, loss = 0.45664704\n",
      "Iteration 4, loss = 0.43420438Iteration 1, loss = 2.02682845Iteration 25, loss = 0.52291934Iteration 14, loss = 0.44656553\n",
      "Iteration 7, loss = 0.46297271\n",
      "Iteration 4, loss = 0.45107251\n",
      "\n",
      "\n",
      "\n",
      "Iteration 17, loss = 0.47242388\n",
      "Iteration 19, loss = 0.45627365\n",
      "Iteration 5, loss = 0.43295115Iteration 2, loss = 0.46246258Iteration 26, loss = 0.52310641Iteration 15, loss = 0.44737180\n",
      "Iteration 8, loss = 0.46204254\n",
      "Iteration 5, loss = 0.44883808\n",
      "\n",
      "\n",
      "\n",
      "Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "\n",
      "Iteration 20, loss = 0.45648359\n",
      "Iteration 6, loss = 0.43196593Iteration 3, loss = 0.44941519Iteration 27, loss = 0.52332933Iteration 16, loss = 0.44569435Iteration 1, loss = 2.04749015Iteration 9, loss = 0.46210699\n",
      "Iteration 6, loss = 0.44821120\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 21, loss = 0.45628807\n",
      "Iteration 7, loss = 0.43191591Iteration 4, loss = 0.44522775Iteration 28, loss = 0.52291827Iteration 17, loss = 0.44614140Iteration 2, loss = 0.47537782Iteration 10, loss = 0.46144027\n",
      "Iteration 7, loss = 0.44719421\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 22, loss = 0.45616187\n",
      "Iteration 8, loss = 0.43115420Iteration 5, loss = 0.44332721Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "Iteration 18, loss = 0.44595262Iteration 3, loss = 0.46121534Iteration 11, loss = 0.46198843\n",
      "Iteration 8, loss = 0.44651574\n",
      "\n",
      "Iteration 1, loss = 2.03069258\n",
      "\n",
      "\n",
      "Iteration 23, loss = 0.45588664\n",
      "Iteration 9, loss = 0.43076750Iteration 6, loss = 0.44229725\n",
      "Iteration 19, loss = 0.44615354Iteration 4, loss = 0.45864930Iteration 12, loss = 0.46168369\n",
      "Iteration 9, loss = 0.44641124\n",
      "\n",
      "Iteration 2, loss = 0.43118896\n",
      "\n",
      "\n",
      "Iteration 24, loss = 0.45564957\n",
      "Iteration 10, loss = 0.43049163Iteration 7, loss = 0.44160753\n",
      "Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "Iteration 5, loss = 0.45549673Iteration 13, loss = 0.46101876\n",
      "Iteration 10, loss = 0.44578821\n",
      "\n",
      "Iteration 3, loss = 0.41856137Iteration 1, loss = 2.10948628\n",
      "\n",
      "Iteration 25, loss = 0.45587058\n",
      "Iteration 11, loss = 0.43011552Iteration 8, loss = 0.44136519\n",
      "\n",
      "Iteration 6, loss = 0.45467950Iteration 14, loss = 0.46113748\n",
      "Iteration 11, loss = 0.44616591\n",
      "\n",
      "Iteration 4, loss = 0.41441418Iteration 2, loss = 0.51992243\n",
      "\n",
      "Iteration 26, loss = 0.45550335\n",
      "Iteration 12, loss = 0.43034503Iteration 9, loss = 0.44074174\n",
      "\n",
      "Iteration 7, loss = 0.45387024Iteration 15, loss = 0.46094237\n",
      "Iteration 12, loss = 0.44531560\n",
      "\n",
      "Iteration 5, loss = 0.41306210Iteration 3, loss = 0.50495121\n",
      "\n",
      "Iteration 27, loss = 0.45590192\n",
      "Iteration 13, loss = 0.43004076Iteration 10, loss = 0.44082204\n",
      "\n",
      "Iteration 8, loss = 0.45353976Iteration 16, loss = 0.46117634\n",
      "Iteration 13, loss = 0.44497156\n",
      "\n",
      "Iteration 6, loss = 0.41245594Iteration 4, loss = 0.50180795\n",
      "\n",
      "Iteration 28, loss = 0.45593504\n",
      "Iteration 14, loss = 0.42980755Iteration 11, loss = 0.44038838\n",
      "\n",
      "Iteration 9, loss = 0.45315764Iteration 17, loss = 0.46172325\n",
      "Iteration 14, loss = 0.44492162\n",
      "\n",
      "Iteration 7, loss = 0.41195669Iteration 5, loss = 0.50052792\n",
      "\n",
      "Iteration 29, loss = 0.45584729\n",
      "Iteration 15, loss = 0.42931848Iteration 12, loss = 0.43970392\n",
      "\n",
      "Iteration 10, loss = 0.45266446Iteration 18, loss = 0.46093376\n",
      "Iteration 15, loss = 0.44489157\n",
      "\n",
      "Iteration 8, loss = 0.41107463Iteration 6, loss = 0.49977101\n",
      "\n",
      "Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "\n",
      "Iteration 16, loss = 0.42939526Iteration 13, loss = 0.43973452\n",
      "\n",
      "Iteration 11, loss = 0.45273085Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 2.01934057Iteration 16, loss = 0.44505785\n",
      "\n",
      "Iteration 9, loss = 0.41081387Iteration 7, loss = 0.49934646\n",
      "Iteration 1, loss = 2.05049172\n",
      "\n",
      "Iteration 17, loss = 0.42962072Iteration 14, loss = 0.43951106\n",
      "\n",
      "Iteration 12, loss = 0.45278290\n",
      "Iteration 2, loss = 0.46954238Iteration 17, loss = 0.44492671\n",
      "\n",
      "Iteration 10, loss = 0.41004952Iteration 8, loss = 0.49898547\n",
      "Iteration 2, loss = 0.46100959\n",
      "\n",
      "Iteration 18, loss = 0.42974538Iteration 15, loss = 0.44033815\n",
      "\n",
      "Iteration 13, loss = 0.45239319\n",
      "Iteration 3, loss = 0.45598904Iteration 18, loss = 0.44485389\n",
      "\n",
      "Iteration 11, loss = 0.41078847Iteration 9, loss = 0.49885893\n",
      "Iteration 3, loss = 0.44690133\n",
      "\n",
      "Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "Iteration 16, loss = 0.43944574\n",
      "\n",
      "Iteration 14, loss = 0.45224325\n",
      "Iteration 4, loss = 0.45317475Iteration 19, loss = 0.44438874Iteration 1, loss = 2.01364981\n",
      "Iteration 12, loss = 0.41016464Iteration 10, loss = 0.49849535\n",
      "Iteration 4, loss = 0.44301755\n",
      "\n",
      "\n",
      "Iteration 17, loss = 0.43973022\n",
      "\n",
      "Iteration 15, loss = 0.45225972\n",
      "Iteration 5, loss = 0.45075055Iteration 20, loss = 0.44484153Iteration 2, loss = 0.43489068\n",
      "Iteration 13, loss = 0.40997465Iteration 11, loss = 0.49768234\n",
      "Iteration 5, loss = 0.44133569\n",
      "\n",
      "\n",
      "Iteration 18, loss = 0.43892629\n",
      "\n",
      "Iteration 16, loss = 0.45279029\n",
      "Iteration 6, loss = 0.44975854Iteration 21, loss = 0.44458853Iteration 3, loss = 0.42174597\n",
      "Iteration 14, loss = 0.40986923Iteration 12, loss = 0.49776735\n",
      "Iteration 6, loss = 0.44083614\n",
      "\n",
      "\n",
      "Iteration 19, loss = 0.43877079\n",
      "\n",
      "Iteration 17, loss = 0.45203000\n",
      "Iteration 7, loss = 0.44937352Iteration 22, loss = 0.44411079Iteration 4, loss = 0.41828609\n",
      "Iteration 15, loss = 0.40948214Iteration 13, loss = 0.49769896\n",
      "Iteration 7, loss = 0.43917985\n",
      "\n",
      "\n",
      "Iteration 20, loss = 0.43903561\n",
      "\n",
      "Iteration 18, loss = 0.45229470\n",
      "Iteration 8, loss = 0.44902730Iteration 23, loss = 0.44375526Iteration 5, loss = 0.41625135\n",
      "Iteration 16, loss = 0.40954343Iteration 14, loss = 0.49762085\n",
      "Iteration 8, loss = 0.43872912\n",
      "\n",
      "\n",
      "Iteration 21, loss = 0.43898062\n",
      "\n",
      "Iteration 19, loss = 0.45215970\n",
      "Iteration 9, loss = 0.44795362Iteration 24, loss = 0.44398118Iteration 6, loss = 0.41564280\n",
      "Iteration 17, loss = 0.40899163Iteration 15, loss = 0.49704959\n",
      "Iteration 9, loss = 0.43851975\n",
      "\n",
      "\n",
      "Iteration 22, loss = 0.43897270\n",
      "\n",
      "Iteration 20, loss = 0.45195372\n",
      "Iteration 10, loss = 0.44801858Iteration 25, loss = 0.44421849Iteration 7, loss = 0.41469356\n",
      "Iteration 18, loss = 0.40960612Iteration 16, loss = 0.49728241\n",
      "Iteration 10, loss = 0.43840469\n",
      "\n",
      "\n",
      "Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "\n",
      "\n",
      "Iteration 21, loss = 0.45186499\n",
      "Iteration 11, loss = 0.44777703Iteration 26, loss = 0.44325532Iteration 8, loss = 0.41456321Iteration 1, loss = 2.06411401Iteration 19, loss = 0.40931203Iteration 17, loss = 0.49733251\n",
      "Iteration 11, loss = 0.43822799\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 22, loss = 0.45097102\n",
      "Iteration 12, loss = 0.44756928Iteration 27, loss = 0.44356283Iteration 9, loss = 0.41438680Iteration 2, loss = 0.51135747Iteration 20, loss = 0.40901265Iteration 18, loss = 0.49683163\n",
      "Iteration 12, loss = 0.43829311\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 23, loss = 0.45164837\n",
      "Iteration 13, loss = 0.44665317Iteration 28, loss = 0.44373309Iteration 10, loss = 0.41378574Iteration 3, loss = 0.49724331Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "Iteration 19, loss = 0.49652062\n",
      "Iteration 13, loss = 0.43799122\n",
      "\n",
      "\n",
      "\n",
      "Iteration 1, loss = 2.01888191\n",
      "Iteration 24, loss = 0.45170290\n",
      "Iteration 14, loss = 0.44667821Iteration 29, loss = 0.44395078Iteration 11, loss = 0.41321090Iteration 4, loss = 0.49335602\n",
      "Iteration 20, loss = 0.49648018\n",
      "Iteration 14, loss = 0.43818756\n",
      "\n",
      "\n",
      "\n",
      "Iteration 2, loss = 0.45792698\n",
      "Iteration 25, loss = 0.45165715\n",
      "Iteration 15, loss = 0.44753876Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "Iteration 12, loss = 0.41435785Iteration 5, loss = 0.49143506\n",
      "Iteration 21, loss = 0.49673834\n",
      "Iteration 15, loss = 0.43763837\n",
      "Iteration 1, loss = 2.04047672\n"
     ]
    }
   ],
   "source": [
    "# Prediction\n",
    "y_pred_train =  bagging.predict(X_train)\n",
    "y_predict_train_proba = bagging.predict_proba(X_train)[:,0]\n",
    "        \n",
    "for i in range(len(y_pred_train)):\n",
    "    if (y_predict_train_proba[i]<0.9)and(y_predict_train_proba[i]>1-0.9):\n",
    "        y_pred_train[i]=0\n",
    "\n",
    "# score\n",
    "score = compute_pred_score(y_train, y_pred_train)\n",
    "print('Score sur le train : %s' % score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Génération de la prédiction sur le test et enregistrement du fichier à soumettre sur le site:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done   2 out of   8 | elapsed:    2.4s remaining:    7.3s\n",
      "[Parallel(n_jobs=8)]: Done   8 out of   8 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=8)]: Done   2 out of   8 | elapsed:    2.4s remaining:    7.2s\n",
      "[Parallel(n_jobs=8)]: Done   8 out of   8 | elapsed:    3.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1  0  1]\n"
     ]
    }
   ],
   "source": [
    "y_pred = bagging.predict(X_test)\n",
    "y_predict_proba = bagging.predict_proba(X_test)[:,0]\n",
    "\n",
    "for i in range(len(y_pred)):\n",
    "    if (y_predict_proba[i]<0.9)and(y_predict_proba[i]>1-0.9):\n",
    "        y_pred[i]=0\n",
    "print np.unique(y_pred)\n",
    "\n",
    "np.savetxt('y_pred.txt', y_pred, fmt='%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 0.164312617702"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
