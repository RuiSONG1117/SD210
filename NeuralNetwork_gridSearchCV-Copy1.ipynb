{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prédiction du genre d'une personne à partir de sa photo\n",
    "\n",
    "auteur : Umut Şimşekli & Alexandre Gramfort, challenge SD210 2017\n",
    "\n",
    "L'objectif est de prédire le genre d'une personne (homme ou femme) à partir de caractéristiques extraites d'une photo.\n",
    "\n",
    "Les données sont fournies par la société Morpho: http://www.morpho.com/fr\n",
    "\n",
    "Le fichier que doit fournir chacun est un fichier au format .txt de 8496 lignes::\n",
    "\n",
    "    1\n",
    "    0\n",
    "    -1\n",
    "    1\n",
    "    ...\n",
    "\n",
    "où chaque ligne contient la prédiction. Contrairement à un problème de classification binaire où y=1 ou y=-1, vous avez la possibilité de prédire 0, ce qui signifie que vous ne savez pas. Il y a 8496 images dans l'ensemble de validation.\n",
    "\n",
    "\n",
    "### Critère de performance \n",
    "\n",
    "Vous pouvez donc répondre pour chaque image : homme (y=1), femme (y=-1) ou je-ne-sais-pas (y=0).\n",
    "\n",
    "Se tromper coûte 10 points et ne pas savoir coûte 1 point. Mathématiquement, le score est calculé de la façon suivante:\n",
    " \n",
    "$score = \\frac1{N} \\sum_{i=1}^N \\Bigl(\\mathbb{1}(\\hat{y}_i = 0) + 10 \\times \\mathbb{1}(y_i \\hat{y}_i = -1)   \\Bigr) $ \n",
    "\n",
    "où $\\mathbb{1}(\\cdot)$ est la fonction indicatrice; $\\mathbb{1}(x) = 1$ si $x$ est vrai, et $\\mathbb{1}(x) = 0$, sinon.\n",
    "\n",
    "Plus ce nombre est petit mieux c'est.\n",
    "\n",
    "\n",
    "# Données d'apprentissage: \n",
    "\n",
    "https://www.dropbox.com/s/dqudxed82ljnxa8/training_templates.csv\n",
    "\n",
    "https://www.dropbox.com/s/l0f9z08rysp0kjy/training_labels.txt\n",
    "\n",
    "\n",
    "# Données de validation:\n",
    "\n",
    "https://www.dropbox.com/s/syrry7miykrmjz0/testing_templates.csv\n",
    "\n",
    "Voyons cela par l'exemple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Critere de performance\n",
    "def compute_pred_score(y_true, y_pred):\n",
    "    y_pred_unq =  np.unique(y_pred)\n",
    "    for i in y_pred_unq:\n",
    "        if((i != -1) & (i!= 1) & (i!= 0) ):\n",
    "            raise ValueError('The predictions can contain only -1, 1, or 0!')\n",
    "    y_comp = y_true * y_pred\n",
    "    score = float(10*np.sum(y_comp == -1) + np.sum(y_comp == 0))\n",
    "    score /= y_comp.shape[0]\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_fname = 'training_templates.csv'\n",
    "y_train_fname = 'training_labels.txt'\n",
    "X_test_fname  = 'testing_templates.csv'\n",
    "X_train = pd.read_csv(X_train_fname, sep=',', header=None).values\n",
    "X_test  = pd.read_csv(X_test_fname,  sep=',', header=None).values\n",
    "y_train = np.loadtxt(y_train_fname, dtype=np.int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((105600, 128), (8496, 128), (105600,))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_samples : 105600, n_features : 128\n"
     ]
    }
   ],
   "source": [
    "print('n_samples : %d, n_features : %d' % X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, array([-1,  1]))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(y_train), np.unique(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "X_scaler = StandardScaler()\n",
    "X_train = X_scaler.fit_transform(X_train)\n",
    "X_test = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exemple de classification\n",
    "\n",
    "Voyons maintenant un exemple de classification et de production d'un fichier de soumission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.19972545\n",
      "Iteration 2, loss = 0.35820512Iteration 1, loss = 1.40794261\n",
      "Iteration 1, loss = 1.40433834\n",
      "Iteration 1, loss = 1.40471707\n",
      "Iteration 1, loss = 1.40464563\n",
      "Iteration 1, loss = 1.38363829\n",
      "Iteration 1, loss = 2.61426024\n",
      "Iteration 1, loss = 2.60953430\n",
      "Iteration 1, loss = 2.61009109\n",
      "Iteration 2, loss = 0.36557323Iteration 2, loss = 0.36357232Iteration 2, loss = 0.36361594Iteration 2, loss = 0.36109785Iteration 2, loss = 0.33801040Iteration 2, loss = 0.55299947Iteration 2, loss = 0.54882743Iteration 2, loss = 0.54990742\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 3, loss = 0.36000786Iteration 3, loss = 0.35798666Iteration 3, loss = 0.35794657Iteration 3, loss = 0.35534031Iteration 3, loss = 0.33275098Iteration 3, loss = 0.54934833Iteration 3, loss = 0.54511421Iteration 3, loss = 0.54621446\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 4, loss = 0.35917776Iteration 4, loss = 0.35698929Iteration 4, loss = 0.35703545Iteration 4, loss = 0.35431865Iteration 4, loss = 0.33093960Iteration 4, loss = 0.54920169Iteration 4, loss = 0.54478312Iteration 4, loss = 0.54550881\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 5, loss = 0.35781669Iteration 5, loss = 0.35524123Iteration 5, loss = 0.35569705Iteration 5, loss = 0.35309475Iteration 5, loss = 0.32973545Iteration 5, loss = 0.54817360Iteration 5, loss = 0.54364141Iteration 5, loss = 0.54457233\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 6, loss = 0.35703605Iteration 6, loss = 0.35480778Iteration 6, loss = 0.35485782Iteration 6, loss = 0.35230116Iteration 6, loss = 0.32921555Iteration 6, loss = 0.54770653Iteration 6, loss = 0.54350261Iteration 6, loss = 0.54420481\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 7, loss = 0.35650632Iteration 7, loss = 0.35356873Iteration 7, loss = 0.35420444Iteration 7, loss = 0.35180912Iteration 7, loss = 0.32880961Iteration 7, loss = 0.54752712Iteration 7, loss = 0.54295204Iteration 7, loss = 0.54369501\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 8, loss = 0.35627168Iteration 8, loss = 0.35373563Iteration 8, loss = 0.35456920Iteration 8, loss = 0.35155666Iteration 8, loss = 0.32876368Iteration 8, loss = 0.54734222Iteration 8, loss = 0.54273042Iteration 8, loss = 0.54417292\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 9, loss = 0.35623720Iteration 9, loss = 0.35379603Iteration 9, loss = 0.35415166Iteration 9, loss = 0.35173460Iteration 9, loss = 0.32843561Iteration 9, loss = 0.54710444Iteration 9, loss = 0.54280054Iteration 9, loss = 0.54333704\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 10, loss = 0.35573053Iteration 10, loss = 0.35303232Iteration 10, loss = 0.35378345Iteration 10, loss = 0.35103790Iteration 10, loss = 0.32789089Iteration 10, loss = 0.54688378Iteration 10, loss = 0.54210048Iteration 10, loss = 0.54306790\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 11, loss = 0.35560848Iteration 11, loss = 0.35297919Iteration 11, loss = 0.35358765Iteration 11, loss = 0.35108082Iteration 11, loss = 0.32812945Iteration 11, loss = 0.54677042Iteration 11, loss = 0.54238700Iteration 11, loss = 0.54294059\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 12, loss = 0.35556007Iteration 12, loss = 0.35296169Iteration 12, loss = 0.35341215Iteration 12, loss = 0.35094210Iteration 12, loss = 0.32804467Iteration 12, loss = 0.54654127Iteration 12, loss = 0.54220192Iteration 12, loss = 0.54282498\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 13, loss = 0.35534794Iteration 13, loss = 0.35264406Iteration 13, loss = 0.35342014Iteration 13, loss = 0.35047506Iteration 13, loss = 0.32764518Iteration 13, loss = 0.54635305Iteration 13, loss = 0.54212153Iteration 13, loss = 0.54305041\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 14, loss = 0.35543845Iteration 14, loss = 0.35280880Iteration 14, loss = 0.35359178Iteration 14, loss = 0.35071172Iteration 14, loss = 0.32746043Iteration 14, loss = 0.54662446Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 14, loss = 0.54300053\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 1, loss = 2.62755226\n",
      "Iteration 15, loss = 0.35517915Iteration 15, loss = 0.35214388Iteration 15, loss = 0.35284422Iteration 15, loss = 0.35020787Iteration 15, loss = 0.32742447Iteration 15, loss = 0.54602937\n",
      "Iteration 15, loss = 0.54227532\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 2, loss = 0.54909889\n",
      "Iteration 16, loss = 0.35507635Iteration 16, loss = 0.35231440Iteration 16, loss = 0.35312130Iteration 16, loss = 0.35027197Iteration 16, loss = 0.32738490Iteration 16, loss = 0.54577795\n",
      "Iteration 16, loss = 0.54238346\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 3, loss = 0.54598942\n",
      "Iteration 17, loss = 0.35536605Iteration 17, loss = 0.35253803Iteration 17, loss = 0.35263516Iteration 17, loss = 0.34995371Iteration 17, loss = 0.32703840Iteration 17, loss = 0.54647230\n",
      "Iteration 17, loss = 0.54229435\n",
      "Iteration 3, loss = 0.35322897\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 4, loss = 0.54460024\n",
      "Iteration 18, loss = 0.35502043Iteration 18, loss = 0.35209397Iteration 18, loss = 0.35266311Iteration 18, loss = 0.34975186Iteration 18, loss = 0.32719395Iteration 18, loss = 0.54590329\n",
      "Iteration 18, loss = 0.54223086\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 5, loss = 0.54392923\n",
      "Iteration 19, loss = 0.35497579Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 19, loss = 0.35289698Iteration 19, loss = 0.35021960Iteration 19, loss = 0.32713536Iteration 19, loss = 0.54589625\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "\n",
      "Iteration 1, loss = 5.00858010\n",
      "\n",
      "\n",
      "\n",
      "Iteration 6, loss = 0.54409547Iteration 1, loss = 2.59597507Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "\n",
      "Iteration 20, loss = 0.35290676Iteration 20, loss = 0.35014093Iteration 20, loss = 0.32692570Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "\n",
      "\n",
      "Iteration 1, loss = 4.95892611Iteration 2, loss = 0.69345443\n",
      "\n",
      "\n",
      "Iteration 1, loss = 4.95908283Iteration 7, loss = 0.54354835Iteration 2, loss = 0.52736748\n",
      "\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 21, loss = 0.34995603Iteration 21, loss = 0.32714333\n",
      "\n",
      "\n",
      "Iteration 2, loss = 0.69330667Iteration 3, loss = 0.69327712Iteration 1, loss = 4.95491482\n",
      "\n",
      "Iteration 2, loss = 0.69331007Iteration 8, loss = 0.54312925Iteration 3, loss = 0.52378444\n",
      "\n",
      "\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 22, loss = 0.32699891\n",
      "\n",
      "\n",
      "Iteration 3, loss = 0.69320077Iteration 4, loss = 0.69322251Iteration 2, loss = 0.69323352Iteration 1, loss = 4.98284421\n",
      "Iteration 3, loss = 0.69320118Iteration 9, loss = 0.54280951Iteration 4, loss = 0.52224339\n",
      "\n",
      "\n",
      "\n",
      "Iteration 23, loss = 0.32656684\n",
      "\n",
      "\n",
      "Iteration 4, loss = 0.69322982Iteration 5, loss = 0.69318881Iteration 3, loss = 0.69318390Iteration 2, loss = 0.69325250\n",
      "Iteration 4, loss = 0.69323018Iteration 10, loss = 0.54253025Iteration 5, loss = 0.52174168\n",
      "\n",
      "\n",
      "\n",
      "Iteration 24, loss = 0.32664034\n",
      "\n",
      "\n",
      "Iteration 5, loss = 0.69320005Iteration 6, loss = 0.69320382Iteration 4, loss = 0.69316853Iteration 3, loss = 0.69319633\n",
      "Iteration 5, loss = 0.69320015Iteration 11, loss = 0.54305152Iteration 6, loss = 0.52243394\n",
      "\n",
      "\n",
      "\n",
      "Iteration 25, loss = 0.32646067\n",
      "\n",
      "\n",
      "Iteration 6, loss = 0.69319116Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 5, loss = 0.69318828Iteration 4, loss = 0.69317750\n",
      "Iteration 6, loss = 0.69319121Iteration 12, loss = 0.54211487Iteration 7, loss = 0.52144220\n",
      "Iteration 1, loss = 9.95906248\n",
      "\n",
      "Iteration 26, loss = 0.32632255\n",
      "\n",
      "\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 5, loss = 0.69318462\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 13, loss = 0.54252614Iteration 8, loss = 0.52102915Iteration 1, loss = 9.92248352Iteration 2, loss = 0.69321661Iteration 1, loss = 9.91924948\n",
      "Iteration 27, loss = 0.32688611Iteration 1, loss = 9.92262144\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "\n",
      "\n",
      "Iteration 14, loss = 0.54255300Iteration 9, loss = 0.52119144Iteration 2, loss = 0.69329119Iteration 3, loss = 0.69316461Iteration 2, loss = 0.69328141Iteration 1, loss = 9.91317579Iteration 28, loss = 0.32639727Iteration 2, loss = 0.69329244\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 15, loss = 0.54194488Iteration 10, loss = 0.52140928Iteration 3, loss = 0.69322112Iteration 4, loss = 0.69317411Iteration 3, loss = 0.69318163Iteration 2, loss = 0.69325588Iteration 29, loss = 0.32628628Iteration 3, loss = 0.69322094\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 16, loss = 0.54209383Iteration 11, loss = 0.52081926Iteration 4, loss = 0.69318538Iteration 5, loss = 0.69318114Iteration 4, loss = 0.69318142Iteration 3, loss = 0.69317223Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 4, loss = 0.69318522\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 1, loss = 20.50182882\n",
      "Iteration 17, loss = 0.54168880Iteration 12, loss = 0.52090588Iteration 5, loss = 0.69318326Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 5, loss = 0.69318352Iteration 4, loss = 0.69317679\n",
      "Iteration 5, loss = 0.69318307\n",
      "\n",
      "\n",
      "Iteration 1, loss = 20.83314310\n",
      "\n",
      "Iteration 2, loss = 0.69341431\n",
      "Iteration 18, loss = 0.54176857Iteration 13, loss = 0.52078129Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 5, loss = 0.69317439\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "\n",
      "\n",
      "Iteration 1, loss = 20.56326843Iteration 2, loss = 0.69334409Iteration 1, loss = 43.50365245\n",
      "Iteration 3, loss = 0.69317505Iteration 1, loss = 20.56395261Iteration 19, loss = 0.54178721Iteration 14, loss = 0.52042191\n",
      "\n",
      "\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 4, loss = 0.35232057Iteration 2, loss = 0.69328072Iteration 3, loss = 0.69318070Iteration 2, loss = 0.69335042Iteration 1, loss = 20.36517572Iteration 4, loss = 0.69314850Iteration 2, loss = 0.69328019Iteration 20, loss = 0.54110781Iteration 15, loss = 0.52031950\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 3, loss = 0.69317132Iteration 4, loss = 0.69317754Iteration 3, loss = 0.69316711Iteration 2, loss = 0.69329556Iteration 5, loss = 0.69318771Iteration 3, loss = 0.69317130Iteration 21, loss = 0.54210672Iteration 16, loss = 0.52035733\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 4, loss = 0.69316704Iteration 5, loss = 0.69317761Iteration 4, loss = 0.69317066Iteration 3, loss = 0.69317153Iteration 6, loss = 0.69316371Iteration 4, loss = 0.69316690Iteration 22, loss = 0.54175992Iteration 17, loss = 0.52016803\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 5, loss = 0.69319068Iteration 6, loss = 0.69317412Iteration 5, loss = 0.69317028Iteration 4, loss = 0.69317733Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 5, loss = 0.69319057Iteration 23, loss = 0.54181695Iteration 18, loss = 0.52023028\n",
      "\n",
      "\n",
      "\n",
      "Iteration 1, loss = 43.22316018\n",
      "\n",
      "\n",
      "Iteration 6, loss = 0.69318038Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 6, loss = 0.69317779Iteration 5, loss = 0.69316752\n",
      "Iteration 6, loss = 0.69318069Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 19, loss = 0.52002019\n",
      "Iteration 1, loss = 42.99841129\n",
      "\n",
      "Iteration 2, loss = 0.69335912\n",
      "Iteration 1, loss = 43.14190785\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 6, loss = 0.69317587\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "\n",
      "Iteration 20, loss = 0.52013351Iteration 1, loss = 43.46215927Iteration 2, loss = 0.69336971Iteration 1, loss = 94.16523952\n",
      "Iteration 3, loss = 0.69316763Iteration 1, loss = 92.83074528Iteration 2, loss = 0.69345590\n",
      "\n",
      "\n",
      "\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "\n",
      "\n",
      "\n",
      "Iteration 21, loss = 0.52013453Iteration 2, loss = 0.69341099Iteration 3, loss = 0.69316487Iteration 2, loss = 0.69380893Iteration 1, loss = 92.44273281Iteration 4, loss = 0.69316100Iteration 2, loss = 0.69364927Iteration 3, loss = 0.69317681\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 22, loss = 0.51974289Iteration 3, loss = 0.69316900Iteration 4, loss = 0.69317916Iteration 3, loss = 0.69318371Iteration 2, loss = 0.69367956Iteration 5, loss = 0.69317707Iteration 3, loss = 0.69316593Iteration 4, loss = 0.69316837\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 23, loss = 0.51978660Iteration 4, loss = 0.69317036Iteration 5, loss = 0.69316088Iteration 4, loss = 0.69316948Iteration 3, loss = 0.69316414Iteration 6, loss = 0.69316987Iteration 4, loss = 0.69316452Iteration 5, loss = 0.69316665\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 24, loss = 0.51970398Iteration 5, loss = 0.69317938Iteration 6, loss = 0.69317499Iteration 5, loss = 0.69316765Iteration 4, loss = 0.69316121Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 5, loss = 0.69316859Iteration 6, loss = 0.69318232\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 1, loss = 93.17572036\n",
      "\n",
      "Iteration 25, loss = 0.52023693Iteration 6, loss = 0.69318080Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 6, loss = 0.69317488Iteration 5, loss = 0.69316278\n",
      "Iteration 6, loss = 0.69317346Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 2, loss = 0.69354151\n",
      "Iteration 1, loss = 92.22943708Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 6, loss = 0.69316359\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "\n",
      "Iteration 2, loss = 0.69355343\n",
      "Iteration 3, loss = 0.69316690\n",
      "\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 4, loss = 0.69316715Iteration 3, loss = 0.69315815\n",
      "\n",
      "Iteration 5, loss = 0.69317391Iteration 4, loss = 0.69315775\n",
      "\n",
      "Iteration 6, loss = 0.69316934Iteration 5, loss = 0.69316124\n",
      "\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 6, loss = 0.69316435\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "\n",
      "Iteration 5, loss = 0.35143558\n",
      "Iteration 6, loss = 0.35070947\n",
      "Iteration 7, loss = 0.35076337\n",
      "Iteration 8, loss = 0.34972691\n",
      "Iteration 9, loss = 0.35001690\n",
      "Iteration 10, loss = 0.34932532\n",
      "Iteration 11, loss = 0.34955921\n",
      "Iteration 12, loss = 0.34914655\n",
      "Iteration 13, loss = 0.34912805\n",
      "Iteration 14, loss = 0.34922294\n",
      "Iteration 15, loss = 0.34915936\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=10.0, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100, 100, 100), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=True, warm_start=False)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_scaler = StandardScaler()\n",
    "X_train = X_scaler.fit_transform(X_train)\n",
    "X_test = X_scaler.transform(X_test)\n",
    "\n",
    "np.random.seed(45)\n",
    "param_grid = {#\"hidden_layer_sizes\":[(128,256),(128,64)],\n",
    "    \"alpha\":np.logspace(1, 3, 7),\n",
    "    #\"learning_rate_init\":np.logspace(-4,-1,3),\n",
    "    #\"momentum\": [0.6, 0.7, 0.8, 0.9]\n",
    "}\n",
    "\n",
    "clf = MLPClassifier(hidden_layer_sizes=(100,100,100), verbose=True)\n",
    "gs = GridSearchCV(clf, param_grid, cv=5, n_jobs=-1)\n",
    "gs.fit(X_train, y_train)\n",
    "\n",
    "gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score sur le train : 0.322774621212\n"
     ]
    }
   ],
   "source": [
    "# Prediction\n",
    "y_pred_train =  gs.best_estimator_.predict(X_train)\n",
    "y_predict_train_proba = gs.best_estimator_.predict_proba(X_train)[:,0]\n",
    "        \n",
    "for i in range(len(y_pred_train)):\n",
    "    if (y_predict_train_proba[i]<0.9)and(y_predict_train_proba[i]>1-0.9):\n",
    "        y_pred_train[i]=0\n",
    "\n",
    "# score\n",
    "score = compute_pred_score(y_train, y_pred_train)\n",
    "print('Score sur le train : %s' % score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Génération de la prédiction sur le test et enregistrement du fichier à soumettre sur le site:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1  0  1]\n"
     ]
    }
   ],
   "source": [
    "y_pred = gs.best_estimator_.predict(X_test)\n",
    "y_predict_proba = gs.best_estimator_.predict_proba(X_test)[:,0]\n",
    "\n",
    "for i in range(len(y_pred)):\n",
    "    if (y_predict_proba[i]<0.75)and(y_predict_proba[i]>1-0.75):\n",
    "        y_pred[i]=0\n",
    "print np.unique(y_pred)\n",
    "\n",
    "np.savetxt('y_pred_MLP1.txt', y_pred, fmt='%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous pouvez maintenant uploader votre fichier `y_pred.txt` sur le site.\n",
    "\n",
    "Bonne chance !"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
