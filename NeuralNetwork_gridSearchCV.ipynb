{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prédiction du genre d'une personne à partir de sa photo\n",
    "\n",
    "auteur : Umut Şimşekli & Alexandre Gramfort, challenge SD210 2017\n",
    "\n",
    "L'objectif est de prédire le genre d'une personne (homme ou femme) à partir de caractéristiques extraites d'une photo.\n",
    "\n",
    "Les données sont fournies par la société Morpho: http://www.morpho.com/fr\n",
    "\n",
    "Le fichier que doit fournir chacun est un fichier au format .txt de 8496 lignes::\n",
    "\n",
    "    1\n",
    "    0\n",
    "    -1\n",
    "    1\n",
    "    ...\n",
    "\n",
    "où chaque ligne contient la prédiction. Contrairement à un problème de classification binaire où y=1 ou y=-1, vous avez la possibilité de prédire 0, ce qui signifie que vous ne savez pas. Il y a 8496 images dans l'ensemble de validation.\n",
    "\n",
    "\n",
    "### Critère de performance \n",
    "\n",
    "Vous pouvez donc répondre pour chaque image : homme (y=1), femme (y=-1) ou je-ne-sais-pas (y=0).\n",
    "\n",
    "Se tromper coûte 10 points et ne pas savoir coûte 1 point. Mathématiquement, le score est calculé de la façon suivante:\n",
    " \n",
    "$score = \\frac1{N} \\sum_{i=1}^N \\Bigl(\\mathbb{1}(\\hat{y}_i = 0) + 10 \\times \\mathbb{1}(y_i \\hat{y}_i = -1)   \\Bigr) $ \n",
    "\n",
    "où $\\mathbb{1}(\\cdot)$ est la fonction indicatrice; $\\mathbb{1}(x) = 1$ si $x$ est vrai, et $\\mathbb{1}(x) = 0$, sinon.\n",
    "\n",
    "Plus ce nombre est petit mieux c'est.\n",
    "\n",
    "\n",
    "# Données d'apprentissage: \n",
    "\n",
    "https://www.dropbox.com/s/dqudxed82ljnxa8/training_templates.csv\n",
    "\n",
    "https://www.dropbox.com/s/l0f9z08rysp0kjy/training_labels.txt\n",
    "\n",
    "\n",
    "# Données de validation:\n",
    "\n",
    "https://www.dropbox.com/s/syrry7miykrmjz0/testing_templates.csv\n",
    "\n",
    "Voyons cela par l'exemple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Critere de performance\n",
    "def compute_pred_score(y_true, y_pred):\n",
    "    y_pred_unq =  np.unique(y_pred)\n",
    "    for i in y_pred_unq:\n",
    "        if((i != -1) & (i!= 1) & (i!= 0) ):\n",
    "            raise ValueError('The predictions can contain only -1, 1, or 0!')\n",
    "    y_comp = y_true * y_pred\n",
    "    score = float(10*np.sum(y_comp == -1) + np.sum(y_comp == 0))\n",
    "    score /= y_comp.shape[0]\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_fname = 'training_templates.csv'\n",
    "y_train_fname = 'training_labels.txt'\n",
    "X_test_fname  = 'testing_templates.csv'\n",
    "X_train = pd.read_csv(X_train_fname, sep=',', header=None).values\n",
    "X_test  = pd.read_csv(X_test_fname,  sep=',', header=None).values\n",
    "y_train = np.loadtxt(y_train_fname, dtype=np.int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((105600, 128), (8496, 128), (105600,))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_samples : 105600, n_features : 128\n"
     ]
    }
   ],
   "source": [
    "print('n_samples : %d, n_features : %d' % X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, array([-1,  1]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(y_train), np.unique(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from sklearn.preprocessing import StandardScaler\n",
    "#X_scaler = StandardScaler()\n",
    "#X_train = X_scaler.fit_transform(X_train)\n",
    "#X_test = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exemple de classification\n",
    "\n",
    "Voyons maintenant un exemple de classification et de production d'un fichier de soumission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.14042248\n",
      "Iteration 2, loss = 0.07742510Iteration 1, loss = 0.15153433\n",
      "Iteration 1, loss = 0.14827177\n",
      "Iteration 1, loss = 0.15115151\n",
      "Iteration 1, loss = 0.15092905\n",
      "Iteration 1, loss = 0.12866818\n",
      "Iteration 1, loss = 0.12241432\n",
      "Iteration 1, loss = 0.12191524\n",
      "Iteration 1, loss = 0.12288954\n",
      "Iteration 2, loss = 0.07529893Iteration 2, loss = 0.07243325Iteration 2, loss = 0.07422173Iteration 2, loss = 0.07380420Iteration 2, loss = 0.05828834Iteration 2, loss = 0.07056211Iteration 2, loss = 0.06975872Iteration 2, loss = 0.07109837\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 3, loss = 0.06461544Iteration 3, loss = 0.06193628Iteration 3, loss = 0.06386670Iteration 3, loss = 0.06339668Iteration 3, loss = 0.05066603Iteration 3, loss = 0.06253909Iteration 3, loss = 0.06197439Iteration 3, loss = 0.06300814\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 4, loss = 0.05810027Iteration 4, loss = 0.05551380Iteration 4, loss = 0.05784516Iteration 4, loss = 0.05690456Iteration 4, loss = 0.04525726Iteration 4, loss = 0.05757265Iteration 4, loss = 0.05656961Iteration 4, loss = 0.05749604\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 5, loss = 0.05366497Iteration 5, loss = 0.05117038Iteration 5, loss = 0.05322468Iteration 5, loss = 0.05260957Iteration 5, loss = 0.04217047Iteration 5, loss = 0.05382712Iteration 5, loss = 0.05303358Iteration 5, loss = 0.05408139\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 6, loss = 0.05040955Iteration 6, loss = 0.04818740Iteration 6, loss = 0.04980839Iteration 6, loss = 0.04963507Iteration 6, loss = 0.03930566Iteration 6, loss = 0.05034892Iteration 6, loss = 0.05018098Iteration 6, loss = 0.05130432\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 7, loss = 0.04780638Iteration 7, loss = 0.04552900Iteration 7, loss = 0.04717266Iteration 7, loss = 0.04672920Iteration 7, loss = 0.03740721Iteration 7, loss = 0.04873919Iteration 7, loss = 0.04813946Iteration 7, loss = 0.04924340\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 8, loss = 0.04533792Iteration 8, loss = 0.04339925Iteration 8, loss = 0.04500459Iteration 8, loss = 0.04458409Iteration 8, loss = 0.03560710Iteration 8, loss = 0.04651684Iteration 8, loss = 0.04607359Iteration 8, loss = 0.04685704\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 9, loss = 0.04316633Iteration 9, loss = 0.04121801Iteration 9, loss = 0.04314451Iteration 9, loss = 0.04257963Iteration 9, loss = 0.03395393Iteration 9, loss = 0.04499961Iteration 9, loss = 0.04431337Iteration 9, loss = 0.04488332\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 10, loss = 0.04180982Iteration 10, loss = 0.03981346Iteration 10, loss = 0.04150737Iteration 10, loss = 0.04083620Iteration 10, loss = 0.03274943Iteration 10, loss = 0.04340424Iteration 10, loss = 0.04296926Iteration 10, loss = 0.04395846\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 11, loss = 0.04016700Iteration 11, loss = 0.03855360Iteration 11, loss = 0.04017772Iteration 11, loss = 0.03953633Iteration 11, loss = 0.03199721Iteration 11, loss = 0.04255680Iteration 11, loss = 0.04209624Iteration 11, loss = 0.04268455\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 12, loss = 0.03902996Iteration 12, loss = 0.03716397Iteration 12, loss = 0.03867907Iteration 12, loss = 0.03841608Iteration 12, loss = 0.03109295Iteration 12, loss = 0.04122384Iteration 12, loss = 0.04097508Iteration 12, loss = 0.04207906\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 13, loss = 0.03777315Iteration 13, loss = 0.03607299Iteration 13, loss = 0.03781029Iteration 13, loss = 0.03706725Iteration 13, loss = 0.03015074Iteration 13, loss = 0.04042908Iteration 13, loss = 0.03950364Iteration 13, loss = 0.04054366\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 14, loss = 0.03745425Iteration 14, loss = 0.03545398Iteration 14, loss = 0.03743924Iteration 14, loss = 0.03717295Iteration 14, loss = 0.02977496Iteration 14, loss = 0.04048209Iteration 14, loss = 0.04035901Iteration 14, loss = 0.04073399\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 15, loss = 0.03601513Iteration 15, loss = 0.03488653Iteration 15, loss = 0.03582407Iteration 15, loss = 0.03564315Iteration 15, loss = 0.02896973Iteration 15, loss = 0.03865789Iteration 15, loss = 0.03871228Iteration 15, loss = 0.03893846\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 16, loss = 0.03540886Iteration 16, loss = 0.03398605Iteration 16, loss = 0.03549567Iteration 16, loss = 0.03490622Iteration 16, loss = 0.02862254Iteration 16, loss = 0.03844032Iteration 16, loss = 0.03806420Iteration 16, loss = 0.03842481\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 17, loss = 0.03514492Iteration 17, loss = 0.03314895Iteration 17, loss = 0.03502300Iteration 17, loss = 0.03458492Iteration 17, loss = 0.02781572Iteration 17, loss = 0.03817591Iteration 17, loss = 0.03793549Iteration 17, loss = 0.03861128\n",
      "Iteration 3, loss = 0.06877014\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 18, loss = 0.03449581Iteration 18, loss = 0.03330854Iteration 18, loss = 0.03430862Iteration 18, loss = 0.03417626Iteration 18, loss = 0.02815731Iteration 18, loss = 0.03714704Iteration 18, loss = 0.03757725Iteration 18, loss = 0.03809624\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 19, loss = 0.03440098Iteration 19, loss = 0.03315472Iteration 19, loss = 0.03422996Iteration 19, loss = 0.03400953Iteration 19, loss = 0.02773691Iteration 19, loss = 0.03744052Iteration 19, loss = 0.03756895Iteration 19, loss = 0.03793233\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 20, loss = 0.03402493Iteration 20, loss = 0.03244916Iteration 20, loss = 0.03362716Iteration 20, loss = 0.03311160Iteration 20, loss = 0.02753641Iteration 20, loss = 0.03683481Iteration 20, loss = 0.03605994Iteration 20, loss = 0.03716119\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 21, loss = 0.03384927Iteration 21, loss = 0.03272327Iteration 21, loss = 0.03372220Iteration 21, loss = 0.03320637Iteration 21, loss = 0.02710092Iteration 21, loss = 0.03675099Iteration 21, loss = 0.03646088Iteration 21, loss = 0.03719726\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 22, loss = 0.03350640Iteration 22, loss = 0.03214000Iteration 22, loss = 0.03343062Iteration 22, loss = 0.03306767Iteration 22, loss = 0.02720629Iteration 22, loss = 0.03681359Iteration 22, loss = 0.03640806Iteration 22, loss = 0.03693503\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 23, loss = 0.03336166Iteration 23, loss = 0.03195236Iteration 23, loss = 0.03314136Iteration 23, loss = 0.03301501Iteration 23, loss = 0.02694560Iteration 23, loss = 0.03623644Iteration 23, loss = 0.03626191Iteration 23, loss = 0.03656437\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 24, loss = 0.03334062Iteration 24, loss = 0.03202829Iteration 24, loss = 0.03297012Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 24, loss = 0.02689486Iteration 24, loss = 0.03610292Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 24, loss = 0.03677727\n",
      "\n",
      "\n",
      "Iteration 1, loss = 0.10125297\n",
      "\n",
      "Iteration 1, loss = 0.11905281\n",
      "Iteration 25, loss = 0.03274874Iteration 25, loss = 0.03155764Iteration 25, loss = 0.03269933\n",
      "Iteration 25, loss = 0.02660886Iteration 25, loss = 0.03566284\n",
      "Iteration 25, loss = 0.03575931\n",
      "\n",
      "\n",
      "Iteration 2, loss = 0.05591469\n",
      "\n",
      "Iteration 2, loss = 0.06805549\n",
      "Iteration 26, loss = 0.03304750Iteration 26, loss = 0.03164355Iteration 26, loss = 0.03277561\n",
      "Iteration 26, loss = 0.02666344Iteration 26, loss = 0.03572085\n",
      "Iteration 26, loss = 0.03595727\n",
      "\n",
      "\n",
      "Iteration 3, loss = 0.05060288\n",
      "\n",
      "Iteration 3, loss = 0.06039867\n",
      "Iteration 27, loss = 0.03250719Iteration 27, loss = 0.03167766Iteration 27, loss = 0.03247543\n",
      "Iteration 27, loss = 0.02638443Iteration 27, loss = 0.03581057\n",
      "Iteration 27, loss = 0.03555677\n",
      "\n",
      "\n",
      "Iteration 4, loss = 0.04602912\n",
      "\n",
      "Iteration 4, loss = 0.05521618\n",
      "Iteration 28, loss = 0.03218225Iteration 28, loss = 0.03094247Iteration 28, loss = 0.03183159\n",
      "Iteration 28, loss = 0.02668709Iteration 28, loss = 0.03453924\n",
      "Iteration 28, loss = 0.03514220\n",
      "\n",
      "\n",
      "Iteration 5, loss = 0.04363927\n",
      "\n",
      "Iteration 5, loss = 0.05187859\n",
      "Iteration 29, loss = 0.03232190Iteration 29, loss = 0.03107206Iteration 29, loss = 0.03212764\n",
      "Iteration 29, loss = 0.02639377Iteration 29, loss = 0.03546361\n",
      "Iteration 29, loss = 0.03552482\n",
      "\n",
      "\n",
      "Iteration 6, loss = 0.04103568\n",
      "\n",
      "Iteration 6, loss = 0.04874477\n",
      "Iteration 30, loss = 0.03233733Iteration 30, loss = 0.03109435Iteration 30, loss = 0.03226046\n",
      "Iteration 30, loss = 0.02591546Iteration 30, loss = 0.03497197\n",
      "Iteration 30, loss = 0.03534489\n",
      "\n",
      "\n",
      "Iteration 7, loss = 0.03969848\n",
      "\n",
      "Iteration 7, loss = 0.04743272\n",
      "Iteration 31, loss = 0.03204976Iteration 31, loss = 0.03091009Iteration 31, loss = 0.03194423\n",
      "Iteration 31, loss = 0.02657378Iteration 31, loss = 0.03471755\n",
      "Iteration 31, loss = 0.03493011\n",
      "\n",
      "\n",
      "Iteration 8, loss = 0.03843304\n",
      "\n",
      "Iteration 8, loss = 0.04529119\n",
      "Iteration 32, loss = 0.03219845Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "\n",
      "Iteration 32, loss = 0.02615644Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "\n",
      "Iteration 32, loss = 0.03491979\n",
      "Iteration 1, loss = 0.11451748Iteration 1, loss = 0.11350974Iteration 9, loss = 0.03662187\n",
      "Iteration 1, loss = 0.11387348Iteration 9, loss = 0.04315237\n",
      "Iteration 33, loss = 0.03161179\n",
      "\n",
      "\n",
      "Iteration 33, loss = 0.02588428\n",
      "\n",
      "Iteration 33, loss = 0.03437220\n",
      "Iteration 4, loss = 0.06455582\n",
      "Iteration 2, loss = 0.07337887Iteration 2, loss = 0.07208688Iteration 10, loss = 0.03549189\n",
      "Iteration 2, loss = 0.07301659Iteration 10, loss = 0.04240669\n",
      "Iteration 34, loss = 0.03160069\n",
      "\n",
      "\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "\n",
      "\n",
      "Iteration 34, loss = 0.03411747\n",
      "Iteration 3, loss = 0.06674158Iteration 3, loss = 0.06543180Iteration 11, loss = 0.03500766Iteration 1, loss = 0.11060943Iteration 3, loss = 0.06599633Iteration 11, loss = 0.04126600\n",
      "Iteration 35, loss = 0.03165370\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 35, loss = 0.03434221\n",
      "Iteration 4, loss = 0.06149459Iteration 4, loss = 0.06023208Iteration 12, loss = 0.03418034Iteration 2, loss = 0.07048442Iteration 4, loss = 0.06141450Iteration 12, loss = 0.04017912\n",
      "Iteration 36, loss = 0.03204875\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 36, loss = 0.03470946\n",
      "Iteration 5, loss = 0.05799240Iteration 5, loss = 0.05668944Iteration 13, loss = 0.03333811Iteration 3, loss = 0.06426373Iteration 5, loss = 0.05768189Iteration 13, loss = 0.03886577\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 37, loss = 0.03374900Iteration 1, loss = 0.09322881Iteration 6, loss = 0.05512671Iteration 6, loss = 0.05332165Iteration 14, loss = 0.03313374Iteration 4, loss = 0.05953139Iteration 6, loss = 0.05415216Iteration 14, loss = 0.03881808\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 38, loss = 0.03408225Iteration 2, loss = 0.05865447Iteration 7, loss = 0.05312077Iteration 7, loss = 0.05185635Iteration 15, loss = 0.03213604Iteration 5, loss = 0.05627975Iteration 7, loss = 0.05250168Iteration 15, loss = 0.03831019\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 39, loss = 0.03376345Iteration 3, loss = 0.05437835Iteration 8, loss = 0.05032659Iteration 8, loss = 0.04923777Iteration 16, loss = 0.03201822Iteration 6, loss = 0.05265651Iteration 8, loss = 0.05014308Iteration 16, loss = 0.03727109\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 40, loss = 0.03345417Iteration 4, loss = 0.05020898Iteration 9, loss = 0.04800374Iteration 9, loss = 0.04743626Iteration 17, loss = 0.03105664Iteration 7, loss = 0.05161382Iteration 9, loss = 0.04843782Iteration 17, loss = 0.03635351\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 41, loss = 0.03378878Iteration 5, loss = 0.04760702Iteration 10, loss = 0.04739369Iteration 10, loss = 0.04652471Iteration 18, loss = 0.03170877Iteration 8, loss = 0.04934631Iteration 10, loss = 0.04681595Iteration 18, loss = 0.03705125\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 42, loss = 0.03337324Iteration 6, loss = 0.04453604Iteration 11, loss = 0.04604748Iteration 11, loss = 0.04503311Iteration 19, loss = 0.03123604Iteration 9, loss = 0.04679808Iteration 11, loss = 0.04578445Iteration 19, loss = 0.03678608\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 43, loss = 0.03319032Iteration 7, loss = 0.04321501Iteration 12, loss = 0.04563925Iteration 12, loss = 0.04386950Iteration 20, loss = 0.03064625Iteration 10, loss = 0.04625352Iteration 12, loss = 0.04471304Iteration 20, loss = 0.03585688\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 44, loss = 0.03310085Iteration 8, loss = 0.04194479Iteration 13, loss = 0.04353041Iteration 13, loss = 0.04270179Iteration 21, loss = 0.03017135Iteration 11, loss = 0.04489288Iteration 13, loss = 0.04380209Iteration 21, loss = 0.03617042\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 45, loss = 0.03361497Iteration 9, loss = 0.03973868Iteration 14, loss = 0.04388581Iteration 14, loss = 0.04333275Iteration 22, loss = 0.03036901Iteration 12, loss = 0.04344880Iteration 14, loss = 0.04359130Iteration 22, loss = 0.03541715\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 46, loss = 0.03291051Iteration 10, loss = 0.03832744Iteration 15, loss = 0.04187032Iteration 15, loss = 0.04152901Iteration 23, loss = 0.03008971Iteration 13, loss = 0.04185631Iteration 15, loss = 0.04150003Iteration 23, loss = 0.03506740\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 47, loss = 0.03301444Iteration 11, loss = 0.03815824Iteration 16, loss = 0.04145825Iteration 16, loss = 0.04064370Iteration 24, loss = 0.02997368Iteration 14, loss = 0.04205309Iteration 16, loss = 0.04132673Iteration 24, loss = 0.03534817\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 48, loss = 0.03285882Iteration 12, loss = 0.03692372Iteration 17, loss = 0.04128361Iteration 17, loss = 0.04045495Iteration 25, loss = 0.02923744Iteration 15, loss = 0.04135283Iteration 17, loss = 0.04113885Iteration 25, loss = 0.03461781\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 49, loss = 0.03260968\n",
      "Iteration 5, loss = 0.06145695Iteration 13, loss = 0.03568057Iteration 18, loss = 0.04104715Iteration 18, loss = 0.03992147Iteration 26, loss = 0.02957174Iteration 16, loss = 0.04020717Iteration 18, loss = 0.03964405Iteration 26, loss = 0.03466772\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 50, loss = 0.03280149Iteration 14, loss = 0.03541652Iteration 19, loss = 0.04049293Iteration 19, loss = 0.04006069Iteration 27, loss = 0.02905933Iteration 17, loss = 0.03901084Iteration 19, loss = 0.03968490Iteration 27, loss = 0.03501892\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 51, loss = 0.03270404Iteration 15, loss = 0.03460049Iteration 20, loss = 0.03970433Iteration 20, loss = 0.03835994Iteration 28, loss = 0.02943732Iteration 18, loss = 0.03936313Iteration 20, loss = 0.03923696Iteration 28, loss = 0.03370669\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 52, loss = 0.03240617Iteration 16, loss = 0.03439032Iteration 21, loss = 0.03966520Iteration 21, loss = 0.03867065Iteration 29, loss = 0.02914888Iteration 19, loss = 0.03916650Iteration 21, loss = 0.03924456Iteration 29, loss = 0.03372952\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 53, loss = 0.03212488Iteration 17, loss = 0.03281806Iteration 22, loss = 0.03948326Iteration 22, loss = 0.03846008Iteration 30, loss = 0.02827196Iteration 20, loss = 0.03803932Iteration 22, loss = 0.03924750Iteration 30, loss = 0.03379639\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 54, loss = 0.03216742Iteration 18, loss = 0.03395018Iteration 23, loss = 0.03925466Iteration 23, loss = 0.03849941Iteration 31, loss = 0.02899337Iteration 21, loss = 0.03839310Iteration 23, loss = 0.03851581Iteration 31, loss = 0.03357406\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 55, loss = 0.03235082Iteration 19, loss = 0.03316639Iteration 24, loss = 0.03916607Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 32, loss = 0.02877490Iteration 22, loss = 0.03757046Iteration 24, loss = 0.03787412Iteration 32, loss = 0.03378415\n",
      "\n",
      "\n",
      "Iteration 1, loss = 0.11129723\n",
      "\n",
      "\n",
      "\n",
      "Iteration 56, loss = 0.03216951Iteration 20, loss = 0.03243425Iteration 25, loss = 0.03784561\n",
      "Iteration 33, loss = 0.02826488Iteration 23, loss = 0.03677321Iteration 25, loss = 0.03768280Iteration 33, loss = 0.03313187\n",
      "\n",
      "\n",
      "Iteration 2, loss = 0.07715064\n",
      "\n",
      "\n",
      "\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 21, loss = 0.03192797Iteration 26, loss = 0.03796409\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 24, loss = 0.03708359Iteration 26, loss = 0.03784899Iteration 34, loss = 0.03317163Iteration 1, loss = 0.12479225\n",
      "\n",
      "Iteration 3, loss = 0.07036321Iteration 1, loss = 0.11187921\n",
      "\n",
      "\n",
      "\n",
      "Iteration 22, loss = 0.03190256Iteration 27, loss = 0.03772542\n",
      "\n",
      "Iteration 25, loss = 0.03664415Iteration 27, loss = 0.03748462Iteration 35, loss = 0.03324042Iteration 2, loss = 0.08585308\n",
      "\n",
      "Iteration 4, loss = 0.06578200Iteration 2, loss = 0.07752688\n",
      "\n",
      "\n",
      "\n",
      "Iteration 23, loss = 0.03179441Iteration 28, loss = 0.03706324\n",
      "\n",
      "Iteration 26, loss = 0.03670976Iteration 28, loss = 0.03631447Iteration 36, loss = 0.03300503Iteration 3, loss = 0.07984661\n",
      "\n",
      "Iteration 5, loss = 0.06174813Iteration 3, loss = 0.07136527\n",
      "\n",
      "\n",
      "\n",
      "Iteration 24, loss = 0.03149546Iteration 29, loss = 0.03746726\n",
      "\n",
      "Iteration 27, loss = 0.03639403Iteration 29, loss = 0.03684952Iteration 37, loss = 0.03277178Iteration 4, loss = 0.07547242\n",
      "\n",
      "Iteration 6, loss = 0.05797419Iteration 4, loss = 0.06601000\n",
      "\n",
      "\n",
      "\n",
      "Iteration 25, loss = 0.03077488Iteration 30, loss = 0.03748117\n",
      "\n",
      "Iteration 28, loss = 0.03537788Iteration 30, loss = 0.03698316Iteration 38, loss = 0.03307629Iteration 5, loss = 0.07227692\n",
      "\n",
      "Iteration 7, loss = 0.05642525Iteration 5, loss = 0.06237750\n",
      "\n",
      "\n",
      "\n",
      "Iteration 26, loss = 0.03080158Iteration 31, loss = 0.03725327\n",
      "\n",
      "Iteration 29, loss = 0.03556489Iteration 31, loss = 0.03623818Iteration 39, loss = 0.03253224Iteration 6, loss = 0.07003715\n",
      "\n",
      "Iteration 8, loss = 0.05344422Iteration 6, loss = 0.05921361\n",
      "\n",
      "\n",
      "\n",
      "Iteration 27, loss = 0.03033055Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "\n",
      "\n",
      "Iteration 30, loss = 0.03556387Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 40, loss = 0.03254455Iteration 7, loss = 0.06823227\n",
      "Iteration 1, loss = 0.10835322Iteration 9, loss = 0.05144845Iteration 7, loss = 0.05711884\n",
      "Iteration 1, loss = 0.11112650\n",
      "\n",
      "Iteration 28, loss = 0.03091514\n",
      "\n",
      "\n",
      "Iteration 31, loss = 0.03503565\n",
      "Iteration 41, loss = 0.03236615Iteration 8, loss = 0.06624945\n",
      "Iteration 2, loss = 0.07462523Iteration 10, loss = 0.04970557Iteration 8, loss = 0.05359572\n",
      "Iteration 2, loss = 0.07606527\n",
      "\n",
      "\n",
      "Iteration 6, loss = 0.05913690Iteration 29, loss = 0.03055738\n",
      "\n",
      "\n",
      "Iteration 32, loss = 0.03528317\n",
      "Iteration 42, loss = 0.03222519Iteration 9, loss = 0.06440788\n",
      "Iteration 3, loss = 0.06872715Iteration 11, loss = 0.04866031Iteration 9, loss = 0.05165008\n",
      "Iteration 3, loss = 0.07000578\n",
      "\n",
      "Iteration 30, loss = 0.02934357\n",
      "\n",
      "\n",
      "Iteration 33, loss = 0.03464762\n",
      "Iteration 43, loss = 0.03184369Iteration 10, loss = 0.06317387\n",
      "Iteration 4, loss = 0.06372295Iteration 12, loss = 0.04732999Iteration 10, loss = 0.05029118\n",
      "Iteration 4, loss = 0.06469249\n",
      "\n",
      "Iteration 31, loss = 0.02989633\n",
      "\n",
      "\n",
      "Iteration 34, loss = 0.03513314\n",
      "Iteration 44, loss = 0.03216409Iteration 11, loss = 0.06188864\n",
      "Iteration 5, loss = 0.06026059Iteration 13, loss = 0.04608842Iteration 11, loss = 0.04884316\n",
      "Iteration 5, loss = 0.06072710\n",
      "\n",
      "Iteration 32, loss = 0.03013896\n",
      "\n",
      "\n",
      "Iteration 35, loss = 0.03449916\n",
      "Iteration 45, loss = 0.03158933Iteration 12, loss = 0.06099192\n",
      "Iteration 6, loss = 0.05642800Iteration 14, loss = 0.04574749Iteration 12, loss = 0.04828997\n",
      "Iteration 6, loss = 0.05704329\n",
      "\n",
      "Iteration 33, loss = 0.02947633\n",
      "\n",
      "\n",
      "Iteration 36, loss = 0.03432068\n",
      "Iteration 46, loss = 0.03164720Iteration 13, loss = 0.05955059\n",
      "Iteration 7, loss = 0.05516912Iteration 15, loss = 0.04361622Iteration 13, loss = 0.04593541\n",
      "Iteration 7, loss = 0.05585603\n",
      "\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "\n",
      "\n",
      "\n",
      "Iteration 37, loss = 0.03440978\n",
      "Iteration 47, loss = 0.03205837Iteration 14, loss = 0.05974020Iteration 1, loss = 0.09111294Iteration 8, loss = 0.05217589Iteration 16, loss = 0.04295241Iteration 14, loss = 0.04653753\n",
      "Iteration 8, loss = 0.05241922\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 38, loss = 0.03438919\n",
      "Iteration 48, loss = 0.03150701Iteration 15, loss = 0.05779337Iteration 2, loss = 0.06254623Iteration 9, loss = 0.04959453Iteration 17, loss = 0.04325577Iteration 15, loss = 0.04382251\n",
      "Iteration 9, loss = 0.05081187\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 39, loss = 0.03393393\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 16, loss = 0.05739612Iteration 3, loss = 0.05879323Iteration 10, loss = 0.04902732Iteration 18, loss = 0.04191420Iteration 16, loss = 0.04385149\n",
      "Iteration 10, loss = 0.04936912Iteration 1, loss = 0.15821205\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 40, loss = 0.03409803\n",
      "\n",
      "Iteration 17, loss = 0.05712864Iteration 4, loss = 0.05441999Iteration 11, loss = 0.04717941Iteration 19, loss = 0.04184393Iteration 17, loss = 0.04373150\n",
      "Iteration 11, loss = 0.04783411Iteration 2, loss = 0.08269887\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 41, loss = 0.03392632\n",
      "\n",
      "Iteration 18, loss = 0.05645007Iteration 5, loss = 0.05155057Iteration 12, loss = 0.04556501Iteration 20, loss = 0.04114856Iteration 18, loss = 0.04276969\n",
      "Iteration 12, loss = 0.04685336Iteration 3, loss = 0.07274657\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 42, loss = 0.03363785\n",
      "\n",
      "Iteration 19, loss = 0.05639169Iteration 6, loss = 0.04807967Iteration 13, loss = 0.04433250Iteration 21, loss = 0.04100815Iteration 19, loss = 0.04256613\n",
      "Iteration 13, loss = 0.04491593Iteration 4, loss = 0.06677140\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 43, loss = 0.03365910\n",
      "\n",
      "Iteration 20, loss = 0.05575791Iteration 7, loss = 0.04636269Iteration 14, loss = 0.04388844Iteration 22, loss = 0.04019929Iteration 20, loss = 0.04170498\n",
      "Iteration 14, loss = 0.04610027Iteration 5, loss = 0.06318443\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 44, loss = 0.03380720\n",
      "\n",
      "Iteration 21, loss = 0.05569256Iteration 8, loss = 0.04491662Iteration 15, loss = 0.04325782Iteration 23, loss = 0.04030013Iteration 21, loss = 0.04167835\n",
      "Iteration 15, loss = 0.04378069Iteration 6, loss = 0.06079684\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 45, loss = 0.03324080\n",
      "\n",
      "Iteration 22, loss = 0.05519448Iteration 9, loss = 0.04262790Iteration 16, loss = 0.04202622Iteration 24, loss = 0.03979360Iteration 22, loss = 0.04120277\n",
      "Iteration 16, loss = 0.04318902Iteration 7, loss = 0.05866064\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 46, loss = 0.03327055\n",
      "\n",
      "Iteration 23, loss = 0.05486707Iteration 10, loss = 0.04076840Iteration 17, loss = 0.04103570Iteration 25, loss = 0.03920547Iteration 23, loss = 0.04058723\n",
      "Iteration 17, loss = 0.04240394Iteration 8, loss = 0.05715188\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 47, loss = 0.03315782\n",
      "\n",
      "Iteration 24, loss = 0.05466754Iteration 11, loss = 0.04075400Iteration 18, loss = 0.04129053Iteration 26, loss = 0.03904832Iteration 24, loss = 0.04073776\n",
      "Iteration 18, loss = 0.04220564Iteration 9, loss = 0.05581811\n",
      "\n",
      "Iteration 7, loss = 0.05746959\n",
      "\n",
      "\n",
      "\n",
      "Iteration 48, loss = 0.03303988\n",
      "\n",
      "Iteration 25, loss = 0.05390778Iteration 12, loss = 0.03929580Iteration 19, loss = 0.04110764Iteration 27, loss = 0.03963140Iteration 25, loss = 0.03997773\n",
      "Iteration 19, loss = 0.04200000Iteration 10, loss = 0.05440037\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 49, loss = 0.03289192\n",
      "\n",
      "Iteration 26, loss = 0.05413338Iteration 13, loss = 0.03800511Iteration 20, loss = 0.03972284Iteration 28, loss = 0.03776823Iteration 26, loss = 0.03987475\n",
      "Iteration 20, loss = 0.04064579Iteration 11, loss = 0.05358740\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 50, loss = 0.03296440\n",
      "\n",
      "Iteration 27, loss = 0.05361106Iteration 14, loss = 0.03714619Iteration 21, loss = 0.04010746Iteration 29, loss = 0.03856391Iteration 27, loss = 0.03954250\n",
      "Iteration 21, loss = 0.04047891Iteration 12, loss = 0.05279553\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 51, loss = 0.03254976\n",
      "\n",
      "Iteration 28, loss = 0.05326612Iteration 15, loss = 0.03645388Iteration 22, loss = 0.03946168Iteration 30, loss = 0.03825296Iteration 28, loss = 0.03873838\n",
      "Iteration 22, loss = 0.04070148Iteration 13, loss = 0.05184851\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 52, loss = 0.03298084\n",
      "\n",
      "Iteration 29, loss = 0.05343243Iteration 16, loss = 0.03577191Iteration 23, loss = 0.03852957Iteration 31, loss = 0.03783102Iteration 29, loss = 0.03906096\n",
      "Iteration 23, loss = 0.04069804Iteration 14, loss = 0.05215929\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 53, loss = 0.03258332\n",
      "\n",
      "Iteration 30, loss = 0.05331307Iteration 17, loss = 0.03462317Iteration 24, loss = 0.03909465Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 30, loss = 0.03918658\n",
      "Iteration 24, loss = 0.03978820Iteration 15, loss = 0.05083353\n",
      "\n",
      "\n",
      "Iteration 1, loss = 0.15848058\n",
      "Iteration 54, loss = 0.03239500\n",
      "\n",
      "Iteration 31, loss = 0.05300255Iteration 18, loss = 0.03576876Iteration 25, loss = 0.03831163\n",
      "Iteration 31, loss = 0.03869814\n",
      "Iteration 25, loss = 0.03917325Iteration 16, loss = 0.05030651\n",
      "\n",
      "\n",
      "Iteration 2, loss = 0.08315762\n",
      "Iteration 55, loss = 0.03278965\n",
      "\n",
      "Iteration 32, loss = 0.05297607Iteration 19, loss = 0.03451954Iteration 26, loss = 0.03870409\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "\n",
      "Iteration 26, loss = 0.03922572Iteration 17, loss = 0.04992555\n",
      "\n",
      "\n",
      "Iteration 3, loss = 0.07329056Iteration 1, loss = 0.15876447Iteration 56, loss = 0.03236757\n",
      "\n",
      "Iteration 33, loss = 0.05218265Iteration 20, loss = 0.03378837Iteration 27, loss = 0.03814170\n",
      "\n",
      "\n",
      "Iteration 27, loss = 0.03902256Iteration 18, loss = 0.04983283\n",
      "\n",
      "\n",
      "Iteration 4, loss = 0.06779746Iteration 2, loss = 0.08412830Iteration 57, loss = 0.03231941\n",
      "\n",
      "Iteration 34, loss = 0.05202207Iteration 21, loss = 0.03312818Iteration 28, loss = 0.03711959\n",
      "\n",
      "\n",
      "Iteration 28, loss = 0.03785713Iteration 19, loss = 0.04968460\n",
      "\n",
      "\n",
      "Iteration 5, loss = 0.06382499Iteration 3, loss = 0.07394101Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "\n",
      "\n",
      "Iteration 35, loss = 0.05222402Iteration 22, loss = 0.03355119Iteration 29, loss = 0.03730760\n",
      "\n",
      "Iteration 1, loss = 0.13799358Iteration 29, loss = 0.03868297Iteration 20, loss = 0.04902519\n",
      "\n",
      "\n",
      "Iteration 6, loss = 0.06110113Iteration 4, loss = 0.06799057\n",
      "\n",
      "\n",
      "Iteration 36, loss = 0.05222337Iteration 23, loss = 0.03316506Iteration 30, loss = 0.03710689\n",
      "\n",
      "Iteration 2, loss = 0.08808729Iteration 30, loss = 0.03829973Iteration 21, loss = 0.04916186\n",
      "\n",
      "\n",
      "Iteration 7, loss = 0.05918543Iteration 5, loss = 0.06424161\n",
      "\n",
      "\n",
      "Iteration 37, loss = 0.05192744Iteration 24, loss = 0.03256430Iteration 31, loss = 0.03663672\n",
      "\n",
      "Iteration 3, loss = 0.08199788Iteration 31, loss = 0.03741101Iteration 22, loss = 0.04875140\n",
      "\n",
      "\n",
      "Iteration 8, loss = 0.05762762Iteration 6, loss = 0.06178971\n",
      "\n",
      "\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 25, loss = 0.03190169Iteration 32, loss = 0.03711540\n",
      "\n",
      "Iteration 4, loss = 0.07815573Iteration 32, loss = 0.03879289Iteration 23, loss = 0.04876363Iteration 1, loss = 0.11973847\n",
      "\n",
      "Iteration 9, loss = 0.05636925Iteration 7, loss = 0.05986160\n",
      "\n",
      "\n",
      "\n",
      "Iteration 26, loss = 0.03249108Iteration 33, loss = 0.03610289\n",
      "\n",
      "Iteration 5, loss = 0.07549850Iteration 33, loss = 0.03699928Iteration 24, loss = 0.04849985Iteration 2, loss = 0.08785813\n",
      "\n",
      "Iteration 10, loss = 0.05517191Iteration 8, loss = 0.05806919\n",
      "\n",
      "\n",
      "\n",
      "Iteration 27, loss = 0.03166050Iteration 34, loss = 0.03652690\n",
      "\n",
      "Iteration 6, loss = 0.07369920Iteration 34, loss = 0.03664527Iteration 25, loss = 0.04815185Iteration 3, loss = 0.08247407\n",
      "Iteration 8, loss = 0.05619106\n",
      "\n",
      "Iteration 11, loss = 0.05426827Iteration 9, loss = 0.05649171\n",
      "\n",
      "\n",
      "\n",
      "Iteration 28, loss = 0.03181873Iteration 35, loss = 0.03622388\n",
      "\n",
      "Iteration 7, loss = 0.07258789Iteration 35, loss = 0.03744962Iteration 26, loss = 0.04833927Iteration 4, loss = 0.07777815\n",
      "\n",
      "Iteration 12, loss = 0.05317404Iteration 10, loss = 0.05561522\n",
      "\n",
      "\n",
      "\n",
      "Iteration 29, loss = 0.03175402Iteration 36, loss = 0.03591767\n",
      "\n",
      "Iteration 8, loss = 0.07119362Iteration 36, loss = 0.03698319Iteration 27, loss = 0.04790705Iteration 5, loss = 0.07383087\n",
      "\n",
      "Iteration 13, loss = 0.05264907Iteration 11, loss = 0.05442795\n",
      "\n",
      "\n",
      "\n",
      "Iteration 30, loss = 0.03098868Iteration 37, loss = 0.03584919\n",
      "\n",
      "Iteration 9, loss = 0.07033826Iteration 37, loss = 0.03712826Iteration 28, loss = 0.04745585Iteration 6, loss = 0.07079772\n",
      "\n",
      "Iteration 14, loss = 0.05243566Iteration 12, loss = 0.05363161\n",
      "\n",
      "\n",
      "\n",
      "Iteration 31, loss = 0.03155729Iteration 38, loss = 0.03619664\n",
      "\n",
      "Iteration 10, loss = 0.06890931Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 29, loss = 0.04793663Iteration 7, loss = 0.06937628\n",
      "\n",
      "Iteration 15, loss = 0.05115275Iteration 13, loss = 0.05266560\n",
      "Iteration 1, loss = 0.15563996\n",
      "\n",
      "Iteration 32, loss = 0.03107947Iteration 39, loss = 0.03554639\n",
      "\n",
      "Iteration 11, loss = 0.06823063\n",
      "Iteration 30, loss = 0.04754386Iteration 8, loss = 0.06699177\n",
      "\n",
      "Iteration 16, loss = 0.05096110Iteration 14, loss = 0.05268587\n",
      "Iteration 2, loss = 0.08137411\n",
      "\n",
      "Iteration 33, loss = 0.03067708Iteration 40, loss = 0.03564586\n",
      "\n",
      "Iteration 12, loss = 0.06748930\n",
      "Iteration 31, loss = 0.04751974Iteration 9, loss = 0.06479091\n",
      "\n",
      "Iteration 17, loss = 0.05062000Iteration 15, loss = 0.05145540\n",
      "Iteration 3, loss = 0.07134593\n",
      "\n",
      "Iteration 34, loss = 0.03108399Iteration 41, loss = 0.03537856\n",
      "\n",
      "Iteration 13, loss = 0.06649024\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 10, loss = 0.06376929\n",
      "\n",
      "Iteration 18, loss = 0.05013843Iteration 16, loss = 0.05109556\n",
      "Iteration 4, loss = 0.06540199Iteration 1, loss = 0.13180784\n",
      "Iteration 35, loss = 0.03035307Iteration 42, loss = 0.03549702\n",
      "\n",
      "Iteration 14, loss = 0.06695992\n",
      "\n",
      "Iteration 11, loss = 0.06209889\n",
      "\n",
      "Iteration 19, loss = 0.05023184Iteration 17, loss = 0.05085619\n",
      "Iteration 5, loss = 0.06186676Iteration 2, loss = 0.08180798\n",
      "Iteration 36, loss = 0.03012744Iteration 43, loss = 0.03527713\n",
      "\n",
      "Iteration 15, loss = 0.06555004\n",
      "\n",
      "Iteration 12, loss = 0.06083238\n",
      "\n",
      "Iteration 20, loss = 0.04963777Iteration 18, loss = 0.05038213\n",
      "Iteration 6, loss = 0.05950091Iteration 3, loss = 0.07478761\n",
      "Iteration 37, loss = 0.03043914Iteration 44, loss = 0.03536459\n",
      "\n",
      "Iteration 16, loss = 0.06494144\n",
      "\n",
      "Iteration 13, loss = 0.05925691\n",
      "\n",
      "Iteration 21, loss = 0.04976259Iteration 19, loss = 0.05053400\n",
      "Iteration 7, loss = 0.05745991Iteration 4, loss = 0.07016906\n",
      "Iteration 38, loss = 0.02968117Iteration 45, loss = 0.03476948\n",
      "\n",
      "Iteration 17, loss = 0.06442807\n",
      "\n",
      "Iteration 14, loss = 0.05911391\n",
      "\n",
      "Iteration 22, loss = 0.04930530Iteration 20, loss = 0.05012162\n",
      "Iteration 8, loss = 0.05596710Iteration 5, loss = 0.06735882\n",
      "Iteration 39, loss = 0.03043223Iteration 46, loss = 0.03477128\n",
      "\n",
      "Iteration 18, loss = 0.06457967\n",
      "\n",
      "Iteration 15, loss = 0.05808678\n",
      "\n",
      "Iteration 23, loss = 0.04912926Iteration 21, loss = 0.05003814\n",
      "Iteration 9, loss = 0.05432924Iteration 6, loss = 0.06536863\n",
      "Iteration 40, loss = 0.02988377Iteration 47, loss = 0.03487372\n",
      "\n",
      "Iteration 19, loss = 0.06429350\n",
      "\n",
      "Iteration 16, loss = 0.05710203\n",
      "\n",
      "Iteration 24, loss = 0.04896753Iteration 22, loss = 0.04949691\n",
      "Iteration 10, loss = 0.05343236Iteration 7, loss = 0.06389503\n",
      "Iteration 41, loss = 0.02961571Iteration 48, loss = 0.03475704\n",
      "\n",
      "Iteration 20, loss = 0.06353466\n",
      "\n",
      "Iteration 17, loss = 0.05617008\n",
      "\n",
      "Iteration 25, loss = 0.04875799Iteration 23, loss = 0.04943815\n",
      "Iteration 11, loss = 0.05259450Iteration 8, loss = 0.06207087\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "\n",
      "\n",
      "Iteration 21, loss = 0.06376090\n",
      "\n",
      "Iteration 18, loss = 0.05631365Iteration 1, loss = 0.12786721Iteration 1, loss = 0.12242575Iteration 26, loss = 0.04885561Iteration 24, loss = 0.04934467\n",
      "Iteration 12, loss = 0.05153651Iteration 9, loss = 0.06055711\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 22, loss = 0.06304342\n",
      "\n",
      "Iteration 19, loss = 0.05588495\n",
      "Iteration 9, loss = 0.05497698Iteration 2, loss = 0.07855007Iteration 2, loss = 0.08935374Iteration 27, loss = 0.04849012Iteration 25, loss = 0.04896782\n",
      "Iteration 13, loss = 0.05063987Iteration 10, loss = 0.05967238\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 23, loss = 0.06307405\n",
      "\n",
      "Iteration 20, loss = 0.05479823Iteration 3, loss = 0.07212676Iteration 3, loss = 0.08351728Iteration 28, loss = 0.04806197Iteration 26, loss = 0.04898643\n",
      "Iteration 14, loss = 0.05043895Iteration 11, loss = 0.05847775\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 24, loss = 0.06269585\n",
      "\n",
      "Iteration 21, loss = 0.05524742Iteration 4, loss = 0.06793463Iteration 4, loss = 0.07863175Iteration 29, loss = 0.04829643Iteration 27, loss = 0.04858370\n",
      "Iteration 15, loss = 0.04998242Iteration 12, loss = 0.05771895\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 25, loss = 0.06231342\n",
      "\n",
      "Iteration 22, loss = 0.05412522Iteration 5, loss = 0.06520926Iteration 5, loss = 0.07461103Iteration 30, loss = 0.04835266Iteration 28, loss = 0.04851921\n",
      "Iteration 16, loss = 0.04928207Iteration 13, loss = 0.05656115\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 26, loss = 0.06240851\n",
      "\n",
      "Iteration 23, loss = 0.05397414Iteration 6, loss = 0.06304747Iteration 6, loss = 0.07149067Iteration 31, loss = 0.04809953Iteration 29, loss = 0.04860667\n",
      "Iteration 17, loss = 0.04857888Iteration 14, loss = 0.05689477\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 27, loss = 0.06190809\n",
      "\n",
      "Iteration 24, loss = 0.05426601Iteration 7, loss = 0.06189699Iteration 7, loss = 0.07002591Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 30, loss = 0.04843280\n",
      "Iteration 18, loss = 0.04874538Iteration 15, loss = 0.05524623\n",
      "\n",
      "\n",
      "Iteration 1, loss = 0.13590288\n",
      "Iteration 28, loss = 0.06133311\n",
      "\n",
      "Iteration 25, loss = 0.05343234Iteration 8, loss = 0.06029755Iteration 8, loss = 0.06750612\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "\n",
      "Iteration 19, loss = 0.04865919Iteration 16, loss = 0.05493477\n",
      "\n",
      "\n",
      "Iteration 2, loss = 0.06659822Iteration 1, loss = 0.13140505Iteration 29, loss = 0.06183595\n",
      "\n",
      "Iteration 26, loss = 0.05358651Iteration 9, loss = 0.05859405Iteration 9, loss = 0.06564065\n",
      "\n",
      "\n",
      "Iteration 20, loss = 0.04810171Iteration 17, loss = 0.05460602\n",
      "\n",
      "\n",
      "Iteration 3, loss = 0.05917428Iteration 2, loss = 0.08134054Iteration 30, loss = 0.06140654\n",
      "\n",
      "Iteration 27, loss = 0.05355273Iteration 10, loss = 0.05790455Iteration 10, loss = 0.06433264\n",
      "\n",
      "\n",
      "Iteration 21, loss = 0.04831464Iteration 18, loss = 0.05411343\n",
      "\n",
      "\n",
      "Iteration 4, loss = 0.05419441Iteration 3, loss = 0.07424517Iteration 31, loss = 0.06127519\n",
      "\n",
      "Iteration 28, loss = 0.05260389Iteration 11, loss = 0.05681581Iteration 11, loss = 0.06276760\n",
      "\n",
      "\n",
      "Iteration 22, loss = 0.04772626Iteration 19, loss = 0.05438764\n",
      "\n",
      "\n",
      "Iteration 5, loss = 0.05151965Iteration 4, loss = 0.07007041Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "\n",
      "\n",
      "Iteration 29, loss = 0.05270228Iteration 12, loss = 0.05592684Iteration 12, loss = 0.06185295\n",
      "\n",
      "Iteration 1, loss = 0.12865756Iteration 23, loss = 0.04764794Iteration 20, loss = 0.05378516\n",
      "\n",
      "\n",
      "Iteration 6, loss = 0.04926746Iteration 5, loss = 0.06719766\n",
      "\n",
      "\n",
      "Iteration 30, loss = 0.05283771Iteration 13, loss = 0.05450279Iteration 13, loss = 0.06011756\n",
      "\n",
      "Iteration 2, loss = 0.09115587Iteration 24, loss = 0.04758447Iteration 21, loss = 0.05355732\n",
      "\n",
      "\n",
      "Iteration 7, loss = 0.04789190Iteration 6, loss = 0.06454757\n",
      "\n",
      "\n",
      "Iteration 31, loss = 0.05243251Iteration 14, loss = 0.05451263Iteration 14, loss = 0.06088770\n",
      "\n",
      "Iteration 3, loss = 0.08640939Iteration 25, loss = 0.04718989Iteration 22, loss = 0.05294112\n",
      "\n",
      "\n",
      "Iteration 8, loss = 0.04655480Iteration 7, loss = 0.06328154\n",
      "\n",
      "\n",
      "Iteration 32, loss = 0.05274399Iteration 15, loss = 0.05392881Iteration 15, loss = 0.05915577\n",
      "\n",
      "Iteration 4, loss = 0.08238964Iteration 26, loss = 0.04738574Iteration 23, loss = 0.05274007\n",
      "\n",
      "\n",
      "Iteration 9, loss = 0.04535467Iteration 8, loss = 0.06170142\n",
      "\n",
      "\n",
      "Iteration 33, loss = 0.05210516Iteration 16, loss = 0.05314862Iteration 16, loss = 0.05823831\n",
      "\n",
      "Iteration 5, loss = 0.07923095Iteration 27, loss = 0.04724781Iteration 24, loss = 0.05271984\n",
      "\n",
      "\n",
      "Iteration 10, loss = 0.04445039Iteration 9, loss = 0.06058077\n",
      "\n",
      "\n",
      "Iteration 34, loss = 0.05197149Iteration 17, loss = 0.05233609Iteration 17, loss = 0.05754956\n",
      "\n",
      "Iteration 6, loss = 0.07702229Iteration 28, loss = 0.04663903Iteration 25, loss = 0.05204947\n",
      "\n",
      "\n",
      "Iteration 11, loss = 0.04409546Iteration 10, loss = 0.05922453\n",
      "\n",
      "\n",
      "Iteration 35, loss = 0.05224476\n",
      "Iteration 10, loss = 0.05437965Iteration 18, loss = 0.05255463Iteration 18, loss = 0.05776578\n",
      "\n",
      "Iteration 7, loss = 0.07580161Iteration 29, loss = 0.04688556Iteration 26, loss = 0.05201095\n",
      "\n",
      "\n",
      "Iteration 12, loss = 0.04358622Iteration 11, loss = 0.05845149\n",
      "\n",
      "\n",
      "Iteration 36, loss = 0.05166262Iteration 19, loss = 0.05233523Iteration 19, loss = 0.05762067\n",
      "\n",
      "Iteration 8, loss = 0.07380111Iteration 30, loss = 0.04673877Iteration 27, loss = 0.05156225\n",
      "\n",
      "\n",
      "Iteration 13, loss = 0.04281349Iteration 12, loss = 0.05713362\n",
      "\n",
      "\n",
      "Iteration 37, loss = 0.05183286Iteration 20, loss = 0.05146915Iteration 20, loss = 0.05620694\n",
      "\n",
      "Iteration 9, loss = 0.07202305Iteration 31, loss = 0.04671086Iteration 28, loss = 0.05139053\n",
      "\n",
      "\n",
      "Iteration 14, loss = 0.04253878Iteration 13, loss = 0.05661366\n",
      "\n",
      "\n",
      "Iteration 38, loss = 0.05182889Iteration 21, loss = 0.05189156Iteration 21, loss = 0.05641991\n",
      "\n",
      "Iteration 10, loss = 0.07117139Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 29, loss = 0.05144592\n",
      "\n",
      "\n",
      "Iteration 15, loss = 0.04194640Iteration 14, loss = 0.05660816\n",
      "Iteration 1, loss = 0.13085054\n",
      "Iteration 39, loss = 0.05146772Iteration 22, loss = 0.05110973Iteration 22, loss = 0.05574594\n",
      "\n",
      "Iteration 11, loss = 0.07002407\n",
      "Iteration 30, loss = 0.05126172\n",
      "\n",
      "\n",
      "Iteration 16, loss = 0.04165999Iteration 15, loss = 0.05482707\n",
      "Iteration 2, loss = 0.08039486\n",
      "Iteration 40, loss = 0.05159636Iteration 23, loss = 0.05075236Iteration 23, loss = 0.05592451\n",
      "\n",
      "Iteration 12, loss = 0.06894645\n",
      "Iteration 31, loss = 0.05113737\n",
      "\n",
      "\n",
      "Iteration 17, loss = 0.04092432Iteration 16, loss = 0.05470114\n",
      "Iteration 3, loss = 0.07366970\n",
      "Iteration 41, loss = 0.05103487Iteration 24, loss = 0.05096156Iteration 24, loss = 0.05543336\n",
      "\n",
      "Iteration 13, loss = 0.06732385\n",
      "Iteration 32, loss = 0.05114161\n",
      "\n",
      "\n",
      "Iteration 18, loss = 0.04137608Iteration 17, loss = 0.05441659\n",
      "Iteration 4, loss = 0.06920003\n",
      "Iteration 42, loss = 0.05138258Iteration 25, loss = 0.05014270Iteration 25, loss = 0.05474600\n",
      "\n",
      "Iteration 14, loss = 0.06733617\n",
      "Iteration 33, loss = 0.05033005\n",
      "\n",
      "\n",
      "Iteration 19, loss = 0.04077834Iteration 18, loss = 0.05361696\n",
      "Iteration 5, loss = 0.06629259\n",
      "Iteration 43, loss = 0.05097048Iteration 26, loss = 0.05033345Iteration 26, loss = 0.05493618\n",
      "\n",
      "Iteration 15, loss = 0.06650288\n",
      "Iteration 34, loss = 0.05015860\n",
      "\n",
      "\n",
      "Iteration 20, loss = 0.04067737Iteration 19, loss = 0.05372557\n",
      "Iteration 6, loss = 0.06406976\n",
      "Iteration 44, loss = 0.05090637Iteration 27, loss = 0.05028928Iteration 27, loss = 0.05436884\n",
      "\n",
      "Iteration 16, loss = 0.06589943\n",
      "Iteration 35, loss = 0.05035663\n",
      "\n",
      "\n",
      "Iteration 21, loss = 0.04020534Iteration 20, loss = 0.05305144\n",
      "Iteration 7, loss = 0.06267953\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 28, loss = 0.04952123Iteration 28, loss = 0.05350385\n",
      "\n",
      "Iteration 17, loss = 0.06475351\n",
      "Iteration 36, loss = 0.05051804\n",
      "\n",
      "Iteration 22, loss = 0.04030921Iteration 21, loss = 0.05318910\n",
      "Iteration 8, loss = 0.06095976\n",
      "Iteration 29, loss = 0.04965665Iteration 29, loss = 0.05439690\n",
      "\n",
      "Iteration 18, loss = 0.06499675\n",
      "Iteration 37, loss = 0.04998917\n",
      "\n",
      "Iteration 23, loss = 0.04013527Iteration 22, loss = 0.05267707\n",
      "Iteration 9, loss = 0.05973031\n",
      "Iteration 30, loss = 0.04948519Iteration 30, loss = 0.05382094\n",
      "\n",
      "Iteration 19, loss = 0.06469438\n",
      "Iteration 38, loss = 0.05024918\n",
      "\n",
      "Iteration 24, loss = 0.04022363Iteration 23, loss = 0.05220328\n",
      "Iteration 10, loss = 0.05845752\n",
      "Iteration 31, loss = 0.04936444Iteration 31, loss = 0.05373815\n",
      "\n",
      "Iteration 20, loss = 0.06382054\n",
      "Iteration 39, loss = 0.04985397\n",
      "\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 24, loss = 0.05214626\n",
      "Iteration 11, loss = 0.05738933\n",
      "Iteration 32, loss = 0.04952266Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.10963775\n",
      "Iteration 21, loss = 0.06430907\n",
      "Iteration 40, loss = 0.04961407\n",
      "Iteration 1, loss = 0.16462452\n",
      "Iteration 25, loss = 0.05175454\n",
      "Iteration 12, loss = 0.05681195\n",
      "Iteration 33, loss = 0.04884326\n",
      "Iteration 2, loss = 0.06542723\n",
      "Iteration 22, loss = 0.06325208\n",
      "Iteration 41, loss = 0.04980461\n",
      "Iteration 2, loss = 0.08960967\n",
      "Iteration 26, loss = 0.05167599\n",
      "Iteration 13, loss = 0.05557717\n",
      "Iteration 34, loss = 0.04882846\n",
      "Iteration 3, loss = 0.06092435\n",
      "Iteration 23, loss = 0.06303090\n",
      "Iteration 42, loss = 0.04963921\n",
      "Iteration 3, loss = 0.07983718\n",
      "Iteration 27, loss = 0.05146599\n",
      "Iteration 11, loss = 0.05323580\n",
      "Iteration 14, loss = 0.05616190\n",
      "Iteration 35, loss = 0.04880334\n",
      "Iteration 4, loss = 0.05720057\n",
      "Iteration 24, loss = 0.06297820\n",
      "Iteration 43, loss = 0.04940652\n",
      "Iteration 4, loss = 0.07424778\n",
      "Iteration 28, loss = 0.05068741\n",
      "Iteration 15, loss = 0.05471338\n",
      "Iteration 36, loss = 0.04844856\n",
      "Iteration 5, loss = 0.05510166\n",
      "Iteration 25, loss = 0.06230006\n",
      "Iteration 44, loss = 0.04935105\n",
      "Iteration 5, loss = 0.07121493\n",
      "Iteration 29, loss = 0.05095170\n",
      "Iteration 16, loss = 0.05398372\n",
      "Iteration 37, loss = 0.04859276\n",
      "Iteration 6, loss = 0.05295246\n",
      "Iteration 26, loss = 0.06262965\n",
      "Iteration 45, loss = 0.04951401\n",
      "Iteration 6, loss = 0.06925336\n",
      "Iteration 30, loss = 0.05091931\n",
      "Iteration 17, loss = 0.05364050\n",
      "Iteration 38, loss = 0.04837665\n",
      "Iteration 7, loss = 0.05195122\n",
      "Iteration 27, loss = 0.06227387\n",
      "Iteration 46, loss = 0.04929666\n",
      "Iteration 7, loss = 0.06763698\n",
      "Iteration 31, loss = 0.05067109\n",
      "Iteration 18, loss = 0.05360599\n",
      "Iteration 39, loss = 0.04831289\n",
      "Iteration 8, loss = 0.05079238\n",
      "Iteration 28, loss = 0.06160255\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "\n",
      "Iteration 8, loss = 0.06651706\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "\n",
      "Iteration 19, loss = 0.05336952Iteration 1, loss = 0.16509414Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "\n",
      "Iteration 9, loss = 0.04925700Iteration 1, loss = 0.12423295Iteration 29, loss = 0.06191660\n",
      "\n",
      "Iteration 1, loss = 0.12280555Iteration 9, loss = 0.06565167\n",
      "\n",
      "\n",
      "Iteration 20, loss = 0.05232972Iteration 2, loss = 0.09096509\n",
      "\n",
      "Iteration 10, loss = 0.04817384Iteration 2, loss = 0.08517672Iteration 30, loss = 0.06169885\n",
      "\n",
      "Iteration 2, loss = 0.09021118Iteration 10, loss = 0.06433676\n",
      "\n",
      "\n",
      "Iteration 21, loss = 0.05261677Iteration 3, loss = 0.08097604\n",
      "\n",
      "Iteration 11, loss = 0.04796848Iteration 3, loss = 0.07892537Iteration 31, loss = 0.06163183\n",
      "\n",
      "Iteration 3, loss = 0.08376818Iteration 11, loss = 0.06381247\n",
      "\n",
      "\n",
      "Iteration 22, loss = 0.05203353Iteration 4, loss = 0.07548225\n",
      "\n",
      "Iteration 12, loss = 0.04737376Iteration 4, loss = 0.07490445Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "\n",
      "\n",
      "Iteration 4, loss = 0.07927660Iteration 12, loss = 0.06323724\n",
      "\n",
      "Iteration 1, loss = 0.12812152Iteration 23, loss = 0.05197856Iteration 5, loss = 0.07228190\n",
      "\n",
      "Iteration 13, loss = 0.04651827Iteration 5, loss = 0.07169012\n",
      "\n",
      "\n",
      "Iteration 5, loss = 0.07544253Iteration 13, loss = 0.06240529\n",
      "\n",
      "Iteration 2, loss = 0.09637072Iteration 24, loss = 0.05168586Iteration 6, loss = 0.07036591\n",
      "\n",
      "Iteration 14, loss = 0.04609598Iteration 6, loss = 0.06876659\n",
      "\n",
      "\n",
      "Iteration 6, loss = 0.07217736Iteration 14, loss = 0.06285393\n",
      "\n",
      "Iteration 3, loss = 0.09088230Iteration 25, loss = 0.05122901Iteration 7, loss = 0.06886577\n",
      "\n",
      "Iteration 15, loss = 0.04546718Iteration 7, loss = 0.06741831\n",
      "\n",
      "\n",
      "Iteration 7, loss = 0.07049748Iteration 15, loss = 0.06170072\n",
      "\n",
      "Iteration 4, loss = 0.08596463Iteration 26, loss = 0.05131493Iteration 8, loss = 0.06748330\n",
      "\n",
      "Iteration 16, loss = 0.04520066Iteration 8, loss = 0.06562730\n",
      "\n",
      "\n",
      "Iteration 8, loss = 0.06838174Iteration 16, loss = 0.06127339\n",
      "\n",
      "Iteration 5, loss = 0.08206142Iteration 27, loss = 0.05087475Iteration 9, loss = 0.06631460\n",
      "\n",
      "Iteration 17, loss = 0.04416367Iteration 9, loss = 0.06399997\n",
      "\n",
      "\n",
      "Iteration 9, loss = 0.06658031Iteration 17, loss = 0.06089725\n",
      "\n",
      "Iteration 6, loss = 0.07946061Iteration 28, loss = 0.05017693Iteration 10, loss = 0.06568379\n",
      "\n",
      "Iteration 18, loss = 0.04472913Iteration 10, loss = 0.06266721\n",
      "\n",
      "\n",
      "Iteration 10, loss = 0.06495834Iteration 18, loss = 0.06100293\n",
      "\n",
      "Iteration 7, loss = 0.07780825Iteration 29, loss = 0.05078885Iteration 11, loss = 0.06474362\n",
      "\n",
      "Iteration 19, loss = 0.04407806Iteration 11, loss = 0.06162598\n",
      "\n",
      "\n",
      "Iteration 11, loss = 0.06379604Iteration 19, loss = 0.06074485\n",
      "\n",
      "Iteration 8, loss = 0.07548546Iteration 30, loss = 0.05043618Iteration 12, loss = 0.06409235\n",
      "\n",
      "Iteration 20, loss = 0.04373907Iteration 12, loss = 0.06043883\n",
      "\n",
      "\n",
      "Iteration 12, loss = 0.06240164Iteration 20, loss = 0.06035069\n",
      "\n",
      "Iteration 9, loss = 0.07369896Iteration 31, loss = 0.05024479Iteration 13, loss = 0.06329265\n",
      "\n",
      "Iteration 21, loss = 0.04317945Iteration 13, loss = 0.05970547\n",
      "\n",
      "\n",
      "Iteration 13, loss = 0.06135486Iteration 21, loss = 0.06046497\n",
      "\n",
      "Iteration 10, loss = 0.07265964Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 14, loss = 0.06351317\n",
      "\n",
      "Iteration 12, loss = 0.05309655\n",
      "Iteration 22, loss = 0.04327611Iteration 14, loss = 0.05918288\n",
      "Iteration 1, loss = 0.12376553\n",
      "Iteration 14, loss = 0.06117478Iteration 22, loss = 0.05996684\n",
      "\n",
      "Iteration 11, loss = 0.07131318\n",
      "Iteration 15, loss = 0.06237201\n",
      "\n",
      "Iteration 23, loss = 0.04305270Iteration 15, loss = 0.05742125\n",
      "Iteration 2, loss = 0.08438053\n",
      "Iteration 15, loss = 0.05902898Iteration 23, loss = 0.06003339\n",
      "\n",
      "Iteration 12, loss = 0.07017098\n",
      "Iteration 16, loss = 0.06216282\n",
      "\n",
      "Iteration 24, loss = 0.04301993Iteration 16, loss = 0.05713790\n",
      "Iteration 3, loss = 0.07860817\n",
      "Iteration 16, loss = 0.05875796Iteration 24, loss = 0.05971032\n",
      "\n",
      "Iteration 13, loss = 0.06856400\n",
      "Iteration 17, loss = 0.06191907\n",
      "\n",
      "Iteration 25, loss = 0.04268178Iteration 17, loss = 0.05670551\n",
      "Iteration 4, loss = 0.07423167\n",
      "Iteration 17, loss = 0.05831701Iteration 25, loss = 0.05951795\n",
      "\n",
      "Iteration 14, loss = 0.06836778\n",
      "Iteration 18, loss = 0.06161180\n",
      "\n",
      "Iteration 26, loss = 0.04259511Iteration 18, loss = 0.05593762\n",
      "Iteration 5, loss = 0.07094521\n",
      "Iteration 18, loss = 0.05747935Iteration 26, loss = 0.05973459\n",
      "\n",
      "Iteration 15, loss = 0.06766946\n",
      "Iteration 19, loss = 0.06172300\n",
      "\n",
      "Iteration 27, loss = 0.04220514Iteration 19, loss = 0.05582785\n",
      "Iteration 6, loss = 0.06820710\n",
      "Iteration 19, loss = 0.05746812Iteration 27, loss = 0.05925040\n",
      "\n",
      "Iteration 16, loss = 0.06696137\n",
      "Iteration 20, loss = 0.06146016\n",
      "\n",
      "Iteration 28, loss = 0.04239020Iteration 20, loss = 0.05505593\n",
      "Iteration 7, loss = 0.06708426\n",
      "Iteration 20, loss = 0.05670897Iteration 28, loss = 0.05887037\n",
      "\n",
      "Iteration 17, loss = 0.06595243\n",
      "Iteration 21, loss = 0.06145385\n",
      "\n",
      "Iteration 29, loss = 0.04196372Iteration 21, loss = 0.05518261\n",
      "Iteration 8, loss = 0.06472245\n",
      "Iteration 21, loss = 0.05692463Iteration 29, loss = 0.05937738\n",
      "\n",
      "Iteration 18, loss = 0.06607711\n",
      "Iteration 22, loss = 0.06077523\n",
      "\n",
      "Iteration 30, loss = 0.04158489Iteration 22, loss = 0.05456758\n",
      "Iteration 9, loss = 0.06351538\n",
      "Iteration 22, loss = 0.05639209Iteration 30, loss = 0.05893670\n",
      "\n",
      "Iteration 19, loss = 0.06586510\n",
      "Iteration 23, loss = 0.06073680\n",
      "\n",
      "Iteration 31, loss = 0.04202007Iteration 23, loss = 0.05414281\n",
      "Iteration 10, loss = 0.06205082\n",
      "Iteration 23, loss = 0.05578295Iteration 31, loss = 0.05892115\n",
      "\n",
      "Iteration 20, loss = 0.06504979\n",
      "Iteration 24, loss = 0.06067218\n",
      "\n",
      "Iteration 32, loss = 0.04169724Iteration 24, loss = 0.05407448\n",
      "Iteration 11, loss = 0.06077724\n",
      "Iteration 24, loss = 0.05581451Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "\n",
      "\n",
      "Iteration 21, loss = 0.06561124\n",
      "Iteration 25, loss = 0.06038149\n",
      "Iteration 1, loss = 0.11626933Iteration 33, loss = 0.04151727Iteration 25, loss = 0.05390391\n",
      "Iteration 12, loss = 0.05994453\n",
      "Iteration 25, loss = 0.05537438\n",
      "\n",
      "\n",
      "Iteration 22, loss = 0.06458500\n",
      "Iteration 26, loss = 0.06036029\n",
      "Iteration 2, loss = 0.07217206Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 26, loss = 0.05351926\n",
      "Iteration 13, loss = 0.05860613\n",
      "Iteration 26, loss = 0.05551224\n",
      "Iteration 1, loss = 0.10271171\n",
      "Iteration 23, loss = 0.06424169\n",
      "Iteration 27, loss = 0.06006519\n",
      "Iteration 3, loss = 0.06829659\n",
      "Iteration 27, loss = 0.05337794\n",
      "Iteration 14, loss = 0.05909574\n",
      "Iteration 27, loss = 0.05516058\n",
      "Iteration 2, loss = 0.06925427\n",
      "Iteration 24, loss = 0.06440088\n",
      "Iteration 28, loss = 0.06000363\n",
      "Iteration 4, loss = 0.06494448\n",
      "Iteration 28, loss = 0.05253209\n",
      "Iteration 15, loss = 0.05748805\n",
      "Iteration 28, loss = 0.05437280\n",
      "Iteration 3, loss = 0.06586272\n",
      "Iteration 25, loss = 0.06359631\n",
      "Iteration 29, loss = 0.06013601\n",
      "Iteration 5, loss = 0.06303881\n",
      "Iteration 29, loss = 0.05305249\n",
      "Iteration 16, loss = 0.05669526\n",
      "Iteration 29, loss = 0.05476195\n",
      "Iteration 4, loss = 0.06200321\n",
      "Iteration 26, loss = 0.06402340\n",
      "Iteration 30, loss = 0.05982069\n",
      "Iteration 6, loss = 0.06123284\n",
      "Iteration 30, loss = 0.05301239\n",
      "Iteration 17, loss = 0.05607325\n",
      "Iteration 30, loss = 0.05495099\n",
      "Iteration 5, loss = 0.05940028\n",
      "Iteration 27, loss = 0.06375333\n",
      "Iteration 31, loss = 0.05993098\n",
      "Iteration 7, loss = 0.06035001\n",
      "Iteration 31, loss = 0.05263390\n",
      "Iteration 18, loss = 0.05625450\n",
      "Iteration 31, loss = 0.05434142\n",
      "Iteration 6, loss = 0.05688352\n",
      "Iteration 28, loss = 0.06302818\n",
      "Iteration 32, loss = 0.05996371\n",
      "Iteration 8, loss = 0.05919168\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "\n",
      "\n",
      "Iteration 13, loss = 0.05273053Iteration 19, loss = 0.05575339\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "\n",
      "Iteration 7, loss = 0.05563270Iteration 1, loss = 0.12076953Iteration 29, loss = 0.06339609\n",
      "Iteration 33, loss = 0.05922821Iteration 1, loss = 0.16488826Iteration 9, loss = 0.05788521\n",
      "\n",
      "\n",
      "Iteration 20, loss = 0.05460210\n",
      "\n",
      "\n",
      "Iteration 8, loss = 0.05413448Iteration 2, loss = 0.08259347Iteration 30, loss = 0.06309934\n",
      "Iteration 34, loss = 0.05928484Iteration 2, loss = 0.09014843Iteration 10, loss = 0.05684684\n",
      "\n",
      "\n",
      "Iteration 21, loss = 0.05473529\n",
      "\n",
      "\n",
      "Iteration 9, loss = 0.05246064Iteration 3, loss = 0.07733903Iteration 31, loss = 0.06303409\n",
      "Iteration 35, loss = 0.05939535Iteration 3, loss = 0.08042892Iteration 11, loss = 0.05671817\n",
      "\n",
      "\n",
      "Iteration 22, loss = 0.05428540\n",
      "\n",
      "\n",
      "Iteration 10, loss = 0.05092399Iteration 4, loss = 0.07326307Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "\n",
      "Iteration 36, loss = 0.05939387Iteration 4, loss = 0.07532436Iteration 12, loss = 0.05644407\n",
      "\n",
      "\n",
      "Iteration 23, loss = 0.05417480\n",
      "\n",
      "Iteration 11, loss = 0.05063028Iteration 5, loss = 0.07017378Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "\n",
      "Iteration 5, loss = 0.07185161Iteration 13, loss = 0.05548484\n",
      "\n",
      "Iteration 1, loss = 0.13258947Iteration 24, loss = 0.05381087\n",
      "\n",
      "Iteration 12, loss = 0.04988165Iteration 6, loss = 0.06740724\n",
      "\n",
      "Iteration 6, loss = 0.06961394Iteration 14, loss = 0.05508452\n",
      "\n",
      "Iteration 2, loss = 0.09449125Iteration 25, loss = 0.05324029\n",
      "\n",
      "Iteration 13, loss = 0.04878863Iteration 7, loss = 0.06614760\n",
      "\n",
      "Iteration 7, loss = 0.06819148Iteration 15, loss = 0.05449819\n",
      "\n",
      "Iteration 3, loss = 0.08877096Iteration 26, loss = 0.05320887\n",
      "\n",
      "Iteration 14, loss = 0.04816435Iteration 8, loss = 0.06407935\n",
      "\n",
      "Iteration 8, loss = 0.06703572Iteration 16, loss = 0.05422883\n",
      "\n",
      "Iteration 4, loss = 0.08448900Iteration 27, loss = 0.05285232\n",
      "\n",
      "Iteration 15, loss = 0.04739947Iteration 9, loss = 0.06202857\n",
      "\n",
      "Iteration 9, loss = 0.06618236Iteration 17, loss = 0.05321268\n",
      "\n",
      "Iteration 5, loss = 0.08141461Iteration 28, loss = 0.05198749\n",
      "\n",
      "Iteration 16, loss = 0.04717389Iteration 10, loss = 0.06118101\n",
      "\n",
      "Iteration 10, loss = 0.06523830Iteration 18, loss = 0.05383415\n",
      "\n",
      "Iteration 6, loss = 0.07956645Iteration 29, loss = 0.05258206\n",
      "\n",
      "Iteration 17, loss = 0.04592506Iteration 11, loss = 0.05975069\n",
      "\n",
      "Iteration 11, loss = 0.06456294Iteration 19, loss = 0.05302537\n",
      "\n",
      "Iteration 7, loss = 0.07789844Iteration 30, loss = 0.05236193\n",
      "\n",
      "Iteration 18, loss = 0.04639869Iteration 12, loss = 0.05883452\n",
      "\n",
      "Iteration 12, loss = 0.06367695Iteration 20, loss = 0.05285201\n",
      "\n",
      "Iteration 8, loss = 0.07605909Iteration 31, loss = 0.05206136\n",
      "\n",
      "Iteration 19, loss = 0.04567301Iteration 13, loss = 0.05707178\n",
      "\n",
      "Iteration 13, loss = 0.06333432Iteration 21, loss = 0.05227259\n",
      "\n",
      "Iteration 9, loss = 0.07450635Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "\n",
      "\n",
      "Iteration 20, loss = 0.04529491Iteration 14, loss = 0.05692900\n",
      "Iteration 1, loss = 0.12325893Iteration 14, loss = 0.06321121Iteration 22, loss = 0.05227425\n",
      "\n",
      "Iteration 10, loss = 0.07353519\n",
      "\n",
      "\n",
      "Iteration 21, loss = 0.04468716Iteration 15, loss = 0.05630202\n",
      "Iteration 2, loss = 0.09083632Iteration 15, loss = 0.06215818Iteration 23, loss = 0.05210967\n",
      "\n",
      "Iteration 11, loss = 0.07226266\n",
      "\n",
      "\n",
      "Iteration 22, loss = 0.04462252Iteration 16, loss = 0.05529526\n",
      "Iteration 3, loss = 0.08483283Iteration 16, loss = 0.06203244Iteration 24, loss = 0.05208662\n",
      "\n",
      "Iteration 12, loss = 0.07139852\n",
      "\n",
      "\n",
      "Iteration 23, loss = 0.04443828Iteration 17, loss = 0.05425028\n",
      "Iteration 4, loss = 0.07975009Iteration 17, loss = 0.06173243Iteration 25, loss = 0.05181849\n",
      "\n",
      "Iteration 13, loss = 0.06982456\n",
      "\n",
      "\n",
      "Iteration 24, loss = 0.04424641Iteration 18, loss = 0.05452661\n",
      "Iteration 5, loss = 0.07586682Iteration 18, loss = 0.06135264Iteration 26, loss = 0.05178970\n",
      "\n",
      "Iteration 14, loss = 0.07030663\n",
      "\n",
      "\n",
      "Iteration 25, loss = 0.04396337Iteration 19, loss = 0.05434710\n",
      "Iteration 6, loss = 0.07353455Iteration 19, loss = 0.06153586Iteration 27, loss = 0.05135786\n",
      "\n",
      "Iteration 15, loss = 0.06857275\n",
      "\n",
      "\n",
      "Iteration 26, loss = 0.04376844Iteration 20, loss = 0.05311315\n",
      "Iteration 7, loss = 0.07110395Iteration 20, loss = 0.06102146Iteration 28, loss = 0.05145606\n",
      "\n",
      "Iteration 16, loss = 0.06825852\n",
      "\n",
      "\n",
      "Iteration 27, loss = 0.04335197Iteration 21, loss = 0.05368705\n",
      "Iteration 8, loss = 0.06902187Iteration 21, loss = 0.06117678\n",
      "Iteration 14, loss = 0.05228998Iteration 29, loss = 0.05122555\n",
      "\n",
      "Iteration 17, loss = 0.06762039\n",
      "\n",
      "\n",
      "Iteration 28, loss = 0.04349941Iteration 22, loss = 0.05258783\n",
      "Iteration 9, loss = 0.06658426Iteration 22, loss = 0.06056737Iteration 30, loss = 0.05077306\n",
      "\n",
      "Iteration 18, loss = 0.06727649\n",
      "\n",
      "\n",
      "Iteration 29, loss = 0.04327028Iteration 23, loss = 0.05229969\n",
      "Iteration 10, loss = 0.06541531Iteration 23, loss = 0.06048066Iteration 31, loss = 0.05121133\n",
      "\n",
      "Iteration 19, loss = 0.06738773\n",
      "\n",
      "\n",
      "Iteration 30, loss = 0.04268556Iteration 24, loss = 0.05254879\n",
      "Iteration 11, loss = 0.06408346Iteration 24, loss = 0.06036127Iteration 32, loss = 0.05085339\n",
      "\n",
      "Iteration 20, loss = 0.06660881\n",
      "\n",
      "\n",
      "Iteration 31, loss = 0.04323375Iteration 25, loss = 0.05160302\n",
      "Iteration 12, loss = 0.06321985Iteration 25, loss = 0.06012299Iteration 33, loss = 0.05065629\n",
      "\n",
      "Iteration 21, loss = 0.06654669\n",
      "\n",
      "\n",
      "Iteration 32, loss = 0.04304259Iteration 26, loss = 0.05212155\n",
      "Iteration 13, loss = 0.06118725Iteration 26, loss = 0.06024290Iteration 34, loss = 0.05064607\n",
      "\n",
      "Iteration 22, loss = 0.06577978\n",
      "\n",
      "\n",
      "Iteration 33, loss = 0.04270039Iteration 27, loss = 0.05172267\n",
      "Iteration 14, loss = 0.06164101Iteration 27, loss = 0.05989508Iteration 35, loss = 0.05017244\n",
      "\n",
      "Iteration 23, loss = 0.06548004\n",
      "\n",
      "\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 28, loss = 0.05075318\n",
      "Iteration 15, loss = 0.05971640Iteration 28, loss = 0.05960314Iteration 36, loss = 0.05002922Iteration 1, loss = 0.10166941\n",
      "Iteration 24, loss = 0.06545656\n",
      "\n",
      "\n",
      "\n",
      "Iteration 29, loss = 0.05094427\n",
      "Iteration 16, loss = 0.05923986Iteration 29, loss = 0.05977187Iteration 37, loss = 0.05018963Iteration 2, loss = 0.07387916\n",
      "Iteration 25, loss = 0.06485800\n",
      "\n",
      "\n",
      "\n",
      "Iteration 30, loss = 0.05097973\n",
      "Iteration 17, loss = 0.05871188Iteration 30, loss = 0.05978383Iteration 38, loss = 0.04991941Iteration 3, loss = 0.07026190\n",
      "Iteration 26, loss = 0.06474003\n",
      "\n",
      "\n",
      "\n",
      "Iteration 31, loss = 0.05064687\n",
      "Iteration 18, loss = 0.05805118Iteration 31, loss = 0.05958188Iteration 39, loss = 0.05041268Iteration 4, loss = 0.06586590\n",
      "Iteration 27, loss = 0.06441030\n",
      "\n",
      "\n",
      "\n",
      "Iteration 32, loss = 0.05097173\n",
      "Iteration 19, loss = 0.05809063Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 40, loss = 0.04981617Iteration 5, loss = 0.06257823\n",
      "Iteration 28, loss = 0.06413682\n",
      "Iteration 1, loss = 0.13898513\n",
      "\n",
      "Iteration 33, loss = 0.05003336\n",
      "Iteration 20, loss = 0.05737761\n",
      "Iteration 41, loss = 0.04966425Iteration 6, loss = 0.05956311\n",
      "Iteration 29, loss = 0.06438389\n",
      "Iteration 2, loss = 0.08963667\n",
      "\n",
      "Iteration 34, loss = 0.04985237\n",
      "Iteration 21, loss = 0.05715977\n",
      "Iteration 42, loss = 0.04940136Iteration 7, loss = 0.05790929\n",
      "Iteration 30, loss = 0.06398192\n",
      "Iteration 3, loss = 0.08310741\n",
      "\n",
      "Iteration 35, loss = 0.04992214\n",
      "Iteration 22, loss = 0.05649282\n",
      "Iteration 43, loss = 0.04965767Iteration 8, loss = 0.05651679\n",
      "Iteration 31, loss = 0.06395650\n",
      "Iteration 4, loss = 0.07906296\n",
      "\n",
      "Iteration 36, loss = 0.04962485\n",
      "Iteration 23, loss = 0.05623387\n",
      "Iteration 44, loss = 0.04931332Iteration 9, loss = 0.05448488\n",
      "Iteration 32, loss = 0.06398170\n",
      "Iteration 5, loss = 0.07664260\n",
      "\n",
      "Iteration 37, loss = 0.04987433\n",
      "Iteration 24, loss = 0.05585710\n",
      "Iteration 45, loss = 0.04951045Iteration 10, loss = 0.05281237\n",
      "Iteration 33, loss = 0.06298842\n",
      "Iteration 6, loss = 0.07521895\n",
      "\n",
      "Iteration 38, loss = 0.04960917\n",
      "Iteration 25, loss = 0.05541090\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 11, loss = 0.05244579\n",
      "Iteration 34, loss = 0.06307383\n",
      "Iteration 7, loss = 0.07383335Iteration 26, loss = 0.05516702\n",
      "Iteration 39, loss = 0.04978117\n",
      "\n",
      "\n",
      "Iteration 12, loss = 0.05169226\n",
      "Iteration 35, loss = 0.06320630Iteration 8, loss = 0.07234521Iteration 27, loss = 0.05482066\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "\n",
      "\n",
      "\n",
      "Iteration 13, loss = 0.05037129Iteration 1, loss = 0.16192847Iteration 36, loss = 0.06316627Iteration 9, loss = 0.07093443Iteration 28, loss = 0.05468706\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 14, loss = 0.04971906Iteration 2, loss = 0.08813386Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 10, loss = 0.07029333Iteration 29, loss = 0.05464130\n",
      "\n",
      "Iteration 1, loss = 0.10961415\n",
      "\n",
      "Iteration 15, loss = 0.04901010Iteration 3, loss = 0.07831670\n",
      "Iteration 11, loss = 0.06919816Iteration 30, loss = 0.05435338\n",
      "\n",
      "Iteration 2, loss = 0.08149284\n",
      "\n",
      "\n",
      "Iteration 15, loss = 0.05161580Iteration 16, loss = 0.04857004Iteration 4, loss = 0.07283181\n",
      "Iteration 12, loss = 0.06857510Iteration 31, loss = 0.05432933\n",
      "\n",
      "Iteration 3, loss = 0.07794093\n",
      "\n",
      "Iteration 17, loss = 0.04743974Iteration 5, loss = 0.06986417\n",
      "Iteration 13, loss = 0.06741723Iteration 32, loss = 0.05441190\n",
      "\n",
      "Iteration 4, loss = 0.07342999\n",
      "\n",
      "Iteration 18, loss = 0.04787307Iteration 6, loss = 0.06795577\n",
      "Iteration 14, loss = 0.06781979Iteration 33, loss = 0.05332496\n",
      "\n",
      "Iteration 5, loss = 0.07004728\n",
      "\n",
      "Iteration 19, loss = 0.04684845Iteration 7, loss = 0.06637714\n",
      "Iteration 15, loss = 0.06630490Iteration 34, loss = 0.05336265\n",
      "\n",
      "Iteration 6, loss = 0.06737738\n",
      "\n",
      "Iteration 20, loss = 0.04657144Iteration 8, loss = 0.06527511\n",
      "Iteration 16, loss = 0.06601566Iteration 35, loss = 0.05359589\n",
      "\n",
      "Iteration 7, loss = 0.06608004\n",
      "\n",
      "Iteration 21, loss = 0.04599817Iteration 9, loss = 0.06403780\n",
      "Iteration 17, loss = 0.06562122Iteration 36, loss = 0.05371794\n",
      "\n",
      "Iteration 8, loss = 0.06429996\n",
      "\n",
      "Iteration 22, loss = 0.04587932Iteration 10, loss = 0.06341600\n",
      "Iteration 18, loss = 0.06520989Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "\n",
      "\n",
      "Iteration 9, loss = 0.06241554\n",
      "Iteration 1, loss = 0.14200801Iteration 23, loss = 0.04562639Iteration 11, loss = 0.06281677\n",
      "Iteration 19, loss = 0.06533393\n",
      "\n",
      "\n",
      "Iteration 10, loss = 0.06077455\n",
      "Iteration 2, loss = 0.07283397Iteration 24, loss = 0.04569298Iteration 12, loss = 0.06196412\n",
      "Iteration 20, loss = 0.06476106\n",
      "\n",
      "\n",
      "Iteration 11, loss = 0.06048782\n",
      "Iteration 3, loss = 0.06541240Iteration 25, loss = 0.04525691Iteration 13, loss = 0.06112871\n",
      "Iteration 21, loss = 0.06475948\n",
      "\n",
      "\n",
      "Iteration 12, loss = 0.05997461\n",
      "Iteration 4, loss = 0.06082919Iteration 26, loss = 0.04523413Iteration 14, loss = 0.06113320\n",
      "Iteration 22, loss = 0.06395849\n",
      "\n",
      "\n",
      "Iteration 13, loss = 0.05865904\n",
      "Iteration 5, loss = 0.05851263Iteration 27, loss = 0.04482019Iteration 15, loss = 0.06072828\n",
      "Iteration 23, loss = 0.06375750\n",
      "\n",
      "\n",
      "Iteration 14, loss = 0.05801129\n",
      "Iteration 6, loss = 0.05671586Iteration 28, loss = 0.04497952Iteration 16, loss = 0.06018160\n",
      "Iteration 24, loss = 0.06377173\n",
      "\n",
      "\n",
      "Iteration 15, loss = 0.05737000\n",
      "Iteration 7, loss = 0.05568549Iteration 29, loss = 0.04467745Iteration 17, loss = 0.05956436\n",
      "Iteration 25, loss = 0.06320951\n",
      "\n",
      "\n",
      "Iteration 16, loss = 0.05707288\n",
      "Iteration 8, loss = 0.05461060Iteration 30, loss = 0.04424757Iteration 18, loss = 0.05980908\n",
      "Iteration 26, loss = 0.06318834\n",
      "\n",
      "\n",
      "Iteration 17, loss = 0.05578816\n",
      "Iteration 9, loss = 0.05371318Iteration 31, loss = 0.04468677Iteration 19, loss = 0.05962564\n",
      "Iteration 27, loss = 0.06272845\n",
      "\n",
      "\n",
      "Iteration 18, loss = 0.05640578\n",
      "Iteration 10, loss = 0.05295936Iteration 32, loss = 0.04427593Iteration 20, loss = 0.05925016\n",
      "Iteration 28, loss = 0.06261650\n",
      "\n",
      "\n",
      "Iteration 19, loss = 0.05532643\n",
      "Iteration 11, loss = 0.05275174Iteration 33, loss = 0.04419724Iteration 21, loss = 0.05952196\n",
      "Iteration 29, loss = 0.06273894\n",
      "\n",
      "\n",
      "Iteration 20, loss = 0.05514336\n",
      "Iteration 12, loss = 0.05253236Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 22, loss = 0.05889950\n",
      "Iteration 30, loss = 0.06239720\n",
      "Iteration 1, loss = 0.13864674\n",
      "Iteration 21, loss = 0.05458882\n",
      "Iteration 13, loss = 0.05183830\n",
      "Iteration 23, loss = 0.05883886\n",
      "Iteration 31, loss = 0.06238645\n",
      "Iteration 2, loss = 0.08908620\n",
      "Iteration 22, loss = 0.05454067\n",
      "Iteration 14, loss = 0.05163964\n",
      "Iteration 24, loss = 0.05883898\n",
      "Iteration 32, loss = 0.06233976\n",
      "Iteration 3, loss = 0.08263534\n",
      "Iteration 23, loss = 0.05429526\n",
      "Iteration 15, loss = 0.05115125\n",
      "Iteration 25, loss = 0.05839829\n",
      "Iteration 33, loss = 0.06151565\n",
      "Iteration 4, loss = 0.07895325\n",
      "Iteration 24, loss = 0.05421952\n",
      "Iteration 16, loss = 0.05088676\n",
      "Iteration 26, loss = 0.05871283\n",
      "Iteration 34, loss = 0.06143482\n",
      "Iteration 5, loss = 0.07642652\n",
      "Iteration 25, loss = 0.05400200\n",
      "Iteration 17, loss = 0.05021468\n",
      "Iteration 27, loss = 0.05843899\n",
      "Iteration 35, loss = 0.06170222\n",
      "Iteration 6, loss = 0.07417764\n",
      "Iteration 26, loss = 0.05408483\n",
      "Iteration 18, loss = 0.05077768\n",
      "Iteration 28, loss = 0.05796748\n",
      "Iteration 36, loss = 0.06159202\n",
      "Iteration 7, loss = 0.07315227\n",
      "Iteration 27, loss = 0.05351430\n",
      "Iteration 19, loss = 0.05011243\n",
      "Iteration 29, loss = 0.05824707\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "\n",
      "Iteration 8, loss = 0.07193702\n",
      "Iteration 16, loss = 0.05111214\n",
      "Iteration 28, loss = 0.05369295Iteration 1, loss = 0.10999864Iteration 20, loss = 0.05012380\n",
      "Iteration 30, loss = 0.05799463\n",
      "\n",
      "\n",
      "Iteration 9, loss = 0.07088420\n",
      "Iteration 29, loss = 0.05347410Iteration 2, loss = 0.07653417Iteration 21, loss = 0.04960947\n",
      "Iteration 31, loss = 0.05810023\n",
      "\n",
      "\n",
      "Iteration 10, loss = 0.06975714\n",
      "Iteration 30, loss = 0.05297658Iteration 3, loss = 0.07346412Iteration 22, loss = 0.04969059\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "\n",
      "\n",
      "\n",
      "Iteration 11, loss = 0.06901300Iteration 1, loss = 0.13499861Iteration 31, loss = 0.05351232Iteration 4, loss = 0.06988740Iteration 23, loss = 0.04956785\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 12, loss = 0.06794698Iteration 2, loss = 0.08623290Iteration 32, loss = 0.05305907Iteration 5, loss = 0.06704724Iteration 24, loss = 0.04966834\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 13, loss = 0.06738962Iteration 3, loss = 0.08056334Iteration 33, loss = 0.05303042Iteration 6, loss = 0.06484279Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 1, loss = 0.13224757Iteration 14, loss = 0.06723372Iteration 4, loss = 0.07685239Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 7, loss = 0.06363639\n",
      "\n",
      "\n",
      "\n",
      "Iteration 2, loss = 0.09378092Iteration 15, loss = 0.06583349Iteration 5, loss = 0.07452224Iteration 8, loss = 0.06217554\n",
      "\n",
      "\n",
      "\n",
      "Iteration 3, loss = 0.08786651Iteration 16, loss = 0.06555389Iteration 6, loss = 0.07278151Iteration 9, loss = 0.06054858\n",
      "\n",
      "\n",
      "\n",
      "Iteration 4, loss = 0.08404221Iteration 17, loss = 0.06533609Iteration 7, loss = 0.07170403Iteration 10, loss = 0.05924294\n",
      "\n",
      "\n",
      "\n",
      "Iteration 5, loss = 0.08091868Iteration 18, loss = 0.06469313Iteration 8, loss = 0.07034808Iteration 11, loss = 0.05906696\n",
      "\n",
      "\n",
      "\n",
      "Iteration 6, loss = 0.07838000Iteration 19, loss = 0.06476429Iteration 9, loss = 0.06887915Iteration 12, loss = 0.05875141\n",
      "\n",
      "\n",
      "\n",
      "Iteration 7, loss = 0.07695393Iteration 20, loss = 0.06411853Iteration 10, loss = 0.06824093Iteration 13, loss = 0.05755576\n",
      "\n",
      "\n",
      "\n",
      "Iteration 8, loss = 0.07542352Iteration 21, loss = 0.06428481Iteration 11, loss = 0.06741201Iteration 14, loss = 0.05690472\n",
      "\n",
      "\n",
      "\n",
      "Iteration 9, loss = 0.07416502Iteration 22, loss = 0.06348050Iteration 12, loss = 0.06649457Iteration 15, loss = 0.05624650\n",
      "\n",
      "\n",
      "\n",
      "Iteration 10, loss = 0.07269085Iteration 23, loss = 0.06325904Iteration 13, loss = 0.06509693Iteration 16, loss = 0.05597035\n",
      "\n",
      "\n",
      "\n",
      "Iteration 11, loss = 0.07174833Iteration 24, loss = 0.06312077Iteration 14, loss = 0.06516279Iteration 17, loss = 0.05476204\n",
      "\n",
      "\n",
      "\n",
      "Iteration 12, loss = 0.07045749Iteration 25, loss = 0.06286263Iteration 15, loss = 0.06466795Iteration 18, loss = 0.05540631\n",
      "\n",
      "\n",
      "\n",
      "Iteration 13, loss = 0.06978715Iteration 26, loss = 0.06283782Iteration 16, loss = 0.06391557Iteration 19, loss = 0.05433278\n",
      "\n",
      "\n",
      "\n",
      "Iteration 14, loss = 0.06941609Iteration 27, loss = 0.06253298Iteration 17, loss = 0.06304685Iteration 20, loss = 0.05413005\n",
      "\n",
      "\n",
      "\n",
      "Iteration 15, loss = 0.06778289Iteration 28, loss = 0.06194323Iteration 18, loss = 0.06336185Iteration 21, loss = 0.05354578\n",
      "\n",
      "\n",
      "\n",
      "Iteration 16, loss = 0.06755431Iteration 29, loss = 0.06225876Iteration 19, loss = 0.06305410Iteration 22, loss = 0.05339868\n",
      "\n",
      "\n",
      "\n",
      "Iteration 17, loss = 0.06719246Iteration 30, loss = 0.06214050Iteration 20, loss = 0.06235899Iteration 23, loss = 0.05323269\n",
      "\n",
      "\n",
      "\n",
      "Iteration 18, loss = 0.06646614Iteration 31, loss = 0.06190517Iteration 21, loss = 0.06294192Iteration 24, loss = 0.05321352\n",
      "\n",
      "\n",
      "\n",
      "Iteration 19, loss = 0.06663272Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 22, loss = 0.06193550Iteration 25, loss = 0.05298251\n",
      "Iteration 1, loss = 0.13160540\n",
      "\n",
      "Iteration 20, loss = 0.06578364\n",
      "Iteration 23, loss = 0.06177166Iteration 26, loss = 0.05293967\n",
      "Iteration 2, loss = 0.09293206\n",
      "\n",
      "Iteration 21, loss = 0.06596539\n",
      "Iteration 24, loss = 0.06176606Iteration 27, loss = 0.05250655\n",
      "Iteration 3, loss = 0.08752623\n",
      "\n",
      "Iteration 22, loss = 0.06517735\n",
      "Iteration 25, loss = 0.06105945Iteration 28, loss = 0.05262652\n",
      "Iteration 4, loss = 0.08371468\n",
      "\n",
      "Iteration 23, loss = 0.06478385\n",
      "Iteration 26, loss = 0.06143021Iteration 29, loss = 0.05228212\n",
      "Iteration 5, loss = 0.08016276\n",
      "\n",
      "Iteration 24, loss = 0.06473723\n",
      "Iteration 27, loss = 0.06111501Iteration 30, loss = 0.05185477\n",
      "Iteration 6, loss = 0.07791839\n",
      "\n",
      "Iteration 25, loss = 0.06435297\n",
      "Iteration 28, loss = 0.06052545Iteration 31, loss = 0.05232601\n",
      "\n",
      "Iteration 17, loss = 0.05106360Iteration 7, loss = 0.07675144\n",
      "\n",
      "Iteration 26, loss = 0.06430442\n",
      "Iteration 29, loss = 0.06067037Iteration 32, loss = 0.05201961\n",
      "Iteration 8, loss = 0.07477274\n",
      "\n",
      "Iteration 27, loss = 0.06389286\n",
      "Iteration 30, loss = 0.06050998Iteration 33, loss = 0.05182300\n",
      "Iteration 9, loss = 0.07368874\n",
      "\n",
      "Iteration 28, loss = 0.06331506\n",
      "Iteration 31, loss = 0.06048329Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "\n",
      "Iteration 10, loss = 0.07207333\n",
      "Iteration 29, loss = 0.06361204\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.13138552\n",
      "Iteration 11, loss = 0.07085636\n",
      "Iteration 30, loss = 0.06350862\n",
      "Iteration 2, loss = 0.09907073\n",
      "Iteration 12, loss = 0.06997498\n",
      "Iteration 31, loss = 0.06331675\n",
      "Iteration 3, loss = 0.09265276\n",
      "Iteration 13, loss = 0.06865180\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "\n",
      "Iteration 4, loss = 0.08805948Iteration 1, loss = 0.13190199Iteration 14, loss = 0.06917098\n",
      "\n",
      "\n",
      "Iteration 5, loss = 0.08459362Iteration 2, loss = 0.10002092Iteration 15, loss = 0.06750513\n",
      "\n",
      "\n",
      "Iteration 6, loss = 0.08140747Iteration 3, loss = 0.09363605Iteration 16, loss = 0.06671942\n",
      "\n",
      "\n",
      "Iteration 7, loss = 0.07968382Iteration 4, loss = 0.08862797Iteration 17, loss = 0.06611284\n",
      "\n",
      "\n",
      "Iteration 8, loss = 0.07795656Iteration 5, loss = 0.08471834Iteration 18, loss = 0.06639436\n",
      "\n",
      "\n",
      "Iteration 9, loss = 0.07624449Iteration 6, loss = 0.08276694Iteration 19, loss = 0.06589704\n",
      "\n",
      "\n",
      "Iteration 10, loss = 0.07479114Iteration 7, loss = 0.08033933Iteration 20, loss = 0.06510674\n",
      "\n",
      "\n",
      "Iteration 11, loss = 0.07360243Iteration 8, loss = 0.07829281Iteration 21, loss = 0.06543167\n",
      "\n",
      "\n",
      "Iteration 12, loss = 0.07225617Iteration 9, loss = 0.07640615Iteration 22, loss = 0.06450180\n",
      "\n",
      "\n",
      "Iteration 13, loss = 0.07132386Iteration 10, loss = 0.07521752Iteration 23, loss = 0.06451831\n",
      "\n",
      "\n",
      "Iteration 14, loss = 0.07103740Iteration 11, loss = 0.07376911Iteration 24, loss = 0.06412636\n",
      "\n",
      "\n",
      "Iteration 15, loss = 0.06928261Iteration 12, loss = 0.07283053Iteration 25, loss = 0.06374336\n",
      "\n",
      "\n",
      "Iteration 16, loss = 0.06888992Iteration 13, loss = 0.07119823Iteration 26, loss = 0.06386657\n",
      "\n",
      "\n",
      "Iteration 17, loss = 0.06859173Iteration 14, loss = 0.07163928Iteration 27, loss = 0.06335679\n",
      "\n",
      "\n",
      "Iteration 18, loss = 0.06781184Iteration 15, loss = 0.06984873Iteration 28, loss = 0.06274051\n",
      "\n",
      "\n",
      "Iteration 19, loss = 0.06792175Iteration 16, loss = 0.06946225Iteration 29, loss = 0.06337154\n",
      "\n",
      "\n",
      "Iteration 20, loss = 0.06729094Iteration 17, loss = 0.06896675Iteration 30, loss = 0.06289923\n",
      "\n",
      "\n",
      "Iteration 21, loss = 0.06762010Iteration 18, loss = 0.06830333Iteration 31, loss = 0.06278482\n",
      "\n",
      "\n",
      "Iteration 22, loss = 0.06667464Iteration 19, loss = 0.06832933Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "\n",
      "\n",
      "Iteration 1, loss = 0.13097747Iteration 23, loss = 0.06641068Iteration 20, loss = 0.06776505\n",
      "\n",
      "\n",
      "Iteration 2, loss = 0.09823524Iteration 24, loss = 0.06640867Iteration 21, loss = 0.06768102\n",
      "\n",
      "\n",
      "Iteration 3, loss = 0.09232159Iteration 25, loss = 0.06588508Iteration 22, loss = 0.06677680\n",
      "\n",
      "\n",
      "Iteration 4, loss = 0.08792331Iteration 26, loss = 0.06601706Iteration 23, loss = 0.06666091\n",
      "\n",
      "\n",
      "Iteration 5, loss = 0.08379850Iteration 27, loss = 0.06582401Iteration 24, loss = 0.06678982\n",
      "\n",
      "\n",
      "Iteration 6, loss = 0.08101113Iteration 28, loss = 0.06512855Iteration 25, loss = 0.06608626\n",
      "\n",
      "\n",
      "Iteration 7, loss = 0.07966234Iteration 29, loss = 0.06547006Iteration 26, loss = 0.06596881\n",
      "\n",
      "\n",
      "Iteration 8, loss = 0.07711648Iteration 30, loss = 0.06542369Iteration 27, loss = 0.06555715\n",
      "\n",
      "\n",
      "Iteration 9, loss = 0.07588609Iteration 31, loss = 0.06520359Iteration 28, loss = 0.06551082\n",
      "\n",
      "\n",
      "Iteration 10, loss = 0.07430003Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 29, loss = 0.06570579\n",
      "\n",
      "Iteration 11, loss = 0.07293405\n",
      "Iteration 30, loss = 0.06542462Iteration 12, loss = 0.07214299\n",
      "\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 13, loss = 0.07085010\n",
      "Iteration 14, loss = 0.07114899\n",
      "Iteration 15, loss = 0.06949985\n",
      "Iteration 16, loss = 0.06875487\n",
      "Iteration 17, loss = 0.06806136\n",
      "Iteration 18, loss = 0.06798368\n",
      "Iteration 19, loss = 0.06788362\n",
      "Iteration 20, loss = 0.06699918\n",
      "Iteration 21, loss = 0.06719337\n",
      "Iteration 22, loss = 0.06619181\n",
      "Iteration 23, loss = 0.06648160\n",
      "Iteration 24, loss = 0.06613415\n",
      "Iteration 25, loss = 0.06546286\n",
      "Iteration 26, loss = 0.06565328\n",
      "Iteration 18, loss = 0.05057471\n",
      "Iteration 27, loss = 0.06521848\n",
      "Iteration 28, loss = 0.06462556\n",
      "Iteration 29, loss = 0.06522320\n",
      "Iteration 30, loss = 0.06472957\n",
      "Iteration 31, loss = 0.06464531\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "\n",
      "Iteration 19, loss = 0.05022285\n",
      "Iteration 20, loss = 0.05033652\n",
      "Iteration 21, loss = 0.05025434\n",
      "Iteration 22, loss = 0.04992942\n",
      "Iteration 23, loss = 0.04961427\n",
      "Iteration 24, loss = 0.04925958\n",
      "Iteration 25, loss = 0.04955384\n",
      "Iteration 26, loss = 0.04923363\n",
      "Iteration 27, loss = 0.04915316\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0099999999999999985,\n",
       "       batch_size='auto', beta_1=0.9, beta_2=0.999, early_stopping=False,\n",
       "       epsilon=1e-08, hidden_layer_sizes=(2048,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=42, shuffle=True,\n",
       "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=True,\n",
       "       warm_start=False)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "param_grid = {#\"hidden_layer_sizes\":[(1000,),(1024,),(1100,)],\n",
    "    #\"alpha\":np.logspace(-3,-1,5)\n",
    "    \"alpha\":np.linspace(0.005,0.015,3),\n",
    "    \"learning_rate_init\":[0.001,0.002,0.003,0.004],\n",
    "}\n",
    "\n",
    "clf = MLPClassifier(hidden_layer_sizes=(2048,), random_state=42, verbose=True)\n",
    "gs = GridSearchCV(clf, param_grid, cv=5, n_jobs=-1)\n",
    "gs.fit(X_train, y_train)\n",
    "\n",
    "gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score sur le train : 0.0439962121212\n"
     ]
    }
   ],
   "source": [
    "# Predictiongrid_search\n",
    "y_pred_train =  gs.best_estimator_.predict(X_train)\n",
    "y_predict_train_proba = gs.best_estimator_.predict_proba(X_train)[:,0]\n",
    "        \n",
    "for i in range(len(y_pred_train)):\n",
    "    if (y_predict_train_proba[i]<0.9)and(y_predict_train_proba[i]>1-0.9):\n",
    "        y_pred_train[i]=0\n",
    "\n",
    "# score\n",
    "score = compute_pred_score(y_train, y_pred_train)\n",
    "print('Score sur le train : %s' % score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Génération de la prédiction sur le test et enregistrement du fichier à soumettre sur le site:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1  0  1]\n"
     ]
    }
   ],
   "source": [
    "y_pred = gs.best_estimator_.predict(X_test)\n",
    "y_predict_proba = gs.best_estimator_.predict_proba(X_test)[:,0]\n",
    "\n",
    "for i in range(len(y_pred)):\n",
    "    if (y_predict_proba[i]<0.9)and(y_predict_proba[i]>1-0.9):\n",
    "        y_pred[i]=0\n",
    "print np.unique(y_pred)\n",
    "\n",
    "np.savetxt('y_pred.txt', y_pred, fmt='%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous pouvez maintenant uploader votre fichier `y_pred.txt` sur le site.\n",
    "\n",
    "Bonne chance !"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
